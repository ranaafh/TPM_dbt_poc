

============================== 2024-05-08 19:44:47.489279 | 7cf90f2a-7b34-4b27-9f5d-dc0a11b642e8 ==============================
[0m19:44:47.489279 [info ] [MainThread]: Running with dbt=1.4.1
[0m19:44:47.489975 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/rana/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m19:44:47.490067 [debug] [MainThread]: Tracking: tracking
[0m19:44:47.508880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d92b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d92970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d92a90>]}
[0m19:44:47.804319 [debug] [MainThread]: Executing "git --help"
[0m19:44:47.822126 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m19:44:47.822538 [debug] [MainThread]: STDERR: "b''"
[0m19:44:47.822855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d9b4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067a5340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067a52e0>]}
[0m19:44:47.823174 [debug] [MainThread]: Flushing usage events


============================== 2024-05-08 19:44:57.242986 | d341f88f-9c9b-4156-93c1-d2af6e6b8b91 ==============================
[0m19:44:57.242986 [info ] [MainThread]: Running with dbt=1.4.1
[0m19:44:57.243714 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/rana/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'skip_profile_setup': False, 'which': 'init', 'indirect_selection': 'eager'}
[0m19:44:57.243815 [debug] [MainThread]: Tracking: tracking
[0m19:44:57.262675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b6be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b6910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b6b50>]}
[0m19:46:05.042517 [debug] [MainThread]: Starter project path: /opt/homebrew/Cellar/dbt-bigquery/1.4.0/libexec/lib/python3.9/site-packages/dbt/include/starter_project
[0m19:46:46.513685 [info ] [MainThread]: Profile tenant_A written to /Users/rana/.dbt/profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m19:46:46.514159 [info ] [MainThread]: 
Your new dbt project "tenant_A" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m19:46:46.514473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061bed60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061be1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061be3a0>]}
[0m19:46:46.514742 [debug] [MainThread]: Flushing usage events


============================== 2024-05-08 20:27:38.257053 | 19b2c30a-c5fa-48cf-a7ab-ada838d22219 ==============================
[0m20:27:38.257053 [info ] [MainThread]: Running with dbt=1.4.1
[0m20:27:38.257871 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/rana/TPM_dbt_poc/tenant_A', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m20:27:38.257998 [debug] [MainThread]: Tracking: tracking
[0m20:27:38.271077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104455f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104455b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044558b0>]}
[0m20:27:38.543195 [debug] [MainThread]: Executing "git --help"
[0m20:27:38.561691 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m20:27:38.562161 [debug] [MainThread]: STDERR: "b''"
[0m20:27:38.567639 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m20:27:38.567979 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:27:39.323544 [debug] [MainThread]: On debug: select 1 as id
[0m20:27:40.759331 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:e76c34e0-0e63-4778-a117-2eec0fdef103&page=queryresults
[0m20:27:40.761841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e90f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e63160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e63460>]}
[0m20:27:40.762813 [debug] [MainThread]: Flushing usage events
[0m20:27:41.070108 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2024-05-08 20:27:45.584930 | 8793986b-232a-4a09-9cb4-cb025d669755 ==============================
[0m20:27:45.584930 [info ] [MainThread]: Running with dbt=1.4.1
[0m20:27:45.586019 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/rana/TPM_dbt_poc/tenant_A', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'parse_only': False, 'which': 'compile', 'rpc_method': 'compile', 'indirect_selection': 'eager'}
[0m20:27:45.586141 [debug] [MainThread]: Tracking: tracking
[0m20:27:45.604013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b042130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b042d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b042790>]}
[0m20:27:45.646753 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 0 files changed.
[0m20:27:45.647009 [debug] [MainThread]: Partial parsing: deleted file: tenant_A://models/example/my_second_dbt_model.sql
[0m20:27:45.652364 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'my_second_dbt_model' in the 'models' section of file 'models/example/schema.yml'
[0m20:27:45.664340 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.tenant_A.unique_my_second_dbt_model_id.57a0f8c493' (models/example/schema.yml) depends on a node named 'my_second_dbt_model' in package '' which was not found
[0m20:27:45.664688 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.tenant_A.not_null_my_second_dbt_model_id.151b76d778' (models/example/schema.yml) depends on a node named 'my_second_dbt_model' in package '' which was not found
[0m20:27:45.672385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8793986b-232a-4a09-9cb4-cb025d669755', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1ec7f0>]}
[0m20:27:45.677745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8793986b-232a-4a09-9cb4-cb025d669755', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b161850>]}
[0m20:27:45.677989 [info ] [MainThread]: Found 21 models, 2 tests, 0 snapshots, 0 analyses, 335 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m20:27:45.678134 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8793986b-232a-4a09-9cb4-cb025d669755', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1acee0>]}
[0m20:27:45.679233 [info ] [MainThread]: 
[0m20:27:45.680136 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m20:27:45.681168 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_prj-s-telus-tpm-data-fcfc_tenant_A'
[0m20:27:45.681321 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:27:46.728877 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8793986b-232a-4a09-9cb4-cb025d669755', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afdc490>]}
[0m20:27:46.730135 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:27:46.730459 [info ] [MainThread]: 
[0m20:27:46.736163 [debug] [Thread-1  ]: Began running node model.anomaly_detection.raw_data
[0m20:27:46.737183 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.raw_data'
[0m20:27:46.737436 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.raw_data
[0m20:27:46.742942 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.raw_data"
[0m20:27:46.743905 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.raw_data (compile): 2024-05-08 20:27:46.737621 => 2024-05-08 20:27:46.743831
[0m20:27:46.744110 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.raw_data
[0m20:27:46.744268 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.raw_data (execute): 2024-05-08 20:27:46.744227 => 2024-05-08 20:27:46.744243
[0m20:27:46.745849 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.raw_data
[0m20:27:46.746509 [debug] [Thread-3  ]: Began running node model.anomaly_detection.aggregations
[0m20:27:46.747119 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.aggregations'
[0m20:27:46.747316 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.aggregations
[0m20:27:46.753894 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.aggregations"
[0m20:27:46.754758 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.aggregations (compile): 2024-05-08 20:27:46.747427 => 2024-05-08 20:27:46.754721
[0m20:27:46.754913 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.aggregations
[0m20:27:46.755034 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.aggregations (execute): 2024-05-08 20:27:46.755008 => 2024-05-08 20:27:46.755014
[0m20:27:46.755448 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.aggregations
[0m20:27:46.755890 [debug] [Thread-2  ]: Began running node model.anomaly_detection.cutoff_dates
[0m20:27:46.756263 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.cutoff_dates'
[0m20:27:46.756405 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.cutoff_dates
[0m20:27:46.759537 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.cutoff_dates"
[0m20:27:46.759953 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.cutoff_dates (compile): 2024-05-08 20:27:46.756509 => 2024-05-08 20:27:46.759911
[0m20:27:46.760103 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.cutoff_dates
[0m20:27:46.760224 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.cutoff_dates (execute): 2024-05-08 20:27:46.760197 => 2024-05-08 20:27:46.760203
[0m20:27:46.760602 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.cutoff_dates
[0m20:27:46.760889 [debug] [Thread-4  ]: Began running node model.anomaly_detection.aggregations_cutoff
[0m20:27:46.761262 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.aggregations_cutoff'
[0m20:27:46.761382 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.aggregations_cutoff
[0m20:27:46.763963 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.aggregations_cutoff"
[0m20:27:46.764423 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.aggregations_cutoff (compile): 2024-05-08 20:27:46.761462 => 2024-05-08 20:27:46.764396
[0m20:27:46.764551 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.aggregations_cutoff
[0m20:27:46.764655 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.aggregations_cutoff (execute): 2024-05-08 20:27:46.764632 => 2024-05-08 20:27:46.764637
[0m20:27:46.764996 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.aggregations_cutoff
[0m20:27:46.765283 [debug] [Thread-1  ]: Began running node model.anomaly_detection.nonrecent_events
[0m20:27:46.765457 [debug] [Thread-2  ]: Began running node model.anomaly_detection.train_data
[0m20:27:46.765786 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.nonrecent_events'
[0m20:27:46.766108 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.train_data'
[0m20:27:46.766246 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.nonrecent_events
[0m20:27:46.766370 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.train_data
[0m20:27:46.768811 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.nonrecent_events"
[0m20:27:46.770764 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.train_data"
[0m20:27:46.771376 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.train_data (compile): 2024-05-08 20:27:46.768944 => 2024-05-08 20:27:46.771349
[0m20:27:46.771467 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_events (compile): 2024-05-08 20:27:46.766462 => 2024-05-08 20:27:46.771442
[0m20:27:46.771585 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.train_data
[0m20:27:46.771700 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.nonrecent_events
[0m20:27:46.771800 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.train_data (execute): 2024-05-08 20:27:46.771779 => 2024-05-08 20:27:46.771784
[0m20:27:46.771897 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_events (execute): 2024-05-08 20:27:46.771877 => 2024-05-08 20:27:46.771880
[0m20:27:46.772219 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.train_data
[0m20:27:46.772552 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.nonrecent_events
[0m20:27:46.772774 [debug] [Thread-4  ]: Began running node model.anomaly_detection.IQR_quartiles
[0m20:27:46.773099 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_quartiles'
[0m20:27:46.773207 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.IQR_quartiles
[0m20:27:46.775364 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.IQR_quartiles"
[0m20:27:46.775654 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.IQR_quartiles (compile): 2024-05-08 20:27:46.773279 => 2024-05-08 20:27:46.775624
[0m20:27:46.775767 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.IQR_quartiles
[0m20:27:46.775869 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.IQR_quartiles (execute): 2024-05-08 20:27:46.775848 => 2024-05-08 20:27:46.775852
[0m20:27:46.776179 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.IQR_quartiles
[0m20:27:46.776419 [debug] [Thread-2  ]: Began running node model.anomaly_detection.IQR_bounds
[0m20:27:46.776734 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_bounds'
[0m20:27:46.776847 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.IQR_bounds
[0m20:27:46.779433 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.IQR_bounds"
[0m20:27:46.779726 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.IQR_bounds (compile): 2024-05-08 20:27:46.776922 => 2024-05-08 20:27:46.779695
[0m20:27:46.779843 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.IQR_bounds
[0m20:27:46.779941 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.IQR_bounds (execute): 2024-05-08 20:27:46.779920 => 2024-05-08 20:27:46.779924
[0m20:27:46.780245 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.IQR_bounds
[0m20:27:46.780470 [debug] [Thread-1  ]: Began running node model.anomaly_detection.IQR_outliers
[0m20:27:46.780756 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_outliers'
[0m20:27:46.780857 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.IQR_outliers
[0m20:27:46.783190 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.IQR_outliers"
[0m20:27:46.783630 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.IQR_outliers (compile): 2024-05-08 20:27:46.780924 => 2024-05-08 20:27:46.783603
[0m20:27:46.783734 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.IQR_outliers
[0m20:27:46.783821 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.IQR_outliers (execute): 2024-05-08 20:27:46.783802 => 2024-05-08 20:27:46.783806
[0m20:27:46.784112 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.IQR_outliers
[0m20:27:46.784332 [debug] [Thread-3  ]: Began running node model.anomaly_detection.forecasts
[0m20:27:46.784619 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.forecasts'
[0m20:27:46.784714 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.forecasts
[0m20:27:46.788712 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.forecasts"
[0m20:27:46.789162 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.forecasts (compile): 2024-05-08 20:27:46.784784 => 2024-05-08 20:27:46.789139
[0m20:27:46.789272 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.forecasts
[0m20:27:46.789360 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.forecasts (execute): 2024-05-08 20:27:46.789341 => 2024-05-08 20:27:46.789345
[0m20:27:46.789653 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.forecasts
[0m20:27:46.789882 [debug] [Thread-4  ]: Began running node model.anomaly_detection.reset_forecasts
[0m20:27:46.790164 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.reset_forecasts'
[0m20:27:46.790274 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.reset_forecasts
[0m20:27:46.792843 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.reset_forecasts"
[0m20:27:46.793822 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.reset_forecasts (compile): 2024-05-08 20:27:46.790342 => 2024-05-08 20:27:46.793801
[0m20:27:46.793927 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.reset_forecasts
[0m20:27:46.794014 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.reset_forecasts (execute): 2024-05-08 20:27:46.793995 => 2024-05-08 20:27:46.793999
[0m20:27:46.794295 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.reset_forecasts
[0m20:27:46.794549 [debug] [Thread-2  ]: Began running node model.anomaly_detection.all_configs
[0m20:27:46.794806 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.all_configs'
[0m20:27:46.794906 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.all_configs
[0m20:27:46.796679 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.all_configs"
[0m20:27:46.797053 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.all_configs (compile): 2024-05-08 20:27:46.794972 => 2024-05-08 20:27:46.797034
[0m20:27:46.797150 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.all_configs
[0m20:27:46.797232 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.all_configs (execute): 2024-05-08 20:27:46.797214 => 2024-05-08 20:27:46.797218
[0m20:27:46.797503 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.all_configs
[0m20:27:46.797711 [debug] [Thread-1  ]: Began running node model.anomaly_detection.nonrecent_configs
[0m20:27:46.797976 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.nonrecent_configs'
[0m20:27:46.798071 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.nonrecent_configs
[0m20:27:46.799867 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.nonrecent_configs"
[0m20:27:46.800455 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_configs (compile): 2024-05-08 20:27:46.798136 => 2024-05-08 20:27:46.800436
[0m20:27:46.800553 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.nonrecent_configs
[0m20:27:46.800634 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_configs (execute): 2024-05-08 20:27:46.800616 => 2024-05-08 20:27:46.800620
[0m20:27:46.800900 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.nonrecent_configs
[0m20:27:46.801108 [debug] [Thread-3  ]: Began running node model.anomaly_detection.filtered_nonrecent_configs
[0m20:27:46.801392 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.filtered_nonrecent_configs'
[0m20:27:46.801490 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.filtered_nonrecent_configs
[0m20:27:46.802907 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.filtered_nonrecent_configs"
[0m20:27:46.803399 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.filtered_nonrecent_configs (compile): 2024-05-08 20:27:46.801557 => 2024-05-08 20:27:46.803378
[0m20:27:46.803498 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.filtered_nonrecent_configs
[0m20:27:46.803577 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.filtered_nonrecent_configs (execute): 2024-05-08 20:27:46.803560 => 2024-05-08 20:27:46.803564
[0m20:27:46.803843 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.filtered_nonrecent_configs
[0m20:27:46.804075 [debug] [Thread-4  ]: Began running node model.anomaly_detection.min_anomalies
[0m20:27:46.804337 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.min_anomalies'
[0m20:27:46.804434 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.min_anomalies
[0m20:27:46.806058 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.min_anomalies"
[0m20:27:46.806294 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.min_anomalies (compile): 2024-05-08 20:27:46.804499 => 2024-05-08 20:27:46.806275
[0m20:27:46.806392 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.min_anomalies
[0m20:27:46.806473 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.min_anomalies (execute): 2024-05-08 20:27:46.806455 => 2024-05-08 20:27:46.806458
[0m20:27:46.806741 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.min_anomalies
[0m20:27:46.806944 [debug] [Thread-2  ]: Began running node model.anomaly_detection.min_anomalies_configs
[0m20:27:46.807214 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.min_anomalies_configs'
[0m20:27:46.807310 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.min_anomalies_configs
[0m20:27:46.809145 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.min_anomalies_configs"
[0m20:27:46.809390 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.min_anomalies_configs (compile): 2024-05-08 20:27:46.807374 => 2024-05-08 20:27:46.809371
[0m20:27:46.809494 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.min_anomalies_configs
[0m20:27:46.809582 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.min_anomalies_configs (execute): 2024-05-08 20:27:46.809563 => 2024-05-08 20:27:46.809567
[0m20:27:46.809859 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.min_anomalies_configs
[0m20:27:46.810068 [debug] [Thread-1  ]: Began running node model.anomaly_detection.min_RMSD
[0m20:27:46.810333 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.min_RMSD'
[0m20:27:46.810432 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.min_RMSD
[0m20:27:46.812119 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.min_RMSD"
[0m20:27:46.812340 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.min_RMSD (compile): 2024-05-08 20:27:46.810498 => 2024-05-08 20:27:46.812321
[0m20:27:46.812438 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.min_RMSD
[0m20:27:46.812521 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.min_RMSD (execute): 2024-05-08 20:27:46.812504 => 2024-05-08 20:27:46.812507
[0m20:27:46.812788 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.min_RMSD
[0m20:27:46.812990 [debug] [Thread-3  ]: Began running node model.anomaly_detection.control_table
[0m20:27:46.813261 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.control_table'
[0m20:27:46.813357 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.control_table
[0m20:27:46.815186 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.control_table"
[0m20:27:46.815472 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.control_table (compile): 2024-05-08 20:27:46.813421 => 2024-05-08 20:27:46.815450
[0m20:27:46.815573 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.control_table
[0m20:27:46.815653 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.control_table (execute): 2024-05-08 20:27:46.815636 => 2024-05-08 20:27:46.815640
[0m20:27:46.815919 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.control_table
[0m20:27:46.816135 [debug] [Thread-4  ]: Began running node model.anomaly_detection.alerting_base
[0m20:27:46.816264 [debug] [Thread-1  ]: Began running node model.tenant_A.my_first_dbt_model
[0m20:27:46.816514 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.alerting_base'
[0m20:27:46.816748 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.tenant_A.my_first_dbt_model'
[0m20:27:46.816851 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.alerting_base
[0m20:27:46.816943 [debug] [Thread-1  ]: Began compiling node model.tenant_A.my_first_dbt_model
[0m20:27:46.819063 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.alerting_base"
[0m20:27:46.821034 [debug] [Thread-1  ]: Writing injected SQL for node "model.tenant_A.my_first_dbt_model"
[0m20:27:46.821349 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.alerting_base (compile): 2024-05-08 20:27:46.817010 => 2024-05-08 20:27:46.821328
[0m20:27:46.821424 [debug] [Thread-1  ]: Timing info for model.tenant_A.my_first_dbt_model (compile): 2024-05-08 20:27:46.819148 => 2024-05-08 20:27:46.821405
[0m20:27:46.821522 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.alerting_base
[0m20:27:46.821618 [debug] [Thread-1  ]: Began executing node model.tenant_A.my_first_dbt_model
[0m20:27:46.821701 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.alerting_base (execute): 2024-05-08 20:27:46.821684 => 2024-05-08 20:27:46.821688
[0m20:27:46.821789 [debug] [Thread-1  ]: Timing info for model.tenant_A.my_first_dbt_model (execute): 2024-05-08 20:27:46.821771 => 2024-05-08 20:27:46.821774
[0m20:27:46.822060 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.alerting_base
[0m20:27:46.822328 [debug] [Thread-1  ]: Finished running node model.tenant_A.my_first_dbt_model
[0m20:27:46.822522 [debug] [Thread-3  ]: Began running node model.anomaly_detection.daily_alerts
[0m20:27:46.822882 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.daily_alerts'
[0m20:27:46.822990 [debug] [Thread-4  ]: Began running node test.tenant_A.not_null_my_first_dbt_model_id.5fb22c2710
[0m20:27:46.823087 [debug] [Thread-2  ]: Began running node test.tenant_A.unique_my_first_dbt_model_id.16e066b321
[0m20:27:46.823183 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.daily_alerts
[0m20:27:46.823405 [debug] [Thread-4  ]: Acquiring new bigquery connection 'test.tenant_A.not_null_my_first_dbt_model_id.5fb22c2710'
[0m20:27:46.823638 [debug] [Thread-2  ]: Acquiring new bigquery connection 'test.tenant_A.unique_my_first_dbt_model_id.16e066b321'
[0m20:27:46.825239 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.daily_alerts"
[0m20:27:46.825356 [debug] [Thread-4  ]: Began compiling node test.tenant_A.not_null_my_first_dbt_model_id.5fb22c2710
[0m20:27:46.825461 [debug] [Thread-2  ]: Began compiling node test.tenant_A.unique_my_first_dbt_model_id.16e066b321
[0m20:27:46.831547 [debug] [Thread-4  ]: Writing injected SQL for node "test.tenant_A.not_null_my_first_dbt_model_id.5fb22c2710"
[0m20:27:46.834581 [debug] [Thread-2  ]: Writing injected SQL for node "test.tenant_A.unique_my_first_dbt_model_id.16e066b321"
[0m20:27:46.834767 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.daily_alerts (compile): 2024-05-08 20:27:46.823706 => 2024-05-08 20:27:46.834742
[0m20:27:46.834928 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.daily_alerts
[0m20:27:46.835048 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.daily_alerts (execute): 2024-05-08 20:27:46.835027 => 2024-05-08 20:27:46.835033
[0m20:27:46.835128 [debug] [Thread-4  ]: Timing info for test.tenant_A.not_null_my_first_dbt_model_id.5fb22c2710 (compile): 2024-05-08 20:27:46.825575 => 2024-05-08 20:27:46.835108
[0m20:27:46.835210 [debug] [Thread-2  ]: Timing info for test.tenant_A.unique_my_first_dbt_model_id.16e066b321 (compile): 2024-05-08 20:27:46.831668 => 2024-05-08 20:27:46.835195
[0m20:27:46.835512 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.daily_alerts
[0m20:27:46.835624 [debug] [Thread-4  ]: Began executing node test.tenant_A.not_null_my_first_dbt_model_id.5fb22c2710
[0m20:27:46.835720 [debug] [Thread-2  ]: Began executing node test.tenant_A.unique_my_first_dbt_model_id.16e066b321
[0m20:27:46.835864 [debug] [Thread-4  ]: Timing info for test.tenant_A.not_null_my_first_dbt_model_id.5fb22c2710 (execute): 2024-05-08 20:27:46.835844 => 2024-05-08 20:27:46.835848
[0m20:27:46.835951 [debug] [Thread-2  ]: Timing info for test.tenant_A.unique_my_first_dbt_model_id.16e066b321 (execute): 2024-05-08 20:27:46.835933 => 2024-05-08 20:27:46.835936
[0m20:27:46.836221 [debug] [Thread-4  ]: Finished running node test.tenant_A.not_null_my_first_dbt_model_id.5fb22c2710
[0m20:27:46.836495 [debug] [Thread-2  ]: Finished running node test.tenant_A.unique_my_first_dbt_model_id.16e066b321
[0m20:27:46.836996 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:27:46.837083 [debug] [MainThread]: Connection 'model.tenant_A.my_first_dbt_model' was properly closed.
[0m20:27:46.837152 [debug] [MainThread]: Connection 'model.anomaly_detection.daily_alerts' was properly closed.
[0m20:27:46.837216 [debug] [MainThread]: Connection 'test.tenant_A.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m20:27:46.837285 [debug] [MainThread]: Connection 'test.tenant_A.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
[0m20:27:46.837793 [debug] [MainThread]: Command end result
[0m20:27:46.842326 [info ] [MainThread]: Done.
[0m20:27:46.842548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b06e6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b03cb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3219a0>]}
[0m20:27:46.842695 [debug] [MainThread]: Flushing usage events


============================== 2024-05-08 20:28:13.058070 | 1e0a3b9b-8775-461e-a06d-0a656ca7f424 ==============================
[0m20:28:13.058070 [info ] [MainThread]: Running with dbt=1.4.1
[0m20:28:13.059499 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/rana/TPM_dbt_poc/tenant_A', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'parse_only': False, 'which': 'compile', 'rpc_method': 'compile', 'indirect_selection': 'eager'}
[0m20:28:13.059691 [debug] [MainThread]: Tracking: tracking
[0m20:28:13.075267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109922100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109922e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109922a00>]}
[0m20:28:13.115933 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 0 files changed.
[0m20:28:13.125493 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m20:28:13.137857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1e0a3b9b-8775-461e-a06d-0a656ca7f424', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b4c0d0>]}
[0m20:28:13.143695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1e0a3b9b-8775-461e-a06d-0a656ca7f424', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b09e20>]}
[0m20:28:13.143894 [info ] [MainThread]: Found 21 models, 0 tests, 0 snapshots, 0 analyses, 335 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m20:28:13.144039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e0a3b9b-8775-461e-a06d-0a656ca7f424', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b09ee0>]}
[0m20:28:13.145056 [info ] [MainThread]: 
[0m20:28:13.145935 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m20:28:13.147027 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_prj-s-telus-tpm-data-fcfc_tenant_A'
[0m20:28:13.147245 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:28:14.308225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e0a3b9b-8775-461e-a06d-0a656ca7f424', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b09ee0>]}
[0m20:28:14.308777 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:28:14.308946 [info ] [MainThread]: 
[0m20:28:14.311566 [debug] [Thread-1  ]: Began running node model.anomaly_detection.raw_data
[0m20:28:14.312005 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.raw_data'
[0m20:28:14.312307 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.raw_data
[0m20:28:14.318229 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.raw_data"
[0m20:28:14.319102 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.raw_data (compile): 2024-05-08 20:28:14.312450 => 2024-05-08 20:28:14.319030
[0m20:28:14.319297 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.raw_data
[0m20:28:14.319408 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.raw_data (execute): 2024-05-08 20:28:14.319378 => 2024-05-08 20:28:14.319391
[0m20:28:14.320496 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.raw_data
[0m20:28:14.321059 [debug] [Thread-3  ]: Began running node model.anomaly_detection.aggregations
[0m20:28:14.321451 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.aggregations'
[0m20:28:14.321578 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.aggregations
[0m20:28:14.325160 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.aggregations"
[0m20:28:14.325599 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.aggregations (compile): 2024-05-08 20:28:14.321653 => 2024-05-08 20:28:14.325563
[0m20:28:14.325728 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.aggregations
[0m20:28:14.325819 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.aggregations (execute): 2024-05-08 20:28:14.325798 => 2024-05-08 20:28:14.325804
[0m20:28:14.326136 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.aggregations
[0m20:28:14.326444 [debug] [Thread-2  ]: Began running node model.anomaly_detection.cutoff_dates
[0m20:28:14.326769 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.cutoff_dates'
[0m20:28:14.326870 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.cutoff_dates
[0m20:28:14.328720 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.cutoff_dates"
[0m20:28:14.328997 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.cutoff_dates (compile): 2024-05-08 20:28:14.326934 => 2024-05-08 20:28:14.328968
[0m20:28:14.329120 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.cutoff_dates
[0m20:28:14.329211 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.cutoff_dates (execute): 2024-05-08 20:28:14.329192 => 2024-05-08 20:28:14.329196
[0m20:28:14.329523 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.cutoff_dates
[0m20:28:14.329765 [debug] [Thread-4  ]: Began running node model.anomaly_detection.aggregations_cutoff
[0m20:28:14.330113 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.aggregations_cutoff'
[0m20:28:14.330231 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.aggregations_cutoff
[0m20:28:14.334011 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.aggregations_cutoff"
[0m20:28:14.334340 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.aggregations_cutoff (compile): 2024-05-08 20:28:14.330302 => 2024-05-08 20:28:14.334306
[0m20:28:14.334453 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.aggregations_cutoff
[0m20:28:14.334544 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.aggregations_cutoff (execute): 2024-05-08 20:28:14.334523 => 2024-05-08 20:28:14.334528
[0m20:28:14.334841 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.aggregations_cutoff
[0m20:28:14.335113 [debug] [Thread-1  ]: Began running node model.anomaly_detection.nonrecent_events
[0m20:28:14.335221 [debug] [Thread-2  ]: Began running node model.anomaly_detection.train_data
[0m20:28:14.335498 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.nonrecent_events'
[0m20:28:14.335761 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.train_data'
[0m20:28:14.335877 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.nonrecent_events
[0m20:28:14.335980 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.train_data
[0m20:28:14.338333 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.nonrecent_events"
[0m20:28:14.339951 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.train_data"
[0m20:28:14.340274 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.train_data (compile): 2024-05-08 20:28:14.338448 => 2024-05-08 20:28:14.340249
[0m20:28:14.340358 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_events (compile): 2024-05-08 20:28:14.336055 => 2024-05-08 20:28:14.340337
[0m20:28:14.340470 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.train_data
[0m20:28:14.340572 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.nonrecent_events
[0m20:28:14.340661 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.train_data (execute): 2024-05-08 20:28:14.340643 => 2024-05-08 20:28:14.340647
[0m20:28:14.340757 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_events (execute): 2024-05-08 20:28:14.340739 => 2024-05-08 20:28:14.340742
[0m20:28:14.341065 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.train_data
[0m20:28:14.341397 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.nonrecent_events
[0m20:28:14.341666 [debug] [Thread-4  ]: Began running node model.anomaly_detection.IQR_quartiles
[0m20:28:14.341942 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_quartiles'
[0m20:28:14.342042 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.IQR_quartiles
[0m20:28:14.344025 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.IQR_quartiles"
[0m20:28:14.344459 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.IQR_quartiles (compile): 2024-05-08 20:28:14.342110 => 2024-05-08 20:28:14.344436
[0m20:28:14.344575 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.IQR_quartiles
[0m20:28:14.344663 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.IQR_quartiles (execute): 2024-05-08 20:28:14.344644 => 2024-05-08 20:28:14.344648
[0m20:28:14.344949 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.IQR_quartiles
[0m20:28:14.345209 [debug] [Thread-2  ]: Began running node model.anomaly_detection.IQR_bounds
[0m20:28:14.345488 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_bounds'
[0m20:28:14.345591 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.IQR_bounds
[0m20:28:14.347903 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.IQR_bounds"
[0m20:28:14.348167 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.IQR_bounds (compile): 2024-05-08 20:28:14.345661 => 2024-05-08 20:28:14.348145
[0m20:28:14.348274 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.IQR_bounds
[0m20:28:14.348360 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.IQR_bounds (execute): 2024-05-08 20:28:14.348342 => 2024-05-08 20:28:14.348346
[0m20:28:14.348639 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.IQR_bounds
[0m20:28:14.348871 [debug] [Thread-3  ]: Began running node model.anomaly_detection.IQR_outliers
[0m20:28:14.349161 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_outliers'
[0m20:28:14.349262 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.IQR_outliers
[0m20:28:14.351569 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.IQR_outliers"
[0m20:28:14.351845 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.IQR_outliers (compile): 2024-05-08 20:28:14.349332 => 2024-05-08 20:28:14.351821
[0m20:28:14.351953 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.IQR_outliers
[0m20:28:14.352036 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.IQR_outliers (execute): 2024-05-08 20:28:14.352018 => 2024-05-08 20:28:14.352022
[0m20:28:14.352324 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.IQR_outliers
[0m20:28:14.352548 [debug] [Thread-1  ]: Began running node model.anomaly_detection.forecasts
[0m20:28:14.352828 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.forecasts'
[0m20:28:14.352925 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.forecasts
[0m20:28:14.356738 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.forecasts"
[0m20:28:14.357411 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.forecasts (compile): 2024-05-08 20:28:14.352989 => 2024-05-08 20:28:14.357388
[0m20:28:14.357521 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.forecasts
[0m20:28:14.357611 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.forecasts (execute): 2024-05-08 20:28:14.357592 => 2024-05-08 20:28:14.357596
[0m20:28:14.357904 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.forecasts
[0m20:28:14.358157 [debug] [Thread-4  ]: Began running node model.anomaly_detection.reset_forecasts
[0m20:28:14.358428 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.reset_forecasts'
[0m20:28:14.358530 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.reset_forecasts
[0m20:28:14.360477 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.reset_forecasts"
[0m20:28:14.360727 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.reset_forecasts (compile): 2024-05-08 20:28:14.358594 => 2024-05-08 20:28:14.360706
[0m20:28:14.360850 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.reset_forecasts
[0m20:28:14.360936 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.reset_forecasts (execute): 2024-05-08 20:28:14.360917 => 2024-05-08 20:28:14.360921
[0m20:28:14.361210 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.reset_forecasts
[0m20:28:14.361459 [debug] [Thread-2  ]: Began running node model.anomaly_detection.all_configs
[0m20:28:14.361731 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.all_configs'
[0m20:28:14.361828 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.all_configs
[0m20:28:14.363635 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.all_configs"
[0m20:28:14.363951 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.all_configs (compile): 2024-05-08 20:28:14.361899 => 2024-05-08 20:28:14.363922
[0m20:28:14.364056 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.all_configs
[0m20:28:14.364144 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.all_configs (execute): 2024-05-08 20:28:14.364124 => 2024-05-08 20:28:14.364128
[0m20:28:14.364428 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.all_configs
[0m20:28:14.364708 [debug] [Thread-3  ]: Began running node model.anomaly_detection.nonrecent_configs
[0m20:28:14.364972 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.nonrecent_configs'
[0m20:28:14.365068 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.nonrecent_configs
[0m20:28:14.367719 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.nonrecent_configs"
[0m20:28:14.368021 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.nonrecent_configs (compile): 2024-05-08 20:28:14.365131 => 2024-05-08 20:28:14.367997
[0m20:28:14.368131 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.nonrecent_configs
[0m20:28:14.368216 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.nonrecent_configs (execute): 2024-05-08 20:28:14.368198 => 2024-05-08 20:28:14.368202
[0m20:28:14.368503 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.nonrecent_configs
[0m20:28:14.368744 [debug] [Thread-1  ]: Began running node model.anomaly_detection.filtered_nonrecent_configs
[0m20:28:14.368996 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.filtered_nonrecent_configs'
[0m20:28:14.369092 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.filtered_nonrecent_configs
[0m20:28:14.370560 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.filtered_nonrecent_configs"
[0m20:28:14.370812 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.filtered_nonrecent_configs (compile): 2024-05-08 20:28:14.369162 => 2024-05-08 20:28:14.370791
[0m20:28:14.370915 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.filtered_nonrecent_configs
[0m20:28:14.371000 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.filtered_nonrecent_configs (execute): 2024-05-08 20:28:14.370982 => 2024-05-08 20:28:14.370985
[0m20:28:14.371281 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.filtered_nonrecent_configs
[0m20:28:14.371523 [debug] [Thread-4  ]: Began running node model.anomaly_detection.min_anomalies
[0m20:28:14.371791 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.min_anomalies'
[0m20:28:14.371888 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.min_anomalies
[0m20:28:14.373622 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.min_anomalies"
[0m20:28:14.373903 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.min_anomalies (compile): 2024-05-08 20:28:14.371953 => 2024-05-08 20:28:14.373882
[0m20:28:14.374022 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.min_anomalies
[0m20:28:14.374115 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.min_anomalies (execute): 2024-05-08 20:28:14.374097 => 2024-05-08 20:28:14.374100
[0m20:28:14.374400 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.min_anomalies
[0m20:28:14.374629 [debug] [Thread-2  ]: Began running node model.anomaly_detection.min_anomalies_configs
[0m20:28:14.374935 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.min_anomalies_configs'
[0m20:28:14.375035 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.min_anomalies_configs
[0m20:28:14.377031 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.min_anomalies_configs"
[0m20:28:14.377315 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.min_anomalies_configs (compile): 2024-05-08 20:28:14.375098 => 2024-05-08 20:28:14.377281
[0m20:28:14.377420 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.min_anomalies_configs
[0m20:28:14.377505 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.min_anomalies_configs (execute): 2024-05-08 20:28:14.377486 => 2024-05-08 20:28:14.377490
[0m20:28:14.377785 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.min_anomalies_configs
[0m20:28:14.378002 [debug] [Thread-3  ]: Began running node model.anomaly_detection.min_RMSD
[0m20:28:14.378305 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.min_RMSD'
[0m20:28:14.378418 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.min_RMSD
[0m20:28:14.380206 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.min_RMSD"
[0m20:28:14.380471 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.min_RMSD (compile): 2024-05-08 20:28:14.378496 => 2024-05-08 20:28:14.380449
[0m20:28:14.380572 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.min_RMSD
[0m20:28:14.380654 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.min_RMSD (execute): 2024-05-08 20:28:14.380637 => 2024-05-08 20:28:14.380640
[0m20:28:14.380943 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.min_RMSD
[0m20:28:14.381161 [debug] [Thread-1  ]: Began running node model.anomaly_detection.control_table
[0m20:28:14.381429 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.control_table'
[0m20:28:14.381521 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.control_table
[0m20:28:14.383465 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.control_table"
[0m20:28:14.383732 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.control_table (compile): 2024-05-08 20:28:14.381583 => 2024-05-08 20:28:14.383705
[0m20:28:14.383851 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.control_table
[0m20:28:14.383937 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.control_table (execute): 2024-05-08 20:28:14.383918 => 2024-05-08 20:28:14.383922
[0m20:28:14.384232 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.control_table
[0m20:28:14.384477 [debug] [Thread-4  ]: Began running node model.anomaly_detection.alerting_base
[0m20:28:14.384604 [debug] [Thread-3  ]: Began running node model.tenant_A.my_first_dbt_model
[0m20:28:14.384870 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.alerting_base'
[0m20:28:14.385126 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.tenant_A.my_first_dbt_model'
[0m20:28:14.385247 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.alerting_base
[0m20:28:14.385352 [debug] [Thread-3  ]: Began compiling node model.tenant_A.my_first_dbt_model
[0m20:28:14.387676 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.alerting_base"
[0m20:28:14.389102 [debug] [Thread-3  ]: Writing injected SQL for node "model.tenant_A.my_first_dbt_model"
[0m20:28:14.389468 [debug] [Thread-3  ]: Timing info for model.tenant_A.my_first_dbt_model (compile): 2024-05-08 20:28:14.387799 => 2024-05-08 20:28:14.389437
[0m20:28:14.389550 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.alerting_base (compile): 2024-05-08 20:28:14.385427 => 2024-05-08 20:28:14.389530
[0m20:28:14.389658 [debug] [Thread-3  ]: Began executing node model.tenant_A.my_first_dbt_model
[0m20:28:14.389760 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.alerting_base
[0m20:28:14.389850 [debug] [Thread-3  ]: Timing info for model.tenant_A.my_first_dbt_model (execute): 2024-05-08 20:28:14.389831 => 2024-05-08 20:28:14.389835
[0m20:28:14.389936 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.alerting_base (execute): 2024-05-08 20:28:14.389918 => 2024-05-08 20:28:14.389921
[0m20:28:14.390225 [debug] [Thread-3  ]: Finished running node model.tenant_A.my_first_dbt_model
[0m20:28:14.390498 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.alerting_base
[0m20:28:14.390775 [debug] [Thread-1  ]: Began running node model.anomaly_detection.daily_alerts
[0m20:28:14.391059 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.daily_alerts'
[0m20:28:14.391161 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.daily_alerts
[0m20:28:14.392787 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.daily_alerts"
[0m20:28:14.393030 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.daily_alerts (compile): 2024-05-08 20:28:14.391229 => 2024-05-08 20:28:14.393006
[0m20:28:14.393131 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.daily_alerts
[0m20:28:14.393211 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.daily_alerts (execute): 2024-05-08 20:28:14.393193 => 2024-05-08 20:28:14.393197
[0m20:28:14.393476 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.daily_alerts
[0m20:28:14.393921 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:28:14.394022 [debug] [MainThread]: Connection 'model.anomaly_detection.daily_alerts' was properly closed.
[0m20:28:14.394093 [debug] [MainThread]: Connection 'model.tenant_A.my_first_dbt_model' was properly closed.
[0m20:28:14.394156 [debug] [MainThread]: Connection 'model.anomaly_detection.min_anomalies_configs' was properly closed.
[0m20:28:14.394216 [debug] [MainThread]: Connection 'model.anomaly_detection.alerting_base' was properly closed.
[0m20:28:14.394706 [debug] [MainThread]: Command end result
[0m20:28:14.399250 [info ] [MainThread]: Done.
[0m20:28:14.399459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b09fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b121c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b12220>]}
[0m20:28:14.399621 [debug] [MainThread]: Flushing usage events


============================== 2024-05-08 20:28:51.490967 | 18f4dfce-cc12-443a-b4a9-f4e7353e12ba ==============================
[0m20:28:51.490967 [info ] [MainThread]: Running with dbt=1.4.1
[0m20:28:51.491774 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/rana/TPM_dbt_poc/tenant_A', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'deps', 'rpc_method': 'deps', 'indirect_selection': 'eager'}
[0m20:28:51.491892 [debug] [MainThread]: Tracking: tracking
[0m20:28:51.509491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c185e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c90ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c90cd0>]}
[0m20:28:51.511601 [debug] [MainThread]: Set downloads directory='/var/folders/2b/s3pxyycs63s1dl1mn2p9mnq40000gn/T/dbt-downloads-4cczkyns'
[0m20:28:51.522367 [info ] [MainThread]: Installing /Users/rana/TPM_dbt_poc/anomaly_detection
[0m20:28:51.523605 [debug] [MainThread]:   Creating symlink to local dependency.
[0m20:28:51.523777 [info ] [MainThread]:   Installed from <local @ /Users/rana/TPM_dbt_poc/anomaly_detection>
[0m20:28:51.523945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '18f4dfce-cc12-443a-b4a9-f4e7353e12ba', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cafb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cafca0>]}
[0m20:28:51.524579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c83730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c18bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108caffa0>]}
[0m20:28:51.524819 [debug] [MainThread]: Flushing usage events


============================== 2024-05-08 20:28:56.054660 | c12cdcef-a408-4f5f-84b9-16f0e56cda8b ==============================
[0m20:28:56.054660 [info ] [MainThread]: Running with dbt=1.4.1
[0m20:28:56.055763 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/rana/TPM_dbt_poc/tenant_A', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m20:28:56.055895 [debug] [MainThread]: Tracking: tracking
[0m20:28:56.072321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121182130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121182fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121182610>]}
[0m20:28:56.091260 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m20:28:56.091512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121176a00>]}
[0m20:28:56.421344 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m20:28:56.435132 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/min_anomalies.sql
[0m20:28:56.438123 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/min_anomalies.sql
[0m20:28:56.438915 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/aggregations_cutoff.sql
[0m20:28:56.442734 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/aggregations_cutoff.sql
[0m20:28:56.443486 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/IQR_outliers.sql
[0m20:28:56.446839 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/IQR_outliers.sql
[0m20:28:56.447674 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/cutoff_dates.sql
[0m20:28:56.450425 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/cutoff_dates.sql
[0m20:28:56.451129 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/min_RMSD.sql
[0m20:28:56.453989 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/min_RMSD.sql
[0m20:28:56.454721 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/forecasts.sql
[0m20:28:56.459185 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/forecasts.sql
[0m20:28:56.459888 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/IQR_quartiles.sql
[0m20:28:56.462754 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/IQR_quartiles.sql
[0m20:28:56.463474 [debug] [MainThread]: 1699: static parser successfully parsed anomaly_detection/filtered_nonrecent_configs.sql
[0m20:28:56.465203 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/control_table.sql
[0m20:28:56.468033 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/control_table.sql
[0m20:28:56.468760 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/alerting_base.sql
[0m20:28:56.472742 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/alerting_base.sql
[0m20:28:56.473450 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/daily_alerts.sql
[0m20:28:56.475902 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/daily_alerts.sql
[0m20:28:56.476525 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/train_data.sql
[0m20:28:56.479042 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/train_data.sql
[0m20:28:56.479766 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/nonrecent_configs.sql
[0m20:28:56.482726 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/nonrecent_configs.sql
[0m20:28:56.483414 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/aggregations.sql
[0m20:28:56.487190 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/aggregations.sql
[0m20:28:56.487891 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/IQR_bounds.sql
[0m20:28:56.490961 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/IQR_bounds.sql
[0m20:28:56.491868 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/raw_data.sql
[0m20:28:56.495134 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/raw_data.sql
[0m20:28:56.495859 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/all_configs.sql
[0m20:28:56.498795 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/all_configs.sql
[0m20:28:56.499509 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/nonrecent_events.sql
[0m20:28:56.503118 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/nonrecent_events.sql
[0m20:28:56.503856 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/min_anomalies_configs.sql
[0m20:28:56.506813 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/min_anomalies_configs.sql
[0m20:28:56.507501 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/reset_forecasts.sql
[0m20:28:56.510527 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/reset_forecasts.sql
[0m20:28:56.536566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1213289a0>]}
[0m20:28:56.541198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1211adaf0>]}
[0m20:28:56.541377 [info ] [MainThread]: Found 21 models, 0 tests, 0 snapshots, 0 analyses, 335 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m20:28:56.541520 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121176e80>]}
[0m20:28:56.542499 [info ] [MainThread]: 
[0m20:28:56.543375 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m20:28:56.544483 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_prj-s-telus-tpm-data-fcfc'
[0m20:28:56.544724 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:28:57.909414 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_prj-s-telus-tpm-data-fcfc_tenant_A'
[0m20:28:57.910222 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:28:58.212686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121176e80>]}
[0m20:28:58.214233 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:28:58.214630 [info ] [MainThread]: 
[0m20:28:58.221072 [debug] [Thread-1  ]: Began running node model.anomaly_detection.raw_data
[0m20:28:58.221685 [info ] [Thread-1  ]: 1 of 21 START sql table model tenant_A.raw_data ................................ [RUN]
[0m20:28:58.222389 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.raw_data'
[0m20:28:58.222601 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.raw_data
[0m20:28:58.228364 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.raw_data"
[0m20:28:58.229084 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.raw_data (compile): 2024-05-08 20:28:58.222770 => 2024-05-08 20:28:58.229011
[0m20:28:58.229286 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.raw_data
[0m20:28:58.245772 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:28:58.576455 [debug] [Thread-1  ]: Writing runtime sql for node "model.anomaly_detection.raw_data"
[0m20:28:58.580438 [debug] [Thread-1  ]: On model.anomaly_detection.raw_data: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.raw_data"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`raw_data`
    
    
    OPTIONS()
    as (
      
SELECT collector_tstamp, event_id, app_event
FROM `prj-s-telus-tpm-data-fcfc`.`dbt_rhashemi`.`sample_table_final`
WHERE DATE( collector_tstamp ) >= DATE_SUB("2023-02-09", INTERVAL 90 DAY) AND DATE( collector_tstamp ) < "2023-02-09"
    );
  
[0m20:29:10.485444 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:901ceab7-0539-491f-89bc-5dbc0a1cca59&page=queryresults
[0m20:29:10.507242 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.raw_data (execute): 2024-05-08 20:28:58.229397 => 2024-05-08 20:29:10.507151
[0m20:29:10.508078 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122013520>]}
[0m20:29:10.508566 [info ] [Thread-1  ]: 1 of 21 OK created sql table model tenant_A.raw_data ........................... [[32mCREATE TABLE (1.1m rows, 76.0 MB processed)[0m in 12.29s]
[0m20:29:10.510027 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.raw_data
[0m20:29:10.510724 [debug] [Thread-3  ]: Began running node model.anomaly_detection.aggregations
[0m20:29:10.511367 [info ] [Thread-3  ]: 2 of 21 START sql table model tenant_A.aggregations ............................ [RUN]
[0m20:29:10.512276 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.aggregations'
[0m20:29:10.512532 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.aggregations
[0m20:29:10.518633 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.aggregations"
[0m20:29:10.519556 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.aggregations (compile): 2024-05-08 20:29:10.512672 => 2024-05-08 20:29:10.519504
[0m20:29:10.519746 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.aggregations
[0m20:29:10.521531 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m20:29:10.804977 [debug] [Thread-3  ]: Writing runtime sql for node "model.anomaly_detection.aggregations"
[0m20:29:10.808122 [debug] [Thread-3  ]: On model.anomaly_detection.aggregations: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.aggregations"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`aggregations`
    
    
    OPTIONS()
    as (
      



    SELECT "4hr" AS agg_tag,
        PARSE_TIMESTAMP("%F %H", CONCAT(date_trunc, ' ', CAST(_4hr_trunc AS STRING))) AS time_stamps,
        app_event,
        event_count
    FROM (
        SELECT FORMAT_TIMESTAMP("%F", collector_tstamp) AS date_trunc,
        FLOOR(CAST(FORMAT_TIMESTAMP("%H", collector_tstamp) AS INT64)/4)*4 AS _4hr_trunc,
        app_event,
        COUNT(event_id) AS event_count
        FROM `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`raw_data`
        GROUP BY
        date_trunc,
        _4hr_trunc,
        app_event
    )


    
    UNION ALL
    


    SELECT "8hr" AS agg_tag,
        PARSE_TIMESTAMP("%F %H", CONCAT(date_trunc, ' ', CAST(_8hr_trunc AS STRING))) AS time_stamps,
        app_event,
        event_count
    FROM (
        SELECT FORMAT_TIMESTAMP("%F", collector_tstamp) AS date_trunc,
        FLOOR(CAST(FORMAT_TIMESTAMP("%H", collector_tstamp) AS INT64)/8)*8 AS _8hr_trunc,
        app_event,
        COUNT(event_id) AS event_count
        FROM `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`raw_data`
        GROUP BY
        date_trunc,
        _8hr_trunc,
        app_event
    )


    
    UNION ALL
    


    SELECT "12hr" AS agg_tag,
        PARSE_TIMESTAMP("%F %H", CONCAT(date_trunc, ' ', CAST(_12hr_trunc AS STRING))) AS time_stamps,
        app_event,
        event_count
    FROM (
        SELECT FORMAT_TIMESTAMP("%F", collector_tstamp) AS date_trunc,
        FLOOR(CAST(FORMAT_TIMESTAMP("%H", collector_tstamp) AS INT64)/12)*12 AS _12hr_trunc,
        app_event,
        COUNT(event_id) AS event_count
        FROM `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`raw_data`
        GROUP BY
        date_trunc,
        _12hr_trunc,
        app_event
    )


    
    UNION ALL
    


    SELECT "24hr" AS agg_tag,
        PARSE_TIMESTAMP("%F %H", CONCAT(date_trunc, ' ', CAST(_24hr_trunc AS STRING))) AS time_stamps,
        app_event,
        event_count
    FROM (
        SELECT FORMAT_TIMESTAMP("%F", collector_tstamp) AS date_trunc,
        FLOOR(CAST(FORMAT_TIMESTAMP("%H", collector_tstamp) AS INT64)/24)*24 AS _24hr_trunc,
        app_event,
        COUNT(event_id) AS event_count
        FROM `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`raw_data`
        GROUP BY
        date_trunc,
        _24hr_trunc,
        app_event
    )


    

    ORDER BY
    agg_tag,
    time_stamps,
    app_event




    );
  
[0m20:29:14.730857 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:0d874ef4-1ce9-4f79-b089-6d148e89f479&page=queryresults
[0m20:29:14.735054 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.aggregations (execute): 2024-05-08 20:29:10.519862 => 2024-05-08 20:29:14.734963
[0m20:29:14.736024 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1213ac6d0>]}
[0m20:29:14.736599 [info ] [Thread-3  ]: 2 of 21 OK created sql table model tenant_A.aggregations ....................... [[32mCREATE TABLE (2.2k rows, 76.0 MB processed)[0m in 4.22s]
[0m20:29:14.737246 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.aggregations
[0m20:29:14.738535 [debug] [Thread-2  ]: Began running node model.anomaly_detection.cutoff_dates
[0m20:29:14.739098 [info ] [Thread-2  ]: 3 of 21 START sql table model tenant_A.cutoff_dates ............................ [RUN]
[0m20:29:14.739889 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.cutoff_dates'
[0m20:29:14.740153 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.cutoff_dates
[0m20:29:14.745150 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.cutoff_dates"
[0m20:29:14.745902 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.cutoff_dates (compile): 2024-05-08 20:29:14.740339 => 2024-05-08 20:29:14.745851
[0m20:29:14.746150 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.cutoff_dates
[0m20:29:14.748232 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m20:29:15.032095 [debug] [Thread-2  ]: Writing runtime sql for node "model.anomaly_detection.cutoff_dates"
[0m20:29:15.033620 [debug] [Thread-2  ]: On model.anomaly_detection.cutoff_dates: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.cutoff_dates"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`cutoff_dates`
    
    
    OPTIONS()
    as (
      

select agg_tag, app_event, min(time_stamps) as strt_time
from `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`aggregations`
where event_count > 50
group by app_event, agg_tag 
order by app_event, agg_tag
    );
  
[0m20:29:17.736149 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:27083346-2e5b-4483-a029-af73cb29eff3&page=queryresults
[0m20:29:17.741830 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.cutoff_dates (execute): 2024-05-08 20:29:14.746291 => 2024-05-08 20:29:17.741720
[0m20:29:17.743087 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1213ac8b0>]}
[0m20:29:17.743773 [info ] [Thread-2  ]: 3 of 21 OK created sql table model tenant_A.cutoff_dates ....................... [[32mCREATE TABLE (8.0 rows, 103.9 KB processed)[0m in 3.00s]
[0m20:29:17.744270 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.cutoff_dates
[0m20:29:17.745415 [debug] [Thread-4  ]: Began running node model.anomaly_detection.aggregations_cutoff
[0m20:29:17.746297 [info ] [Thread-4  ]: 4 of 21 START sql table model tenant_A.aggregations_cutoff ..................... [RUN]
[0m20:29:17.747211 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.aggregations_cutoff'
[0m20:29:17.747538 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.aggregations_cutoff
[0m20:29:17.755386 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.aggregations_cutoff"
[0m20:29:17.756666 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.aggregations_cutoff (compile): 2024-05-08 20:29:17.747742 => 2024-05-08 20:29:17.756561
[0m20:29:17.757044 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.aggregations_cutoff
[0m20:29:17.759571 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m20:29:18.186931 [debug] [Thread-4  ]: Writing runtime sql for node "model.anomaly_detection.aggregations_cutoff"
[0m20:29:18.188717 [debug] [Thread-4  ]: On model.anomaly_detection.aggregations_cutoff: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.aggregations_cutoff"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`aggregations_cutoff`
    
    
    OPTIONS()
    as (
      

select time_stamps, app_event, agg_tag, event_count
from(
select time_stamps, strt_time, main.app_event, main.agg_tag, event_count
from `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`aggregations` as main
inner join `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`cutoff_dates` as cutoff
on main.agg_tag = cutoff.agg_tag
and main.app_event = cutoff.app_event
order by main.app_event, main.agg_tag, time_stamps)
where time_stamps >= strt_time
    );
  
[0m20:29:21.545830 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:e480b3b9-43a8-4938-b937-a6b2bd700c0c&page=queryresults
[0m20:29:21.548057 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.aggregations_cutoff (execute): 2024-05-08 20:29:17.757197 => 2024-05-08 20:29:21.547979
[0m20:29:21.548820 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122072730>]}
[0m20:29:21.549253 [info ] [Thread-4  ]: 4 of 21 OK created sql table model tenant_A.aggregations_cutoff ................ [[32mCREATE TABLE (2.2k rows, 104.2 KB processed)[0m in 3.80s]
[0m20:29:21.549565 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.aggregations_cutoff
[0m20:29:21.550335 [debug] [Thread-1  ]: Began running node model.anomaly_detection.nonrecent_events
[0m20:29:21.550796 [debug] [Thread-2  ]: Began running node model.anomaly_detection.train_data
[0m20:29:21.551230 [info ] [Thread-1  ]: 5 of 21 START sql table model tenant_A.nonrecent_events ........................ [RUN]
[0m20:29:21.551741 [info ] [Thread-2  ]: 6 of 21 START sql table model tenant_A.train_data .............................. [RUN]
[0m20:29:21.552641 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.nonrecent_events'
[0m20:29:21.553368 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.train_data'
[0m20:29:21.553745 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.nonrecent_events
[0m20:29:21.553992 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.train_data
[0m20:29:21.559108 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.nonrecent_events"
[0m20:29:21.562501 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.train_data"
[0m20:29:21.563712 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_events (compile): 2024-05-08 20:29:21.554176 => 2024-05-08 20:29:21.563572
[0m20:29:21.563988 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.train_data (compile): 2024-05-08 20:29:21.559360 => 2024-05-08 20:29:21.563941
[0m20:29:21.564250 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.nonrecent_events
[0m20:29:21.564455 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.train_data
[0m20:29:21.566893 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:29:21.568854 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m20:29:21.894075 [debug] [Thread-2  ]: Writing runtime sql for node "model.anomaly_detection.train_data"
[0m20:29:21.897371 [debug] [Thread-2  ]: On model.anomaly_detection.train_data: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.train_data"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`train_data`
    
    
    OPTIONS()
    as (
      

select *
from `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`aggregations_cutoff`
where DATE(time_stamps) < DATE_SUB("2023-02-09", INTERVAL 10 DAY)
    );
  
[0m20:29:21.924520 [debug] [Thread-1  ]: Writing runtime sql for node "model.anomaly_detection.nonrecent_events"
[0m20:29:21.925603 [debug] [Thread-1  ]: On model.anomaly_detection.nonrecent_events: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.nonrecent_events"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`nonrecent_events`
    
    
    OPTIONS()
    as (
      

SELECT MIN(time_stamps) AS strt_time, app_event
FROM `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`aggregations_cutoff`
GROUP BY app_event
HAVING DATE(MIN(time_stamps)) < DATE_SUB("2023-02-09", INTERVAL 30 DAY)
ORDER BY strt_time
    );
  
[0m20:29:24.622519 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:35b4dc9a-8fea-4ced-b831-da2f25400460&page=queryresults
[0m20:29:24.627094 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.train_data (execute): 2024-05-08 20:29:21.567079 => 2024-05-08 20:29:24.626984
[0m20:29:24.628319 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1213576d0>]}
[0m20:29:24.629034 [info ] [Thread-2  ]: 6 of 21 OK created sql table model tenant_A.train_data ......................... [[32mCREATE TABLE (1.9k rows, 103.9 KB processed)[0m in 3.08s]
[0m20:29:24.629560 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.train_data
[0m20:29:24.630452 [debug] [Thread-4  ]: Began running node model.anomaly_detection.IQR_quartiles
[0m20:29:24.631133 [info ] [Thread-4  ]: 7 of 21 START sql table model tenant_A.IQR_quartiles ........................... [RUN]
[0m20:29:24.631981 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_quartiles'
[0m20:29:24.632251 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.IQR_quartiles
[0m20:29:24.637911 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.IQR_quartiles"
[0m20:29:24.638812 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.IQR_quartiles (compile): 2024-05-08 20:29:24.632424 => 2024-05-08 20:29:24.638758
[0m20:29:24.639045 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.IQR_quartiles
[0m20:29:24.641541 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m20:29:24.708221 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:ecbdf4ea-f2dd-42a4-8e60-4d35ef5379ab&page=queryresults
[0m20:29:24.712210 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_events (execute): 2024-05-08 20:29:21.564587 => 2024-05-08 20:29:24.712134
[0m20:29:24.713137 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121220430>]}
[0m20:29:24.713646 [info ] [Thread-1  ]: 5 of 21 OK created sql table model tenant_A.nonrecent_events ................... [[32mCREATE TABLE (2.0 rows, 75.9 KB processed)[0m in 3.16s]
[0m20:29:24.714010 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.nonrecent_events
[0m20:29:25.044423 [debug] [Thread-4  ]: Writing runtime sql for node "model.anomaly_detection.IQR_quartiles"
[0m20:29:25.046280 [debug] [Thread-4  ]: On model.anomaly_detection.IQR_quartiles: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.IQR_quartiles"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`IQR_quartiles`
    
    
    OPTIONS()
    as (
      

select   ARRAY(SELECT x FROM UNNEST(output) AS x WITH OFFSET
  WHERE OFFSET BETWEEN 1 AND ARRAY_LENGTH(output) - 2) as output, 
  app_event, agg_tag
  from (
select APPROX_QUANTILES(event_count, 4) AS output, app_event
, agg_tag
from `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`train_data`
group by app_event, agg_tag
order by app_event, agg_tag )
    );
  
[0m20:29:27.904062 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:921d466b-6082-4849-a112-6dfec08c3171&page=queryresults
[0m20:29:27.912531 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.IQR_quartiles (execute): 2024-05-08 20:29:24.639187 => 2024-05-08 20:29:27.912447
[0m20:29:27.913501 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1220bd490>]}
[0m20:29:27.914097 [info ] [Thread-4  ]: 7 of 21 OK created sql table model tenant_A.IQR_quartiles ...................... [[32mCREATE TABLE (8.0 rows, 77.3 KB processed)[0m in 3.28s]
[0m20:29:27.914501 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.IQR_quartiles
[0m20:29:27.915586 [debug] [Thread-2  ]: Began running node model.anomaly_detection.IQR_bounds
[0m20:29:27.916304 [info ] [Thread-2  ]: 8 of 21 START sql table model tenant_A.IQR_bounds .............................. [RUN]
[0m20:29:27.917110 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_bounds'
[0m20:29:27.917386 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.IQR_bounds
[0m20:29:27.923544 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.IQR_bounds"
[0m20:29:27.924281 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.IQR_bounds (compile): 2024-05-08 20:29:27.917550 => 2024-05-08 20:29:27.924230
[0m20:29:27.924508 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.IQR_bounds
[0m20:29:27.926445 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m20:29:28.327065 [debug] [Thread-2  ]: Writing runtime sql for node "model.anomaly_detection.IQR_bounds"
[0m20:29:28.329946 [debug] [Thread-2  ]: On model.anomaly_detection.IQR_bounds: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.IQR_bounds"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`IQR_bounds`
    
    
    OPTIONS()
    as (
      

with temp as (
select quarts, app_event, agg_tag from(
select *
from `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`IQR_quartiles`,
unnest(output) as quarts)),

temp_1 as (
select app_event, agg_tag, max(quarts) as q3, min(quarts) as q1
from temp
group by app_event, agg_tag),

temp_2 as (
select app_event, agg_tag, q3, q1, q3-q1 as IQR 
from temp_1)

select app_event, agg_tag, (q1-4.5*IQR) as LB, (q3+4.5*IQR) as UB
from temp_2
order by app_event, agg_tag
    );
  
[0m20:29:31.025190 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:f992afc6-4b0c-447a-9a40-41e8f3f371cb&page=queryresults
[0m20:29:31.027614 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.IQR_bounds (execute): 2024-05-08 20:29:27.924642 => 2024-05-08 20:29:31.027525
[0m20:29:31.028416 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1220bd0d0>]}
[0m20:29:31.028870 [info ] [Thread-2  ]: 8 of 21 OK created sql table model tenant_A.IQR_bounds ......................... [[32mCREATE TABLE (8.0 rows, 460.0 Bytes processed)[0m in 3.11s]
[0m20:29:31.029178 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.IQR_bounds
[0m20:29:31.029794 [debug] [Thread-1  ]: Began running node model.anomaly_detection.IQR_outliers
[0m20:29:31.030291 [info ] [Thread-1  ]: 9 of 21 START sql table model tenant_A.IQR_outliers ............................ [RUN]
[0m20:29:31.031015 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_outliers'
[0m20:29:31.031233 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.IQR_outliers
[0m20:29:31.035446 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.IQR_outliers"
[0m20:29:31.035997 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.IQR_outliers (compile): 2024-05-08 20:29:31.031364 => 2024-05-08 20:29:31.035959
[0m20:29:31.036167 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.IQR_outliers
[0m20:29:31.037872 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:29:31.341842 [debug] [Thread-1  ]: Writing runtime sql for node "model.anomaly_detection.IQR_outliers"
[0m20:29:31.343657 [debug] [Thread-1  ]: On model.anomaly_detection.IQR_outliers: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.IQR_outliers"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`IQR_outliers`
    
    
    OPTIONS()
    as (
      

with bounds_agg as (
select time_stamps, bounds.app_event as app_event, bounds.agg_tag as agg_tag, event_count, LB, UB
from `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`IQR_bounds` as bounds
inner join `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`train_data` as aggs
on bounds.app_event = aggs.app_event
and bounds.agg_tag = aggs.agg_tag
order by bounds.app_event, bounds.agg_tag)

select time_stamps, app_event, agg_tag,
case when event_count > UB then UB
when event_count < LB then LB
else event_count
end as event_count
from bounds_agg
order by app_event, agg_tag, time_stamps
    );
  
[0m20:29:34.387657 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:cf0c1ba3-d97e-462f-a8c4-94d12bbc1ba0&page=queryresults
[0m20:29:34.391332 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.IQR_outliers (execute): 2024-05-08 20:29:31.036276 => 2024-05-08 20:29:34.391232
[0m20:29:34.392394 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1220bd670>]}
[0m20:29:34.393063 [info ] [Thread-1  ]: 9 of 21 OK created sql table model tenant_A.IQR_outliers ....................... [[32mCREATE TABLE (1.9k rows, 92.7 KB processed)[0m in 3.36s]
[0m20:29:34.393566 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.IQR_outliers
[0m20:29:34.394756 [debug] [Thread-3  ]: Began running node model.anomaly_detection.forecasts
[0m20:29:34.395242 [info ] [Thread-3  ]: 10 of 21 START sql table model tenant_A.forecasts .............................. [RUN]
[0m20:29:34.396022 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.forecasts'
[0m20:29:34.396304 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.forecasts
[0m20:29:34.406134 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.forecasts"
[0m20:29:34.406944 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.forecasts (compile): 2024-05-08 20:29:34.396489 => 2024-05-08 20:29:34.406891
[0m20:29:34.407145 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.forecasts
[0m20:29:34.409166 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m20:29:34.720120 [debug] [Thread-3  ]: Writing runtime sql for node "model.anomaly_detection.forecasts"
[0m20:29:34.723667 [debug] [Thread-3  ]: On model.anomaly_detection.forecasts: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.forecasts"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`forecasts`
    
    
    OPTIONS()
    as (
      -- 3 periods of training * 2 probabality threshold * 4 aggregation levels



-- depends_on: `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`IQR_outliers`


  WITH test_set AS (
    SELECT
    time_stamps,
          event_count,
          app_event,
          agg_tag
        FROM
          `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`aggregations_cutoff`
        WHERE
        DATE(time_stamps) >= DATE_SUB("2023-02-09", INTERVAL 10 DAY)
  )

    

      

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_1mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_1mon_8hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_2mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_2mon_24hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_2mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_2mon_12hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_2mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_2mon_8hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_2mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_2mon_4hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_1mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_1mon_4hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_1mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_1mon_12hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_1mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_1mon_24hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_05mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_05mon_4hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_05mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_05mon_8hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_05mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_05mon_12hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_05mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_05mon_24hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

    

      

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_1mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_1mon_8hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_2mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_2mon_24hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_2mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_2mon_12hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_2mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_2mon_8hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_2mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_2mon_4hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_1mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_1mon_4hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_1mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_1mon_12hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_1mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_1mon_24hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_05mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_05mon_4hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_05mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_05mon_8hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_05mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_05mon_12hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_05mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`models_05mon_24hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        

      

    
    );
  
[0m20:29:38.971668 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:bb76d933-0022-478d-8b03-ba5fabb8479f&page=queryresults
[0m20:29:38.975901 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.forecasts (execute): 2024-05-08 20:29:34.407285 => 2024-05-08 20:29:38.975810
[0m20:29:38.976872 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12204af40>]}
[0m20:29:38.977409 [info ] [Thread-3  ]: 10 of 21 OK created sql table model tenant_A.forecasts ......................... [[32mCREATE TABLE (1.4k rows, 550.5 KB processed)[0m in 4.58s]
[0m20:29:38.977777 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.forecasts
[0m20:29:38.978742 [debug] [Thread-4  ]: Began running node model.anomaly_detection.reset_forecasts
[0m20:29:38.979276 [info ] [Thread-4  ]: 11 of 21 START sql table model tenant_A.reset_forecasts ........................ [RUN]
[0m20:29:38.979900 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.reset_forecasts'
[0m20:29:38.980117 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.reset_forecasts
[0m20:29:38.984996 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.reset_forecasts"
[0m20:29:38.986073 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.reset_forecasts (compile): 2024-05-08 20:29:38.980277 => 2024-05-08 20:29:38.986017
[0m20:29:38.986269 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.reset_forecasts
[0m20:29:38.989489 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m20:29:39.288619 [debug] [Thread-4  ]: Writing runtime sql for node "model.anomaly_detection.reset_forecasts"
[0m20:29:39.291756 [debug] [Thread-4  ]: On model.anomaly_detection.reset_forecasts: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.reset_forecasts"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`reset_forecasts`
    
    
    OPTIONS()
    as (
      
  
  with neg_bound_reset as (
SELECT app_event, agg_tag, time_stamps, prob_threshold, training_period, event_count, 
  IF (lower_bound < 0, 2, (1 / 1.3) * lower_bound) AS lower_bound, 1.3 * upper_bound AS upper_bound, anomaly_probability, is_anomaly
FROM `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`forecasts` )

SELECT app_event, agg_tag, time_stamps, prob_threshold, training_period, event_count, 
  lower_bound, upper_bound, anomaly_probability,
  (upper_bound < event_count OR event_count < lower_bound) AS is_anomaly
FROM neg_bound_reset
    );
  
[0m20:29:41.914124 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:c1b0deb7-6c4c-484c-9585-acf292a6877d&page=queryresults
[0m20:29:41.918873 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.reset_forecasts (execute): 2024-05-08 20:29:38.986378 => 2024-05-08 20:29:41.918756
[0m20:29:41.920115 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122087940>]}
[0m20:29:41.920700 [info ] [Thread-4  ]: 11 of 21 OK created sql table model tenant_A.reset_forecasts ................... [[32mCREATE TABLE (1.4k rows, 151.6 KB processed)[0m in 2.94s]
[0m20:29:41.921121 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.reset_forecasts
[0m20:29:41.922370 [debug] [Thread-2  ]: Began running node model.anomaly_detection.all_configs
[0m20:29:41.922850 [info ] [Thread-2  ]: 12 of 21 START sql table model tenant_A.all_configs ............................ [RUN]
[0m20:29:41.923648 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.all_configs'
[0m20:29:41.923937 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.all_configs
[0m20:29:41.929692 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.all_configs"
[0m20:29:41.930647 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.all_configs (compile): 2024-05-08 20:29:41.924229 => 2024-05-08 20:29:41.930589
[0m20:29:41.930887 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.all_configs
[0m20:29:41.933210 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m20:29:42.583497 [debug] [Thread-2  ]: Writing runtime sql for node "model.anomaly_detection.all_configs"
[0m20:29:42.586382 [debug] [Thread-2  ]: On model.anomaly_detection.all_configs: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.all_configs"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`all_configs`
    
    
    OPTIONS()
    as (
      
  
  SELECT
    app_event,
    CONCAT(agg_tag, '_', prob_threshold, "threshold", '_', RTRIM(LTRIM(training_period, "derived_models_"), CONCAT('_', agg_tag))) AS control_config,
    SUM(CASE WHEN is_anomaly = TRUE THEN 1 ELSE 0 END) AS anomalies,
    SQRT(AVG( POWER(upper_bound - lower_bound, 2) ) ) / AVG(lower_bound) AS RMSD_prcnt
  FROM `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`reset_forecasts` AS all_configs
  GROUP BY
    app_event,
    control_config
  ORDER BY
    control_config,
    app_event
    );
  
[0m20:29:45.110154 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:727825c5-e4fb-40d0-b294-e0b93e6e8ec6&page=queryresults
[0m20:29:45.114909 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.all_configs (execute): 2024-05-08 20:29:41.931036 => 2024-05-08 20:29:45.114771
[0m20:29:45.116074 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1220193d0>]}
[0m20:29:45.116749 [info ] [Thread-2  ]: 12 of 21 OK created sql table model tenant_A.all_configs ....................... [[32mCREATE TABLE (48.0 rows, 119.3 KB processed)[0m in 3.19s]
[0m20:29:45.117242 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.all_configs
[0m20:29:45.118511 [debug] [Thread-1  ]: Began running node model.anomaly_detection.nonrecent_configs
[0m20:29:45.119134 [info ] [Thread-1  ]: 13 of 21 START sql table model tenant_A.nonrecent_configs ...................... [RUN]
[0m20:29:45.119964 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.nonrecent_configs'
[0m20:29:45.120229 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.nonrecent_configs
[0m20:29:45.125263 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.nonrecent_configs"
[0m20:29:45.127620 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_configs (compile): 2024-05-08 20:29:45.120401 => 2024-05-08 20:29:45.127522
[0m20:29:45.128023 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.nonrecent_configs
[0m20:29:45.130811 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:29:45.382676 [debug] [Thread-1  ]: Writing runtime sql for node "model.anomaly_detection.nonrecent_configs"
[0m20:29:45.384396 [debug] [Thread-1  ]: On model.anomaly_detection.nonrecent_configs: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.nonrecent_configs"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`nonrecent_configs`
    
    
    OPTIONS()
    as (
      
SELECT features.app_event, control_config, anomalies, RMSD_prcnt
FROM `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`nonrecent_events` AS non_recent
INNER JOIN `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`all_configs` AS features
  ON non_recent.app_event = features.app_event
    );
  
[0m20:29:48.041503 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:b3ea1179-b3a9-4952-8a59-326a3f173175&page=queryresults
[0m20:29:48.044202 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_configs (execute): 2024-05-08 20:29:45.128205 => 2024-05-08 20:29:48.044148
[0m20:29:48.044816 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122019d90>]}
[0m20:29:48.045156 [info ] [Thread-1  ]: 13 of 21 OK created sql table model tenant_A.nonrecent_configs ................. [[32mCREATE TABLE (48.0 rows, 3.4 KB processed)[0m in 2.93s]
[0m20:29:48.045411 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.nonrecent_configs
[0m20:29:48.046019 [debug] [Thread-3  ]: Began running node model.anomaly_detection.filtered_nonrecent_configs
[0m20:29:48.046370 [info ] [Thread-3  ]: 14 of 21 START sql table model tenant_A.filtered_nonrecent_configs ............. [RUN]
[0m20:29:48.047060 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.filtered_nonrecent_configs'
[0m20:29:48.047525 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.filtered_nonrecent_configs
[0m20:29:48.051879 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.filtered_nonrecent_configs"
[0m20:29:48.052634 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.filtered_nonrecent_configs (compile): 2024-05-08 20:29:48.047764 => 2024-05-08 20:29:48.052575
[0m20:29:48.052890 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.filtered_nonrecent_configs
[0m20:29:48.055343 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m20:29:48.420865 [debug] [Thread-3  ]: Writing runtime sql for node "model.anomaly_detection.filtered_nonrecent_configs"
[0m20:29:48.423807 [debug] [Thread-3  ]: On model.anomaly_detection.filtered_nonrecent_configs: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.filtered_nonrecent_configs"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`filtered_nonrecent_configs`
    
    
    OPTIONS()
    as (
      

select *
from `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`nonrecent_configs`
where RMSD_prcnt is not null
    );
  
[0m20:29:51.528414 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:a2bda26d-6ba0-4ea3-824f-175d956c2e6b&page=queryresults
[0m20:29:51.531712 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.filtered_nonrecent_configs (execute): 2024-05-08 20:29:48.053057 => 2024-05-08 20:29:51.531610
[0m20:29:51.532773 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122085940>]}
[0m20:29:51.533334 [info ] [Thread-3  ]: 14 of 21 OK created sql table model tenant_A.filtered_nonrecent_configs ........ [[32mCREATE TABLE (48.0 rows, 3.4 KB processed)[0m in 3.49s]
[0m20:29:51.533748 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.filtered_nonrecent_configs
[0m20:29:51.534676 [debug] [Thread-4  ]: Began running node model.anomaly_detection.min_anomalies
[0m20:29:51.535467 [info ] [Thread-4  ]: 15 of 21 START sql table model tenant_A.min_anomalies .......................... [RUN]
[0m20:29:51.536259 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.min_anomalies'
[0m20:29:51.536530 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.min_anomalies
[0m20:29:51.544320 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.min_anomalies"
[0m20:29:51.545073 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.min_anomalies (compile): 2024-05-08 20:29:51.536713 => 2024-05-08 20:29:51.544999
[0m20:29:51.545340 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.min_anomalies
[0m20:29:51.548017 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m20:29:51.860139 [debug] [Thread-4  ]: Writing runtime sql for node "model.anomaly_detection.min_anomalies"
[0m20:29:51.861886 [debug] [Thread-4  ]: On model.anomaly_detection.min_anomalies: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.min_anomalies"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`min_anomalies`
    
    
    OPTIONS()
    as (
      

SELECT app_event, MIN(anomalies) AS anomalies 
  FROM `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`filtered_nonrecent_configs`
  GROUP BY app_event
  ORDER BY app_event
    );
  
[0m20:29:54.609453 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:6c228a6c-8089-4275-9fd9-414dbed12c85&page=queryresults
[0m20:29:54.614106 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.min_anomalies (execute): 2024-05-08 20:29:51.545494 => 2024-05-08 20:29:54.613986
[0m20:29:54.615309 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12231bdf0>]}
[0m20:29:54.615986 [info ] [Thread-4  ]: 15 of 21 OK created sql table model tenant_A.min_anomalies ..................... [[32mCREATE TABLE (2.0 rows, 1.7 KB processed)[0m in 3.08s]
[0m20:29:54.616479 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.min_anomalies
[0m20:29:54.617555 [debug] [Thread-2  ]: Began running node model.anomaly_detection.min_anomalies_configs
[0m20:29:54.618041 [info ] [Thread-2  ]: 16 of 21 START sql table model tenant_A.min_anomalies_configs .................. [RUN]
[0m20:29:54.618749 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.min_anomalies_configs'
[0m20:29:54.619016 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.min_anomalies_configs
[0m20:29:54.625134 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.min_anomalies_configs"
[0m20:29:54.626229 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.min_anomalies_configs (compile): 2024-05-08 20:29:54.619189 => 2024-05-08 20:29:54.626169
[0m20:29:54.626463 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.min_anomalies_configs
[0m20:29:54.628829 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m20:29:54.922880 [debug] [Thread-2  ]: Writing runtime sql for node "model.anomaly_detection.min_anomalies_configs"
[0m20:29:54.924063 [debug] [Thread-2  ]: On model.anomaly_detection.min_anomalies_configs: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.min_anomalies_configs"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`min_anomalies_configs`
    
    
    OPTIONS()
    as (
      

SELECT configs.app_event, configs.control_config, 
    configs.anomalies, configs.RMSD_prcnt
  FROM `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`filtered_nonrecent_configs` AS configs
  INNER JOIN `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`min_anomalies` AS min_anomalies
    ON configs.anomalies = min_anomalies.anomalies
      AND configs.app_event = min_anomalies.app_event
  ORDER BY configs.app_event, RMSD_prcnt DESC
    );
  
[0m20:29:57.743857 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:417a0084-c319-49c0-aac3-b2a9d333b076&page=queryresults
[0m20:29:57.745928 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.min_anomalies_configs (execute): 2024-05-08 20:29:54.626616 => 2024-05-08 20:29:57.745879
[0m20:29:57.746501 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122054280>]}
[0m20:29:57.746852 [info ] [Thread-2  ]: 16 of 21 OK created sql table model tenant_A.min_anomalies_configs ............. [[32mCREATE TABLE (37.0 rows, 3.4 KB processed)[0m in 3.13s]
[0m20:29:57.747133 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.min_anomalies_configs
[0m20:29:57.747682 [debug] [Thread-1  ]: Began running node model.anomaly_detection.min_RMSD
[0m20:29:57.748234 [info ] [Thread-1  ]: 17 of 21 START sql table model tenant_A.min_RMSD ............................... [RUN]
[0m20:29:57.748835 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.min_RMSD'
[0m20:29:57.749048 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.min_RMSD
[0m20:29:57.752649 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.min_RMSD"
[0m20:29:57.753442 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.min_RMSD (compile): 2024-05-08 20:29:57.749174 => 2024-05-08 20:29:57.753387
[0m20:29:57.753655 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.min_RMSD
[0m20:29:57.755450 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:29:58.036415 [debug] [Thread-1  ]: Writing runtime sql for node "model.anomaly_detection.min_RMSD"
[0m20:29:58.037965 [debug] [Thread-1  ]: On model.anomaly_detection.min_RMSD: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.min_RMSD"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`min_RMSD`
    
    
    OPTIONS()
    as (
      

SELECT app_event, MIN(RMSD_prcnt) AS RMSD_prcnt 
  FROM `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`min_anomalies_configs`
  GROUP BY app_event
  ORDER BY app_event
    );
  
[0m20:30:00.664697 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:e5325210-7d90-4777-b4bc-7b080acb3b2a&page=queryresults
[0m20:30:00.669648 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.min_RMSD (execute): 2024-05-08 20:29:57.753785 => 2024-05-08 20:30:00.669528
[0m20:30:00.671097 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122054a30>]}
[0m20:30:00.671674 [info ] [Thread-1  ]: 17 of 21 OK created sql table model tenant_A.min_RMSD .......................... [[32mCREATE TABLE (2.0 rows, 1.3 KB processed)[0m in 2.92s]
[0m20:30:00.672099 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.min_RMSD
[0m20:30:00.673222 [debug] [Thread-3  ]: Began running node model.anomaly_detection.control_table
[0m20:30:00.673877 [info ] [Thread-3  ]: 18 of 21 START sql table model tenant_A.control_table .......................... [RUN]
[0m20:30:00.674727 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.control_table'
[0m20:30:00.675000 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.control_table
[0m20:30:00.680301 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.control_table"
[0m20:30:00.681197 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.control_table (compile): 2024-05-08 20:30:00.675175 => 2024-05-08 20:30:00.681143
[0m20:30:00.681424 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.control_table
[0m20:30:00.684008 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m20:30:00.987915 [debug] [Thread-3  ]: Writing runtime sql for node "model.anomaly_detection.control_table"
[0m20:30:00.989909 [debug] [Thread-3  ]: On model.anomaly_detection.control_table: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.control_table"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`control_table`
    
    
    OPTIONS()
    as (
      

SELECT configs.app_event, configs.control_config, 
    configs.anomalies, configs.RMSD_prcnt
  FROM `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`min_anomalies_configs` AS configs
  INNER JOIN `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`min_RMSD` AS min_RMSD
    ON configs.RMSD_prcnt = min_RMSD.RMSD_prcnt
      AND configs.app_event = min_RMSD.app_event
  ORDER BY configs.app_event, control_config
    );
  
[0m20:30:03.849247 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:c5ba40d8-22d8-4674-b783-8edf9565aa3b&page=queryresults
[0m20:30:03.855400 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.control_table (execute): 2024-05-08 20:30:00.681574 => 2024-05-08 20:30:03.855308
[0m20:30:03.856289 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12234c040>]}
[0m20:30:03.856781 [info ] [Thread-3  ]: 18 of 21 OK created sql table model tenant_A.control_table ..................... [[32mCREATE TABLE (2.0 rows, 2.7 KB processed)[0m in 3.18s]
[0m20:30:03.857148 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.control_table
[0m20:30:03.858217 [debug] [Thread-4  ]: Began running node model.anomaly_detection.alerting_base
[0m20:30:03.858646 [debug] [Thread-1  ]: Began running node model.tenant_A.my_first_dbt_model
[0m20:30:03.858947 [info ] [Thread-4  ]: 19 of 21 START sql table model tenant_A.alerting_base .......................... [RUN]
[0m20:30:03.859367 [info ] [Thread-1  ]: 20 of 21 START sql table model tenant_A.my_first_dbt_model ..................... [RUN]
[0m20:30:03.860288 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.alerting_base'
[0m20:30:03.861012 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.tenant_A.my_first_dbt_model'
[0m20:30:03.861318 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.alerting_base
[0m20:30:03.861563 [debug] [Thread-1  ]: Began compiling node model.tenant_A.my_first_dbt_model
[0m20:30:03.868121 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.alerting_base"
[0m20:30:03.871504 [debug] [Thread-1  ]: Writing injected SQL for node "model.tenant_A.my_first_dbt_model"
[0m20:30:03.873795 [debug] [Thread-1  ]: Timing info for model.tenant_A.my_first_dbt_model (compile): 2024-05-08 20:30:03.868419 => 2024-05-08 20:30:03.873707
[0m20:30:03.874018 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.alerting_base (compile): 2024-05-08 20:30:03.861737 => 2024-05-08 20:30:03.873960
[0m20:30:03.874244 [debug] [Thread-1  ]: Began executing node model.tenant_A.my_first_dbt_model
[0m20:30:03.874460 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.alerting_base
[0m20:30:03.876921 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:30:03.879054 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m20:30:04.241651 [debug] [Thread-4  ]: Writing runtime sql for node "model.anomaly_detection.alerting_base"
[0m20:30:04.243499 [debug] [Thread-4  ]: On model.anomaly_detection.alerting_base: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.alerting_base"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`alerting_base`
    
    
    OPTIONS()
    as (
      
  
  WITH ml_detect_updated AS (
    SELECT app_event, 
      CONCAT(agg_tag, '_', prob_threshold, "threshold", '_', RTRIM(LTRIM(training_period, "derived_models_"), CONCAT('_', agg_tag))) AS control_config,
      time_stamps, event_count, is_anomaly, lower_bound, upper_bound, anomaly_probability
    FROM `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`reset_forecasts`
  )
  SELECT time_stamps, all_forecasts.app_event AS app_event, control_table.control_config AS control_config, 
    anomalies, RMSD_prcnt, event_count, lower_bound, upper_bound, anomaly_probability, is_anomaly
  FROM ml_detect_updated AS all_forecasts 
  INNER JOIN `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`control_table` AS control_table 
    ON all_forecasts.app_event = control_table.app_event
      AND all_forecasts.control_config = control_table.control_config
  ORDER BY all_forecasts.app_event, time_stamps
    );
  
[0m20:30:04.322055 [debug] [Thread-1  ]: Writing runtime sql for node "model.tenant_A.my_first_dbt_model"
[0m20:30:04.323607 [debug] [Thread-1  ]: On model.tenant_A.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.tenant_A.my_first_dbt_model"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



select * 
from `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`control_table`

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m20:30:07.246476 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:1923f288-c1cd-49d5-9c63-08f71920cecf&page=queryresults
[0m20:30:07.251165 [debug] [Thread-1  ]: Timing info for model.tenant_A.my_first_dbt_model (execute): 2024-05-08 20:30:03.874593 => 2024-05-08 20:30:07.251078
[0m20:30:07.252030 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1220f1ac0>]}
[0m20:30:07.252505 [info ] [Thread-1  ]: 20 of 21 OK created sql table model tenant_A.my_first_dbt_model ................ [[32mCREATE TABLE (2.0 rows, 141.0 Bytes processed)[0m in 3.39s]
[0m20:30:07.252843 [debug] [Thread-1  ]: Finished running node model.tenant_A.my_first_dbt_model
[0m20:30:07.336282 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:9529d36a-e40e-492c-a4b0-afbd288b8ca3&page=queryresults
[0m20:30:07.339561 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.alerting_base (execute): 2024-05-08 20:30:03.877193 => 2024-05-08 20:30:07.339447
[0m20:30:07.340830 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12230cf70>]}
[0m20:30:07.341522 [info ] [Thread-4  ]: 19 of 21 OK created sql table model tenant_A.alerting_base ..................... [[32mCREATE TABLE (50.0 rows, 153.2 KB processed)[0m in 3.48s]
[0m20:30:07.341952 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.alerting_base
[0m20:30:07.342927 [debug] [Thread-3  ]: Began running node model.anomaly_detection.daily_alerts
[0m20:30:07.343622 [info ] [Thread-3  ]: 21 of 21 START sql table model tenant_A.daily_alerts ........................... [RUN]
[0m20:30:07.344568 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.daily_alerts'
[0m20:30:07.344884 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.daily_alerts
[0m20:30:07.350097 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.daily_alerts"
[0m20:30:07.350910 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.daily_alerts (compile): 2024-05-08 20:30:07.345078 => 2024-05-08 20:30:07.350856
[0m20:30:07.351135 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.daily_alerts
[0m20:30:07.353569 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m20:30:07.662798 [debug] [Thread-3  ]: Writing runtime sql for node "model.anomaly_detection.daily_alerts"
[0m20:30:07.664709 [debug] [Thread-3  ]: On model.anomaly_detection.daily_alerts: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.daily_alerts"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`daily_alerts`
    
    
    OPTIONS()
    as (
      
SELECT time_stamps, app_event, event_count AS event_count_anomalous_yesterday
FROM `prj-s-telus-tpm-data-fcfc`.`tenant_A`.`alerting_base`
WHERE DATE(time_stamps) = "2023-02-09" - 1 
  AND is_anomaly
    );
  
[0m20:30:10.316273 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:ee6f60c6-7a56-41e1-8530-bcfd525f5d95&page=queryresults
[0m20:30:10.319467 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.daily_alerts (execute): 2024-05-08 20:30:07.351277 => 2024-05-08 20:30:10.319410
[0m20:30:10.320233 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12cdcef-a408-4f5f-84b9-16f0e56cda8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12209f850>]}
[0m20:30:10.320803 [info ] [Thread-3  ]: 21 of 21 OK created sql table model tenant_A.daily_alerts ...................... [[32mCREATE TABLE (0.0 rows, 2.2 KB processed)[0m in 2.98s]
[0m20:30:10.321261 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.daily_alerts
[0m20:30:10.323248 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m20:30:10.324120 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:30:10.324376 [debug] [MainThread]: Connection 'model.tenant_A.my_first_dbt_model' was properly closed.
[0m20:30:10.324556 [debug] [MainThread]: Connection 'model.anomaly_detection.daily_alerts' was properly closed.
[0m20:30:10.324713 [debug] [MainThread]: Connection 'model.anomaly_detection.min_anomalies_configs' was properly closed.
[0m20:30:10.324864 [debug] [MainThread]: Connection 'model.anomaly_detection.alerting_base' was properly closed.
[0m20:30:10.325158 [info ] [MainThread]: 
[0m20:30:10.325514 [info ] [MainThread]: Finished running 21 table models in 0 hours 1 minutes and 13.78 seconds (73.78s).
[0m20:30:10.326880 [debug] [MainThread]: Command end result
[0m20:30:10.341129 [info ] [MainThread]: 
[0m20:30:10.341573 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:30:10.341805 [info ] [MainThread]: 
[0m20:30:10.342021 [info ] [MainThread]: Done. PASS=21 WARN=0 ERROR=0 SKIP=0 TOTAL=21
[0m20:30:10.342376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1213dcb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122094790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122094d30>]}
[0m20:30:10.342646 [debug] [MainThread]: Flushing usage events


============================== 2024-05-08 20:35:47.756630 | c9403f38-88a3-45e7-87f4-aeb8e18e552a ==============================
[0m20:35:47.756630 [info ] [MainThread]: Running with dbt=1.4.1
[0m20:35:47.757454 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/rana/TPM_dbt_poc/tenant_B', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m20:35:47.757550 [debug] [MainThread]: Tracking: tracking
[0m20:35:47.784547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108617760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086289d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108628700>]}
[0m20:35:48.054391 [debug] [MainThread]: Executing "git --help"
[0m20:35:48.076813 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m20:35:48.077314 [debug] [MainThread]: STDERR: "b''"
[0m20:35:48.082714 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m20:35:48.083149 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:35:48.886861 [debug] [MainThread]: On debug: select 1 as id
[0m20:35:50.086247 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:22954d9e-0e80-4f35-a273-cbdf5634d53b&page=queryresults
[0m20:35:50.087439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a096370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0966d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a096e50>]}
[0m20:35:50.088062 [debug] [MainThread]: Flushing usage events
[0m20:35:50.337580 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2024-05-08 20:35:56.433731 | bf2b7325-6fa5-4ddc-aacf-a223b3a65cda ==============================
[0m20:35:56.433731 [info ] [MainThread]: Running with dbt=1.4.1
[0m20:35:56.434480 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/rana/TPM_dbt_poc/tenant_B', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'deps', 'rpc_method': 'deps', 'indirect_selection': 'eager'}
[0m20:35:56.434575 [debug] [MainThread]: Tracking: tracking
[0m20:35:56.451543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d8e310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e10b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e10bb0>]}
[0m20:35:56.454011 [debug] [MainThread]: Set downloads directory='/var/folders/2b/s3pxyycs63s1dl1mn2p9mnq40000gn/T/dbt-downloads-xqq9zxrr'
[0m20:35:56.465312 [info ] [MainThread]: Installing /Users/rana/TPM_dbt_poc/anomaly_detection
[0m20:35:56.483794 [debug] [MainThread]:   Creating symlink to local dependency.
[0m20:35:56.484092 [info ] [MainThread]:   Installed from <local @ /Users/rana/TPM_dbt_poc/anomaly_detection>
[0m20:35:56.484309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'bf2b7325-6fa5-4ddc-aacf-a223b3a65cda', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e0b8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e0bf10>]}
[0m20:35:56.484745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d986a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e024c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e0bfd0>]}
[0m20:35:56.484863 [debug] [MainThread]: Flushing usage events


============================== 2024-05-08 20:36:02.212556 | c5ba2bed-19d8-41a2-a605-27988a7e432b ==============================
[0m20:36:02.212556 [info ] [MainThread]: Running with dbt=1.4.1
[0m20:36:02.213620 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/rana/TPM_dbt_poc/tenant_B', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'parse_only': False, 'which': 'compile', 'rpc_method': 'compile', 'indirect_selection': 'eager'}
[0m20:36:02.213740 [debug] [MainThread]: Tracking: tracking
[0m20:36:02.231304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c82100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c82e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c829a0>]}
[0m20:36:02.251612 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m20:36:02.251855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c5ba2bed-19d8-41a2-a605-27988a7e432b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c51520>]}
[0m20:36:02.581975 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m20:36:02.595942 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/min_anomalies.sql
[0m20:36:02.598859 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/min_anomalies.sql
[0m20:36:02.599680 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/aggregations_cutoff.sql
[0m20:36:02.603608 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/aggregations_cutoff.sql
[0m20:36:02.604411 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/IQR_outliers.sql
[0m20:36:02.607758 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/IQR_outliers.sql
[0m20:36:02.608498 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/cutoff_dates.sql
[0m20:36:02.611434 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/cutoff_dates.sql
[0m20:36:02.612147 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/min_RMSD.sql
[0m20:36:02.614922 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/min_RMSD.sql
[0m20:36:02.615620 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/forecasts.sql
[0m20:36:02.620111 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/forecasts.sql
[0m20:36:02.620769 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/IQR_quartiles.sql
[0m20:36:02.623255 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/IQR_quartiles.sql
[0m20:36:02.623931 [debug] [MainThread]: 1699: static parser successfully parsed anomaly_detection/filtered_nonrecent_configs.sql
[0m20:36:02.625684 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/control_table.sql
[0m20:36:02.628537 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/control_table.sql
[0m20:36:02.629276 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/alerting_base.sql
[0m20:36:02.633317 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/alerting_base.sql
[0m20:36:02.634070 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/daily_alerts.sql
[0m20:36:02.636725 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/daily_alerts.sql
[0m20:36:02.637424 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/train_data.sql
[0m20:36:02.639924 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/train_data.sql
[0m20:36:02.640608 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/nonrecent_configs.sql
[0m20:36:02.643442 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/nonrecent_configs.sql
[0m20:36:02.644145 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/aggregations.sql
[0m20:36:02.647927 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/aggregations.sql
[0m20:36:02.648657 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/IQR_bounds.sql
[0m20:36:02.651880 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/IQR_bounds.sql
[0m20:36:02.652737 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/raw_data.sql
[0m20:36:02.656130 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/raw_data.sql
[0m20:36:02.656844 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/all_configs.sql
[0m20:36:02.659578 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/all_configs.sql
[0m20:36:02.660297 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/nonrecent_events.sql
[0m20:36:02.663973 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/nonrecent_events.sql
[0m20:36:02.664707 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/min_anomalies_configs.sql
[0m20:36:02.667617 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/min_anomalies_configs.sql
[0m20:36:02.668352 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/reset_forecasts.sql
[0m20:36:02.671534 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/reset_forecasts.sql
[0m20:36:02.697963 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c5ba2bed-19d8-41a2-a605-27988a7e432b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d70d90>]}
[0m20:36:02.703621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c5ba2bed-19d8-41a2-a605-27988a7e432b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c76fa0>]}
[0m20:36:02.703810 [info ] [MainThread]: Found 21 models, 0 tests, 0 snapshots, 0 analyses, 335 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m20:36:02.703955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c5ba2bed-19d8-41a2-a605-27988a7e432b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cc2d00>]}
[0m20:36:02.704985 [info ] [MainThread]: 
[0m20:36:02.705842 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m20:36:02.706824 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_prj-s-telus-tpm-data-fcfc_tenant_B'
[0m20:36:02.706999 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:36:03.914841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c5ba2bed-19d8-41a2-a605-27988a7e432b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c829a0>]}
[0m20:36:03.916887 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:36:03.917383 [info ] [MainThread]: 
[0m20:36:03.925050 [debug] [Thread-1  ]: Began running node model.anomaly_detection.raw_data
[0m20:36:03.926048 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.raw_data'
[0m20:36:03.926324 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.raw_data
[0m20:36:03.933141 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.raw_data"
[0m20:36:03.934873 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.raw_data (compile): 2024-05-08 20:36:03.926539 => 2024-05-08 20:36:03.934731
[0m20:36:03.935235 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.raw_data
[0m20:36:03.935461 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.raw_data (execute): 2024-05-08 20:36:03.935392 => 2024-05-08 20:36:03.935428
[0m20:36:03.937539 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.raw_data
[0m20:36:03.938192 [debug] [Thread-3  ]: Began running node model.anomaly_detection.aggregations
[0m20:36:03.938757 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.aggregations'
[0m20:36:03.938933 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.aggregations
[0m20:36:03.944257 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.aggregations"
[0m20:36:03.944768 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.aggregations (compile): 2024-05-08 20:36:03.939051 => 2024-05-08 20:36:03.944723
[0m20:36:03.944950 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.aggregations
[0m20:36:03.945094 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.aggregations (execute): 2024-05-08 20:36:03.945063 => 2024-05-08 20:36:03.945070
[0m20:36:03.945575 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.aggregations
[0m20:36:03.946065 [debug] [Thread-2  ]: Began running node model.anomaly_detection.cutoff_dates
[0m20:36:03.946825 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.cutoff_dates'
[0m20:36:03.947027 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.cutoff_dates
[0m20:36:03.952000 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.cutoff_dates"
[0m20:36:03.952525 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.cutoff_dates (compile): 2024-05-08 20:36:03.947148 => 2024-05-08 20:36:03.952479
[0m20:36:03.952688 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.cutoff_dates
[0m20:36:03.952813 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.cutoff_dates (execute): 2024-05-08 20:36:03.952785 => 2024-05-08 20:36:03.952793
[0m20:36:03.953278 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.cutoff_dates
[0m20:36:03.953691 [debug] [Thread-4  ]: Began running node model.anomaly_detection.aggregations_cutoff
[0m20:36:03.954117 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.aggregations_cutoff'
[0m20:36:03.954271 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.aggregations_cutoff
[0m20:36:03.957537 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.aggregations_cutoff"
[0m20:36:03.957894 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.aggregations_cutoff (compile): 2024-05-08 20:36:03.954368 => 2024-05-08 20:36:03.957864
[0m20:36:03.958025 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.aggregations_cutoff
[0m20:36:03.958129 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.aggregations_cutoff (execute): 2024-05-08 20:36:03.958106 => 2024-05-08 20:36:03.958111
[0m20:36:03.958492 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.aggregations_cutoff
[0m20:36:03.958823 [debug] [Thread-1  ]: Began running node model.anomaly_detection.nonrecent_events
[0m20:36:03.958995 [debug] [Thread-2  ]: Began running node model.anomaly_detection.train_data
[0m20:36:03.959346 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.nonrecent_events'
[0m20:36:03.959661 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.train_data'
[0m20:36:03.959795 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.nonrecent_events
[0m20:36:03.959925 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.train_data
[0m20:36:03.962307 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.nonrecent_events"
[0m20:36:03.964318 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.train_data"
[0m20:36:03.964689 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_events (compile): 2024-05-08 20:36:03.960018 => 2024-05-08 20:36:03.964659
[0m20:36:03.964790 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.train_data (compile): 2024-05-08 20:36:03.962428 => 2024-05-08 20:36:03.964764
[0m20:36:03.964918 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.nonrecent_events
[0m20:36:03.965032 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.train_data
[0m20:36:03.965145 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_events (execute): 2024-05-08 20:36:03.965122 => 2024-05-08 20:36:03.965127
[0m20:36:03.965243 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.train_data (execute): 2024-05-08 20:36:03.965222 => 2024-05-08 20:36:03.965227
[0m20:36:03.965578 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.nonrecent_events
[0m20:36:03.965912 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.train_data
[0m20:36:03.966307 [debug] [Thread-4  ]: Began running node model.anomaly_detection.IQR_quartiles
[0m20:36:03.966641 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_quartiles'
[0m20:36:03.966770 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.IQR_quartiles
[0m20:36:03.968905 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.IQR_quartiles"
[0m20:36:03.969193 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.IQR_quartiles (compile): 2024-05-08 20:36:03.966849 => 2024-05-08 20:36:03.969163
[0m20:36:03.969313 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.IQR_quartiles
[0m20:36:03.969409 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.IQR_quartiles (execute): 2024-05-08 20:36:03.969388 => 2024-05-08 20:36:03.969392
[0m20:36:03.969738 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.IQR_quartiles
[0m20:36:03.970035 [debug] [Thread-1  ]: Began running node model.anomaly_detection.IQR_bounds
[0m20:36:03.970332 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_bounds'
[0m20:36:03.970443 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.IQR_bounds
[0m20:36:03.973003 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.IQR_bounds"
[0m20:36:03.973288 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.IQR_bounds (compile): 2024-05-08 20:36:03.970535 => 2024-05-08 20:36:03.973266
[0m20:36:03.973409 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.IQR_bounds
[0m20:36:03.973506 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.IQR_bounds (execute): 2024-05-08 20:36:03.973485 => 2024-05-08 20:36:03.973489
[0m20:36:03.973822 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.IQR_bounds
[0m20:36:03.974091 [debug] [Thread-3  ]: Began running node model.anomaly_detection.IQR_outliers
[0m20:36:03.974393 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_outliers'
[0m20:36:03.974518 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.IQR_outliers
[0m20:36:03.977069 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.IQR_outliers"
[0m20:36:03.977339 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.IQR_outliers (compile): 2024-05-08 20:36:03.974597 => 2024-05-08 20:36:03.977317
[0m20:36:03.977453 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.IQR_outliers
[0m20:36:03.977542 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.IQR_outliers (execute): 2024-05-08 20:36:03.977522 => 2024-05-08 20:36:03.977527
[0m20:36:03.977838 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.IQR_outliers
[0m20:36:03.978071 [debug] [Thread-2  ]: Began running node model.anomaly_detection.forecasts
[0m20:36:03.978361 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.forecasts'
[0m20:36:03.978466 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.forecasts
[0m20:36:03.982447 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.forecasts"
[0m20:36:03.983157 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.forecasts (compile): 2024-05-08 20:36:03.978536 => 2024-05-08 20:36:03.983135
[0m20:36:03.983267 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.forecasts
[0m20:36:03.983357 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.forecasts (execute): 2024-05-08 20:36:03.983338 => 2024-05-08 20:36:03.983342
[0m20:36:03.983658 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.forecasts
[0m20:36:03.983905 [debug] [Thread-4  ]: Began running node model.anomaly_detection.reset_forecasts
[0m20:36:03.984172 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.reset_forecasts'
[0m20:36:03.984270 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.reset_forecasts
[0m20:36:03.986335 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.reset_forecasts"
[0m20:36:03.986710 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.reset_forecasts (compile): 2024-05-08 20:36:03.984345 => 2024-05-08 20:36:03.986690
[0m20:36:03.986813 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.reset_forecasts
[0m20:36:03.986897 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.reset_forecasts (execute): 2024-05-08 20:36:03.986878 => 2024-05-08 20:36:03.986882
[0m20:36:03.987174 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.reset_forecasts
[0m20:36:03.987388 [debug] [Thread-1  ]: Began running node model.anomaly_detection.all_configs
[0m20:36:03.987679 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.all_configs'
[0m20:36:03.987798 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.all_configs
[0m20:36:03.990334 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.all_configs"
[0m20:36:03.990611 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.all_configs (compile): 2024-05-08 20:36:03.987875 => 2024-05-08 20:36:03.990588
[0m20:36:03.990714 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.all_configs
[0m20:36:03.990801 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.all_configs (execute): 2024-05-08 20:36:03.990781 => 2024-05-08 20:36:03.990785
[0m20:36:03.991085 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.all_configs
[0m20:36:03.991303 [debug] [Thread-3  ]: Began running node model.anomaly_detection.nonrecent_configs
[0m20:36:03.991596 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.nonrecent_configs'
[0m20:36:03.991696 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.nonrecent_configs
[0m20:36:03.993579 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.nonrecent_configs"
[0m20:36:03.993852 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.nonrecent_configs (compile): 2024-05-08 20:36:03.991765 => 2024-05-08 20:36:03.993823
[0m20:36:03.993959 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.nonrecent_configs
[0m20:36:03.994046 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.nonrecent_configs (execute): 2024-05-08 20:36:03.994027 => 2024-05-08 20:36:03.994031
[0m20:36:03.994336 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.nonrecent_configs
[0m20:36:03.994578 [debug] [Thread-2  ]: Began running node model.anomaly_detection.filtered_nonrecent_configs
[0m20:36:03.994835 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.filtered_nonrecent_configs'
[0m20:36:03.994930 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.filtered_nonrecent_configs
[0m20:36:03.996324 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.filtered_nonrecent_configs"
[0m20:36:03.996558 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.filtered_nonrecent_configs (compile): 2024-05-08 20:36:03.994994 => 2024-05-08 20:36:03.996535
[0m20:36:03.996656 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.filtered_nonrecent_configs
[0m20:36:03.996738 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.filtered_nonrecent_configs (execute): 2024-05-08 20:36:03.996720 => 2024-05-08 20:36:03.996724
[0m20:36:03.997012 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.filtered_nonrecent_configs
[0m20:36:03.997220 [debug] [Thread-4  ]: Began running node model.anomaly_detection.min_anomalies
[0m20:36:03.997496 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.min_anomalies'
[0m20:36:03.997589 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.min_anomalies
[0m20:36:03.999311 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.min_anomalies"
[0m20:36:03.999554 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.min_anomalies (compile): 2024-05-08 20:36:03.997654 => 2024-05-08 20:36:03.999529
[0m20:36:03.999650 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.min_anomalies
[0m20:36:03.999733 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.min_anomalies (execute): 2024-05-08 20:36:03.999715 => 2024-05-08 20:36:03.999719
[0m20:36:04.000002 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.min_anomalies
[0m20:36:04.000208 [debug] [Thread-1  ]: Began running node model.anomaly_detection.min_anomalies_configs
[0m20:36:04.000486 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.min_anomalies_configs'
[0m20:36:04.000579 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.min_anomalies_configs
[0m20:36:04.002451 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.min_anomalies_configs"
[0m20:36:04.002711 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.min_anomalies_configs (compile): 2024-05-08 20:36:04.000642 => 2024-05-08 20:36:04.002683
[0m20:36:04.002810 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.min_anomalies_configs
[0m20:36:04.002891 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.min_anomalies_configs (execute): 2024-05-08 20:36:04.002873 => 2024-05-08 20:36:04.002877
[0m20:36:04.003157 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.min_anomalies_configs
[0m20:36:04.003393 [debug] [Thread-3  ]: Began running node model.anomaly_detection.min_RMSD
[0m20:36:04.003648 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.min_RMSD'
[0m20:36:04.003741 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.min_RMSD
[0m20:36:04.005362 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.min_RMSD"
[0m20:36:04.005580 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.min_RMSD (compile): 2024-05-08 20:36:04.003803 => 2024-05-08 20:36:04.005559
[0m20:36:04.005677 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.min_RMSD
[0m20:36:04.005761 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.min_RMSD (execute): 2024-05-08 20:36:04.005742 => 2024-05-08 20:36:04.005746
[0m20:36:04.006026 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.min_RMSD
[0m20:36:04.006231 [debug] [Thread-2  ]: Began running node model.anomaly_detection.control_table
[0m20:36:04.006497 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.control_table'
[0m20:36:04.006614 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.control_table
[0m20:36:04.008539 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.control_table"
[0m20:36:04.008793 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.control_table (compile): 2024-05-08 20:36:04.006680 => 2024-05-08 20:36:04.008767
[0m20:36:04.008893 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.control_table
[0m20:36:04.008988 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.control_table (execute): 2024-05-08 20:36:04.008970 => 2024-05-08 20:36:04.008974
[0m20:36:04.009262 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.control_table
[0m20:36:04.009486 [debug] [Thread-4  ]: Began running node model.anomaly_detection.alerting_base
[0m20:36:04.009606 [debug] [Thread-3  ]: Began running node model.tenant_A.my_first_dbt_model
[0m20:36:04.009864 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.alerting_base'
[0m20:36:04.010096 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.tenant_A.my_first_dbt_model'
[0m20:36:04.010198 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.alerting_base
[0m20:36:04.010292 [debug] [Thread-3  ]: Began compiling node model.tenant_A.my_first_dbt_model
[0m20:36:04.012349 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.alerting_base"
[0m20:36:04.013640 [debug] [Thread-3  ]: Writing injected SQL for node "model.tenant_A.my_first_dbt_model"
[0m20:36:04.013918 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.alerting_base (compile): 2024-05-08 20:36:04.010360 => 2024-05-08 20:36:04.013897
[0m20:36:04.013999 [debug] [Thread-3  ]: Timing info for model.tenant_A.my_first_dbt_model (compile): 2024-05-08 20:36:04.012435 => 2024-05-08 20:36:04.013981
[0m20:36:04.014105 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.alerting_base
[0m20:36:04.014217 [debug] [Thread-3  ]: Began executing node model.tenant_A.my_first_dbt_model
[0m20:36:04.014311 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.alerting_base (execute): 2024-05-08 20:36:04.014293 => 2024-05-08 20:36:04.014297
[0m20:36:04.014399 [debug] [Thread-3  ]: Timing info for model.tenant_A.my_first_dbt_model (execute): 2024-05-08 20:36:04.014381 => 2024-05-08 20:36:04.014385
[0m20:36:04.014669 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.alerting_base
[0m20:36:04.014937 [debug] [Thread-3  ]: Finished running node model.tenant_A.my_first_dbt_model
[0m20:36:04.015168 [debug] [Thread-2  ]: Began running node model.anomaly_detection.daily_alerts
[0m20:36:04.015411 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.daily_alerts'
[0m20:36:04.015503 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.daily_alerts
[0m20:36:04.017742 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.daily_alerts"
[0m20:36:04.017995 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.daily_alerts (compile): 2024-05-08 20:36:04.015566 => 2024-05-08 20:36:04.017976
[0m20:36:04.018093 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.daily_alerts
[0m20:36:04.018176 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.daily_alerts (execute): 2024-05-08 20:36:04.018158 => 2024-05-08 20:36:04.018162
[0m20:36:04.018442 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.daily_alerts
[0m20:36:04.018914 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:36:04.019007 [debug] [MainThread]: Connection 'model.anomaly_detection.min_anomalies_configs' was properly closed.
[0m20:36:04.019077 [debug] [MainThread]: Connection 'model.tenant_A.my_first_dbt_model' was properly closed.
[0m20:36:04.019141 [debug] [MainThread]: Connection 'model.anomaly_detection.daily_alerts' was properly closed.
[0m20:36:04.019200 [debug] [MainThread]: Connection 'model.anomaly_detection.alerting_base' was properly closed.
[0m20:36:04.019660 [debug] [MainThread]: Command end result
[0m20:36:04.024003 [info ] [MainThread]: Done.
[0m20:36:04.024222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111db79a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111db71f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d4cdf0>]}
[0m20:36:04.024378 [debug] [MainThread]: Flushing usage events


============================== 2024-05-08 20:36:07.335133 | 0e34a286-63cd-4dcd-90a0-12ee41ce1f7b ==============================
[0m20:36:07.335133 [info ] [MainThread]: Running with dbt=1.4.1
[0m20:36:07.336477 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/rana/TPM_dbt_poc/tenant_B', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m20:36:07.336607 [debug] [MainThread]: Tracking: tracking
[0m20:36:07.348130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105efa100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105efae50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105efa880>]}
[0m20:36:07.381971 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:36:07.382168 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:36:07.386065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0e34a286-63cd-4dcd-90a0-12ee41ce1f7b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b4f40>]}
[0m20:36:07.390472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0e34a286-63cd-4dcd-90a0-12ee41ce1f7b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fcfb50>]}
[0m20:36:07.390684 [info ] [MainThread]: Found 21 models, 0 tests, 0 snapshots, 0 analyses, 335 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m20:36:07.390837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0e34a286-63cd-4dcd-90a0-12ee41ce1f7b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fcf9a0>]}
[0m20:36:07.391909 [info ] [MainThread]: 
[0m20:36:07.392799 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m20:36:07.393944 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_prj-s-telus-tpm-data-fcfc'
[0m20:36:07.394191 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:36:08.424880 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_prj-s-telus-tpm-data-fcfc_tenant_B'
[0m20:36:08.425796 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:36:08.904773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0e34a286-63cd-4dcd-90a0-12ee41ce1f7b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f16460>]}
[0m20:36:08.905985 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:36:08.906246 [info ] [MainThread]: 
[0m20:36:08.911892 [debug] [Thread-1  ]: Began running node model.anomaly_detection.raw_data
[0m20:36:08.912377 [info ] [Thread-1  ]: 1 of 21 START sql table model tenant_B.raw_data ................................ [RUN]
[0m20:36:08.913045 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.raw_data'
[0m20:36:08.913214 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.raw_data
[0m20:36:08.917740 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.raw_data"
[0m20:36:08.918475 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.raw_data (compile): 2024-05-08 20:36:08.913372 => 2024-05-08 20:36:08.918384
[0m20:36:08.918663 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.raw_data
[0m20:36:08.950486 [debug] [Thread-1  ]: Writing runtime sql for node "model.anomaly_detection.raw_data"
[0m20:36:08.951387 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:36:08.951781 [debug] [Thread-1  ]: On model.anomaly_detection.raw_data: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.raw_data"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`raw_data`
    
    
    OPTIONS()
    as (
      
SELECT collector_tstamp, event_id, app_event
FROM `prj-s-telus-tpm-data-fcfc`.`dbt_rhashemi`.`sample_table_final`
WHERE DATE( collector_tstamp ) >= DATE_SUB("2023-02-09", INTERVAL 90 DAY) AND DATE( collector_tstamp ) < "2023-02-09"
    );
  
[0m20:36:15.657457 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:258a3151-df0b-4d9a-a3d8-6f8211ff3704&page=queryresults
[0m20:36:15.681420 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.raw_data (execute): 2024-05-08 20:36:08.918770 => 2024-05-08 20:36:15.681383
[0m20:36:15.681920 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e34a286-63cd-4dcd-90a0-12ee41ce1f7b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106229340>]}
[0m20:36:15.682165 [info ] [Thread-1  ]: 1 of 21 OK created sql table model tenant_B.raw_data ........................... [[32mCREATE TABLE (1.1m rows, 76.0 MB processed)[0m in 6.77s]
[0m20:36:15.683124 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.raw_data
[0m20:36:15.683955 [debug] [Thread-3  ]: Began running node model.anomaly_detection.aggregations
[0m20:36:15.684215 [info ] [Thread-3  ]: 2 of 21 START sql table model tenant_B.aggregations ............................ [RUN]
[0m20:36:15.684638 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.aggregations'
[0m20:36:15.684795 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.aggregations
[0m20:36:15.688294 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.aggregations"
[0m20:36:15.689028 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.aggregations (compile): 2024-05-08 20:36:15.684876 => 2024-05-08 20:36:15.688964
[0m20:36:15.689242 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.aggregations
[0m20:36:15.692070 [debug] [Thread-3  ]: Writing runtime sql for node "model.anomaly_detection.aggregations"
[0m20:36:15.692661 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m20:36:15.692877 [debug] [Thread-3  ]: On model.anomaly_detection.aggregations: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.aggregations"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`aggregations`
    
    
    OPTIONS()
    as (
      



    SELECT "4hr" AS agg_tag,
        PARSE_TIMESTAMP("%F %H", CONCAT(date_trunc, ' ', CAST(_4hr_trunc AS STRING))) AS time_stamps,
        app_event,
        event_count
    FROM (
        SELECT FORMAT_TIMESTAMP("%F", collector_tstamp) AS date_trunc,
        FLOOR(CAST(FORMAT_TIMESTAMP("%H", collector_tstamp) AS INT64)/4)*4 AS _4hr_trunc,
        app_event,
        COUNT(event_id) AS event_count
        FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`raw_data`
        GROUP BY
        date_trunc,
        _4hr_trunc,
        app_event
    )


    
    UNION ALL
    


    SELECT "8hr" AS agg_tag,
        PARSE_TIMESTAMP("%F %H", CONCAT(date_trunc, ' ', CAST(_8hr_trunc AS STRING))) AS time_stamps,
        app_event,
        event_count
    FROM (
        SELECT FORMAT_TIMESTAMP("%F", collector_tstamp) AS date_trunc,
        FLOOR(CAST(FORMAT_TIMESTAMP("%H", collector_tstamp) AS INT64)/8)*8 AS _8hr_trunc,
        app_event,
        COUNT(event_id) AS event_count
        FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`raw_data`
        GROUP BY
        date_trunc,
        _8hr_trunc,
        app_event
    )


    
    UNION ALL
    


    SELECT "12hr" AS agg_tag,
        PARSE_TIMESTAMP("%F %H", CONCAT(date_trunc, ' ', CAST(_12hr_trunc AS STRING))) AS time_stamps,
        app_event,
        event_count
    FROM (
        SELECT FORMAT_TIMESTAMP("%F", collector_tstamp) AS date_trunc,
        FLOOR(CAST(FORMAT_TIMESTAMP("%H", collector_tstamp) AS INT64)/12)*12 AS _12hr_trunc,
        app_event,
        COUNT(event_id) AS event_count
        FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`raw_data`
        GROUP BY
        date_trunc,
        _12hr_trunc,
        app_event
    )


    
    UNION ALL
    


    SELECT "24hr" AS agg_tag,
        PARSE_TIMESTAMP("%F %H", CONCAT(date_trunc, ' ', CAST(_24hr_trunc AS STRING))) AS time_stamps,
        app_event,
        event_count
    FROM (
        SELECT FORMAT_TIMESTAMP("%F", collector_tstamp) AS date_trunc,
        FLOOR(CAST(FORMAT_TIMESTAMP("%H", collector_tstamp) AS INT64)/24)*24 AS _24hr_trunc,
        app_event,
        COUNT(event_id) AS event_count
        FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`raw_data`
        GROUP BY
        date_trunc,
        _24hr_trunc,
        app_event
    )


    

    ORDER BY
    agg_tag,
    time_stamps,
    app_event




    );
  
[0m20:36:19.543715 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:e6a7ba18-371e-46f0-b5d8-62dd018eb57b&page=queryresults
[0m20:36:19.548939 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.aggregations (execute): 2024-05-08 20:36:15.689325 => 2024-05-08 20:36:19.548829
[0m20:36:19.550600 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e34a286-63cd-4dcd-90a0-12ee41ce1f7b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106277cd0>]}
[0m20:36:19.551418 [info ] [Thread-3  ]: 2 of 21 OK created sql table model tenant_B.aggregations ....................... [[32mCREATE TABLE (2.2k rows, 76.0 MB processed)[0m in 3.87s]
[0m20:36:19.552054 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.aggregations
[0m20:36:19.552924 [debug] [Thread-2  ]: Began running node model.anomaly_detection.cutoff_dates
[0m20:36:19.553370 [info ] [Thread-2  ]: 3 of 21 START sql table model tenant_B.cutoff_dates ............................ [RUN]
[0m20:36:19.554434 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.cutoff_dates'
[0m20:36:19.554811 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.cutoff_dates
[0m20:36:19.561393 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.cutoff_dates"
[0m20:36:19.562559 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.cutoff_dates (compile): 2024-05-08 20:36:19.555016 => 2024-05-08 20:36:19.562481
[0m20:36:19.562872 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.cutoff_dates
[0m20:36:19.565812 [debug] [Thread-2  ]: Writing runtime sql for node "model.anomaly_detection.cutoff_dates"
[0m20:36:19.566260 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m20:36:19.566428 [debug] [Thread-2  ]: On model.anomaly_detection.cutoff_dates: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.cutoff_dates"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`cutoff_dates`
    
    
    OPTIONS()
    as (
      

select agg_tag, app_event, min(time_stamps) as strt_time
from `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`aggregations`
where event_count > 50
group by app_event, agg_tag 
order by app_event, agg_tag
    );
  
[0m20:36:22.934179 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:45e9e157-c721-46f6-97aa-775ae33dc3b1&page=queryresults
[0m20:36:22.944241 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.cutoff_dates (execute): 2024-05-08 20:36:19.563072 => 2024-05-08 20:36:22.944078
[0m20:36:22.946231 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e34a286-63cd-4dcd-90a0-12ee41ce1f7b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106277af0>]}
[0m20:36:22.947144 [info ] [Thread-2  ]: 3 of 21 OK created sql table model tenant_B.cutoff_dates ....................... [[32mCREATE TABLE (8.0 rows, 103.9 KB processed)[0m in 3.39s]
[0m20:36:22.947736 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.cutoff_dates
[0m20:36:22.949911 [debug] [Thread-4  ]: Began running node model.anomaly_detection.aggregations_cutoff
[0m20:36:22.951800 [info ] [Thread-4  ]: 4 of 21 START sql table model tenant_B.aggregations_cutoff ..................... [RUN]
[0m20:36:22.953225 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.aggregations_cutoff'
[0m20:36:22.953865 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.aggregations_cutoff
[0m20:36:22.963134 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.aggregations_cutoff"
[0m20:36:22.964597 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.aggregations_cutoff (compile): 2024-05-08 20:36:22.954115 => 2024-05-08 20:36:22.964513
[0m20:36:22.964951 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.aggregations_cutoff
[0m20:36:22.968857 [debug] [Thread-4  ]: Writing runtime sql for node "model.anomaly_detection.aggregations_cutoff"
[0m20:36:22.969574 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m20:36:22.969958 [debug] [Thread-4  ]: On model.anomaly_detection.aggregations_cutoff: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.aggregations_cutoff"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`aggregations_cutoff`
    
    
    OPTIONS()
    as (
      

select time_stamps, app_event, agg_tag, event_count
from(
select time_stamps, strt_time, main.app_event, main.agg_tag, event_count
from `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`aggregations` as main
inner join `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`cutoff_dates` as cutoff
on main.agg_tag = cutoff.agg_tag
and main.app_event = cutoff.app_event
order by main.app_event, main.agg_tag, time_stamps)
where time_stamps >= strt_time
    );
  
[0m20:36:26.456526 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:e8a50cfc-4705-4fa8-a39d-4bab1b224af4&page=queryresults
[0m20:36:26.464253 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.aggregations_cutoff (execute): 2024-05-08 20:36:22.965178 => 2024-05-08 20:36:26.464095
[0m20:36:26.466188 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e34a286-63cd-4dcd-90a0-12ee41ce1f7b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106277cd0>]}
[0m20:36:26.467264 [info ] [Thread-4  ]: 4 of 21 OK created sql table model tenant_B.aggregations_cutoff ................ [[32mCREATE TABLE (2.2k rows, 104.2 KB processed)[0m in 3.51s]
[0m20:36:26.468393 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.aggregations_cutoff
[0m20:36:26.471977 [debug] [Thread-1  ]: Began running node model.anomaly_detection.nonrecent_events
[0m20:36:26.472909 [debug] [Thread-2  ]: Began running node model.anomaly_detection.train_data
[0m20:36:26.473614 [info ] [Thread-1  ]: 5 of 21 START sql table model tenant_B.nonrecent_events ........................ [RUN]
[0m20:36:26.476126 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.nonrecent_events'
[0m20:36:26.477096 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.nonrecent_events
[0m20:36:26.486758 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.nonrecent_events"
[0m20:36:26.474162 [info ] [Thread-2  ]: 6 of 21 START sql table model tenant_B.train_data .............................. [RUN]
[0m20:36:26.489152 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.train_data'
[0m20:36:26.489483 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.train_data
[0m20:36:26.494820 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.train_data"
[0m20:36:26.495339 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_events (compile): 2024-05-08 20:36:26.480486 => 2024-05-08 20:36:26.495268
[0m20:36:26.495614 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.nonrecent_events
[0m20:36:26.495800 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.train_data (compile): 2024-05-08 20:36:26.489703 => 2024-05-08 20:36:26.495762
[0m20:36:26.498696 [debug] [Thread-1  ]: Writing runtime sql for node "model.anomaly_detection.nonrecent_events"
[0m20:36:26.498890 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.train_data
[0m20:36:26.501046 [debug] [Thread-2  ]: Writing runtime sql for node "model.anomaly_detection.train_data"
[0m20:36:26.501508 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:36:26.501762 [debug] [Thread-1  ]: On model.anomaly_detection.nonrecent_events: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.nonrecent_events"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`nonrecent_events`
    
    
    OPTIONS()
    as (
      

SELECT MIN(time_stamps) AS strt_time, app_event
FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`aggregations_cutoff`
GROUP BY app_event
HAVING DATE(MIN(time_stamps)) < DATE_SUB("2023-02-09", INTERVAL 30 DAY)
ORDER BY strt_time
    );
  
[0m20:36:26.501883 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m20:36:26.502570 [debug] [Thread-2  ]: On model.anomaly_detection.train_data: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.train_data"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`train_data`
    
    
    OPTIONS()
    as (
      

select *
from `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`aggregations_cutoff`
where DATE(time_stamps) < DATE_SUB("2023-02-09", INTERVAL 10 DAY)
    );
  
[0m20:36:29.333186 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:001ead11-58d3-4548-9db1-707708861120&page=queryresults
[0m20:36:29.336754 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_events (execute): 2024-05-08 20:36:26.495955 => 2024-05-08 20:36:29.336418
[0m20:36:29.338595 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e34a286-63cd-4dcd-90a0-12ee41ce1f7b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106568f10>]}
[0m20:36:29.339820 [info ] [Thread-1  ]: 5 of 21 OK created sql table model tenant_B.nonrecent_events ................... [[32mCREATE TABLE (2.0 rows, 75.9 KB processed)[0m in 2.86s]
[0m20:36:29.340866 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.nonrecent_events
[0m20:36:29.692517 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:12268e10-341d-422c-985a-6ba1a645813f&page=queryresults
[0m20:36:29.697424 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.train_data (execute): 2024-05-08 20:36:26.499071 => 2024-05-08 20:36:29.697021
[0m20:36:29.699645 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e34a286-63cd-4dcd-90a0-12ee41ce1f7b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106568b20>]}
[0m20:36:29.700781 [info ] [Thread-2  ]: 6 of 21 OK created sql table model tenant_B.train_data ......................... [[32mCREATE TABLE (1.9k rows, 103.9 KB processed)[0m in 3.21s]
[0m20:36:29.701719 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.train_data
[0m20:36:29.706000 [debug] [Thread-4  ]: Began running node model.anomaly_detection.IQR_quartiles
[0m20:36:29.707035 [info ] [Thread-4  ]: 7 of 21 START sql table model tenant_B.IQR_quartiles ........................... [RUN]
[0m20:36:29.708793 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_quartiles'
[0m20:36:29.709543 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.IQR_quartiles
[0m20:36:29.716777 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.IQR_quartiles"
[0m20:36:29.718086 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.IQR_quartiles (compile): 2024-05-08 20:36:29.709880 => 2024-05-08 20:36:29.718002
[0m20:36:29.718424 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.IQR_quartiles
[0m20:36:29.722241 [debug] [Thread-4  ]: Writing runtime sql for node "model.anomaly_detection.IQR_quartiles"
[0m20:36:29.722937 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m20:36:29.723343 [debug] [Thread-4  ]: On model.anomaly_detection.IQR_quartiles: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.IQR_quartiles"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_quartiles`
    
    
    OPTIONS()
    as (
      

select   ARRAY(SELECT x FROM UNNEST(output) AS x WITH OFFSET
  WHERE OFFSET BETWEEN 1 AND ARRAY_LENGTH(output) - 2) as output, 
  app_event, agg_tag
  from (
select APPROX_QUANTILES(event_count, 4) AS output, app_event
, agg_tag
from `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`train_data`
group by app_event, agg_tag
order by app_event, agg_tag )
    );
  
[0m20:36:32.868825 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:d7e309df-426b-4e75-9797-1ce0fda90721&page=queryresults
[0m20:36:32.871876 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.IQR_quartiles (execute): 2024-05-08 20:36:29.718646 => 2024-05-08 20:36:32.871768
[0m20:36:32.872975 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e34a286-63cd-4dcd-90a0-12ee41ce1f7b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065791c0>]}
[0m20:36:32.873707 [info ] [Thread-4  ]: 7 of 21 OK created sql table model tenant_B.IQR_quartiles ...................... [[32mCREATE TABLE (8.0 rows, 77.3 KB processed)[0m in 3.17s]
[0m20:36:32.874212 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.IQR_quartiles
[0m20:36:32.875386 [debug] [Thread-1  ]: Began running node model.anomaly_detection.IQR_bounds
[0m20:36:32.875888 [info ] [Thread-1  ]: 8 of 21 START sql table model tenant_B.IQR_bounds .............................. [RUN]
[0m20:36:32.876611 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_bounds'
[0m20:36:32.876875 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.IQR_bounds
[0m20:36:32.883174 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.IQR_bounds"
[0m20:36:32.884190 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.IQR_bounds (compile): 2024-05-08 20:36:32.877048 => 2024-05-08 20:36:32.884131
[0m20:36:32.884429 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.IQR_bounds
[0m20:36:32.887720 [debug] [Thread-1  ]: Writing runtime sql for node "model.anomaly_detection.IQR_bounds"
[0m20:36:32.888368 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:36:32.888687 [debug] [Thread-1  ]: On model.anomaly_detection.IQR_bounds: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.IQR_bounds"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_bounds`
    
    
    OPTIONS()
    as (
      

with temp as (
select quarts, app_event, agg_tag from(
select *
from `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_quartiles`,
unnest(output) as quarts)),

temp_1 as (
select app_event, agg_tag, max(quarts) as q3, min(quarts) as q1
from temp
group by app_event, agg_tag),

temp_2 as (
select app_event, agg_tag, q3, q1, q3-q1 as IQR 
from temp_1)

select app_event, agg_tag, (q1-4.5*IQR) as LB, (q3+4.5*IQR) as UB
from temp_2
order by app_event, agg_tag
    );
  
[0m20:36:36.042572 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:59ae10b1-62a8-4fd3-bc85-0f95c0893e96&page=queryresults
[0m20:36:36.048570 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.IQR_bounds (execute): 2024-05-08 20:36:32.884571 => 2024-05-08 20:36:36.048353
[0m20:36:36.049801 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e34a286-63cd-4dcd-90a0-12ee41ce1f7b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065791c0>]}
[0m20:36:36.050249 [info ] [Thread-1  ]: 8 of 21 OK created sql table model tenant_B.IQR_bounds ......................... [[32mCREATE TABLE (8.0 rows, 460.0 Bytes processed)[0m in 3.17s]
[0m20:36:36.050530 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.IQR_bounds
[0m20:36:36.051096 [debug] [Thread-3  ]: Began running node model.anomaly_detection.IQR_outliers
[0m20:36:36.051662 [info ] [Thread-3  ]: 9 of 21 START sql table model tenant_B.IQR_outliers ............................ [RUN]
[0m20:36:36.052415 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_outliers'
[0m20:36:36.052634 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.IQR_outliers
[0m20:36:36.058798 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.IQR_outliers"
[0m20:36:36.059278 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.IQR_outliers (compile): 2024-05-08 20:36:36.052743 => 2024-05-08 20:36:36.059238
[0m20:36:36.059425 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.IQR_outliers
[0m20:36:36.061796 [debug] [Thread-3  ]: Writing runtime sql for node "model.anomaly_detection.IQR_outliers"
[0m20:36:36.062185 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m20:36:36.062457 [debug] [Thread-3  ]: On model.anomaly_detection.IQR_outliers: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.IQR_outliers"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_outliers`
    
    
    OPTIONS()
    as (
      

with bounds_agg as (
select time_stamps, bounds.app_event as app_event, bounds.agg_tag as agg_tag, event_count, LB, UB
from `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_bounds` as bounds
inner join `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`train_data` as aggs
on bounds.app_event = aggs.app_event
and bounds.agg_tag = aggs.agg_tag
order by bounds.app_event, bounds.agg_tag)

select time_stamps, app_event, agg_tag,
case when event_count > UB then UB
when event_count < LB then LB
else event_count
end as event_count
from bounds_agg
order by app_event, agg_tag, time_stamps
    );
  
[0m20:36:39.130474 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:314af8af-ea1e-4b63-b717-238765ee6257&page=queryresults
[0m20:36:39.134457 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.IQR_outliers (execute): 2024-05-08 20:36:36.059507 => 2024-05-08 20:36:39.134366
[0m20:36:39.135413 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e34a286-63cd-4dcd-90a0-12ee41ce1f7b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106579100>]}
[0m20:36:39.135915 [info ] [Thread-3  ]: 9 of 21 OK created sql table model tenant_B.IQR_outliers ....................... [[32mCREATE TABLE (1.9k rows, 92.7 KB processed)[0m in 3.08s]
[0m20:36:39.136287 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.IQR_outliers
[0m20:36:39.137348 [debug] [Thread-2  ]: Began running node model.anomaly_detection.forecasts
[0m20:36:39.137995 [info ] [Thread-2  ]: 10 of 21 START sql table model tenant_B.forecasts .............................. [RUN]
[0m20:36:39.138754 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.forecasts'
[0m20:36:39.139018 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.forecasts
[0m20:36:39.148848 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.forecasts"
[0m20:36:39.150079 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.forecasts (compile): 2024-05-08 20:36:39.139185 => 2024-05-08 20:36:39.149985
[0m20:36:39.150370 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.forecasts
[0m20:36:39.153635 [debug] [Thread-2  ]: Writing runtime sql for node "model.anomaly_detection.forecasts"
[0m20:36:39.154367 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m20:36:39.154694 [debug] [Thread-2  ]: On model.anomaly_detection.forecasts: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.forecasts"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`forecasts`
    
    
    OPTIONS()
    as (
      -- 3 periods of training * 2 probabality threshold * 4 aggregation levels



-- depends_on: `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_outliers`


  WITH test_set AS (
    SELECT
    time_stamps,
          event_count,
          app_event,
          agg_tag
        FROM
          `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`aggregations_cutoff`
        WHERE
        DATE(time_stamps) >= DATE_SUB("2023-02-09", INTERVAL 10 DAY)
  )

    

      

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_1mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_8hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_2mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_24hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_2mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_12hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_2mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_8hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_2mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_4hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_1mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_4hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_1mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_12hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_1mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_24hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_05mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_4hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_05mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_8hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_05mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_12hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_05mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_24hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

    

      

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_1mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_8hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_2mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_24hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_2mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_12hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_2mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_8hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_2mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_4hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_1mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_4hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_1mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_12hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_1mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_24hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_05mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_4hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_05mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_8hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_05mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_12hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_05mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_24hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        

      

    
    );
  
[0m20:36:39.833693 [debug] [Thread-2  ]: BigQuery adapter: Unhandled error while running:
/* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.forecasts"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`forecasts`
    
    
    OPTIONS()
    as (
      -- 3 periods of training * 2 probabality threshold * 4 aggregation levels



-- depends_on: `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_outliers`


  WITH test_set AS (
    SELECT
    time_stamps,
          event_count,
          app_event,
          agg_tag
        FROM
          `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`aggregations_cutoff`
        WHERE
        DATE(time_stamps) >= DATE_SUB("2023-02-09", INTERVAL 10 DAY)
  )

    

      

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_1mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_8hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_2mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_24hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_2mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_12hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_2mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_8hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_2mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_4hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_1mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_4hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_1mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_12hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_1mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_24hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_05mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_4hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_05mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_8hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_05mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_12hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_05mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_24hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

    

      

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_1mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_8hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_2mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_24hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_2mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_12hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_2mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_8hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_2mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_4hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_1mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_4hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_1mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_12hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_1mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_24hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_05mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_4hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_05mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_8hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_05mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_12hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_05mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_24hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        

      

    
    );
  
[0m20:36:39.834956 [debug] [Thread-2  ]: BigQuery adapter: 404 Not found: Model prj-s-telus-tpm-data-fcfc:tenant_B.models_05mon_12hr

Location: US
Job ID: 9f393972-4683-4446-9b58-3b04b4cee52a

[0m20:36:39.835459 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.forecasts (execute): 2024-05-08 20:36:39.150537 => 2024-05-08 20:36:39.835363
[0m20:36:39.846091 [debug] [Thread-2  ]: Runtime Error in model forecasts (models/anomaly_detection/forecasts.sql)
  404 Not found: Model prj-s-telus-tpm-data-fcfc:tenant_B.models_05mon_12hr
  
  Location: US
  Job ID: 9f393972-4683-4446-9b58-3b04b4cee52a
  
[0m20:36:39.846544 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e34a286-63cd-4dcd-90a0-12ee41ce1f7b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065a6490>]}
[0m20:36:39.847068 [error] [Thread-2  ]: 10 of 21 ERROR creating sql table model tenant_B.forecasts ..................... [[31mERROR[0m in 0.71s]
[0m20:36:39.847427 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.forecasts
[0m20:36:39.848408 [debug] [Thread-4  ]: Began running node model.anomaly_detection.reset_forecasts
[0m20:36:39.848821 [info ] [Thread-4  ]: 11 of 21 SKIP relation tenant_B.reset_forecasts ................................ [[33mSKIP[0m]
[0m20:36:39.849123 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.reset_forecasts
[0m20:36:39.849655 [debug] [Thread-1  ]: Began running node model.anomaly_detection.all_configs
[0m20:36:39.849977 [info ] [Thread-1  ]: 12 of 21 SKIP relation tenant_B.all_configs .................................... [[33mSKIP[0m]
[0m20:36:39.850223 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.all_configs
[0m20:36:39.850622 [debug] [Thread-3  ]: Began running node model.anomaly_detection.nonrecent_configs
[0m20:36:39.850884 [info ] [Thread-3  ]: 13 of 21 SKIP relation tenant_B.nonrecent_configs .............................. [[33mSKIP[0m]
[0m20:36:39.851187 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.nonrecent_configs
[0m20:36:39.851822 [debug] [Thread-2  ]: Began running node model.anomaly_detection.filtered_nonrecent_configs
[0m20:36:39.852141 [info ] [Thread-2  ]: 14 of 21 SKIP relation tenant_B.filtered_nonrecent_configs ..................... [[33mSKIP[0m]
[0m20:36:39.852495 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.filtered_nonrecent_configs
[0m20:36:39.853072 [debug] [Thread-4  ]: Began running node model.anomaly_detection.min_anomalies
[0m20:36:39.853384 [info ] [Thread-4  ]: 15 of 21 SKIP relation tenant_B.min_anomalies .................................. [[33mSKIP[0m]
[0m20:36:39.853637 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.min_anomalies
[0m20:36:39.854083 [debug] [Thread-1  ]: Began running node model.anomaly_detection.min_anomalies_configs
[0m20:36:39.854391 [info ] [Thread-1  ]: 16 of 21 SKIP relation tenant_B.min_anomalies_configs .......................... [[33mSKIP[0m]
[0m20:36:39.854724 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.min_anomalies_configs
[0m20:36:39.855158 [debug] [Thread-3  ]: Began running node model.anomaly_detection.min_RMSD
[0m20:36:39.855480 [info ] [Thread-3  ]: 17 of 21 SKIP relation tenant_B.min_RMSD ....................................... [[33mSKIP[0m]
[0m20:36:39.855735 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.min_RMSD
[0m20:36:39.856177 [debug] [Thread-2  ]: Began running node model.anomaly_detection.control_table
[0m20:36:39.856410 [info ] [Thread-2  ]: 18 of 21 SKIP relation tenant_B.control_table .................................. [[33mSKIP[0m]
[0m20:36:39.856654 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.control_table
[0m20:36:39.857019 [debug] [Thread-4  ]: Began running node model.anomaly_detection.alerting_base
[0m20:36:39.857255 [debug] [Thread-3  ]: Began running node model.tenant_A.my_first_dbt_model
[0m20:36:39.857525 [info ] [Thread-4  ]: 19 of 21 SKIP relation tenant_B.alerting_base .................................. [[33mSKIP[0m]
[0m20:36:39.857839 [info ] [Thread-3  ]: 20 of 21 SKIP relation tenant_B.my_first_dbt_model ............................. [[33mSKIP[0m]
[0m20:36:39.858220 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.alerting_base
[0m20:36:39.858506 [debug] [Thread-3  ]: Finished running node model.tenant_A.my_first_dbt_model
[0m20:36:39.858926 [debug] [Thread-3  ]: Began running node model.anomaly_detection.daily_alerts
[0m20:36:39.859130 [info ] [Thread-3  ]: 21 of 21 SKIP relation tenant_B.daily_alerts ................................... [[33mSKIP[0m]
[0m20:36:39.859334 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.daily_alerts
[0m20:36:39.860352 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m20:36:39.860767 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:36:39.860893 [debug] [MainThread]: Connection 'model.anomaly_detection.IQR_bounds' was properly closed.
[0m20:36:39.861005 [debug] [MainThread]: Connection 'model.anomaly_detection.IQR_outliers' was properly closed.
[0m20:36:39.861112 [debug] [MainThread]: Connection 'model.anomaly_detection.forecasts' was properly closed.
[0m20:36:39.861214 [debug] [MainThread]: Connection 'model.anomaly_detection.IQR_quartiles' was properly closed.
[0m20:36:39.861398 [info ] [MainThread]: 
[0m20:36:39.861619 [info ] [MainThread]: Finished running 21 table models in 0 hours 0 minutes and 32.47 seconds (32.47s).
[0m20:36:39.862333 [debug] [MainThread]: Command end result
[0m20:36:39.868412 [info ] [MainThread]: 
[0m20:36:39.868664 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m20:36:39.868814 [info ] [MainThread]: 
[0m20:36:39.869065 [error] [MainThread]: [33mRuntime Error in model forecasts (models/anomaly_detection/forecasts.sql)[0m
[0m20:36:39.869223 [error] [MainThread]:   404 Not found: Model prj-s-telus-tpm-data-fcfc:tenant_B.models_05mon_12hr
[0m20:36:39.869357 [error] [MainThread]:   
[0m20:36:39.869487 [error] [MainThread]:   Location: US
[0m20:36:39.869614 [error] [MainThread]:   Job ID: 9f393972-4683-4446-9b58-3b04b4cee52a
[0m20:36:39.869738 [error] [MainThread]:   
[0m20:36:39.869888 [info ] [MainThread]: 
[0m20:36:39.870037 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=1 SKIP=11 TOTAL=21
[0m20:36:39.870298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f27460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fcf6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062fce80>]}
[0m20:36:39.870499 [debug] [MainThread]: Flushing usage events


============================== 2024-05-08 20:37:08.447805 | d96ce089-4fe0-4c89-9551-03fabbdba62b ==============================
[0m20:37:08.447805 [info ] [MainThread]: Running with dbt=1.4.1
[0m20:37:08.448677 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/rana/TPM_dbt_poc/tenant_B', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'deps', 'rpc_method': 'deps', 'indirect_selection': 'eager'}
[0m20:37:08.448792 [debug] [MainThread]: Tracking: tracking
[0m20:37:08.474161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108707550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10876fb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10876fbb0>]}
[0m20:37:08.475756 [debug] [MainThread]: Set downloads directory='/var/folders/2b/s3pxyycs63s1dl1mn2p9mnq40000gn/T/dbt-downloads-cs5pte9m'
[0m20:37:08.487108 [info ] [MainThread]: Installing /Users/rana/TPM_dbt_poc/anomaly_detection
[0m20:37:08.487529 [debug] [MainThread]:   Creating symlink to local dependency.
[0m20:37:08.487724 [info ] [MainThread]:   Installed from <local @ /Users/rana/TPM_dbt_poc/anomaly_detection>
[0m20:37:08.487898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'd96ce089-4fe0-4c89-9551-03fabbdba62b', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108798fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108798f70>]}
[0m20:37:08.488267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108764e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087644f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108798f40>]}
[0m20:37:08.488403 [debug] [MainThread]: Flushing usage events


============================== 2024-05-08 20:37:13.348408 | c0b389a7-1931-43d3-905c-332abd2b5e3a ==============================
[0m20:37:13.348408 [info ] [MainThread]: Running with dbt=1.4.1
[0m20:37:13.349427 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/rana/TPM_dbt_poc/tenant_B', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m20:37:13.349553 [debug] [MainThread]: Tracking: tracking
[0m20:37:13.371693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e07100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e07d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e07640>]}
[0m20:37:13.390887 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m20:37:13.391129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d9f190>]}
[0m20:37:13.724221 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m20:37:13.738103 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/min_anomalies.sql
[0m20:37:13.741131 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/min_anomalies.sql
[0m20:37:13.741924 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/aggregations_cutoff.sql
[0m20:37:13.745731 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/aggregations_cutoff.sql
[0m20:37:13.746503 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/IQR_outliers.sql
[0m20:37:13.749851 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/IQR_outliers.sql
[0m20:37:13.750663 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/cutoff_dates.sql
[0m20:37:13.753360 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/cutoff_dates.sql
[0m20:37:13.754055 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/min_RMSD.sql
[0m20:37:13.756464 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/min_RMSD.sql
[0m20:37:13.757259 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/forecasts.sql
[0m20:37:13.764970 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/forecasts.sql
[0m20:37:13.765891 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/IQR_quartiles.sql
[0m20:37:13.768695 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/IQR_quartiles.sql
[0m20:37:13.769427 [debug] [MainThread]: 1699: static parser successfully parsed anomaly_detection/filtered_nonrecent_configs.sql
[0m20:37:13.771177 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/control_table.sql
[0m20:37:13.774057 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/control_table.sql
[0m20:37:13.774870 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/alerting_base.sql
[0m20:37:13.778893 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/alerting_base.sql
[0m20:37:13.779604 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/daily_alerts.sql
[0m20:37:13.782235 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/daily_alerts.sql
[0m20:37:13.782949 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/train_data.sql
[0m20:37:13.785731 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/train_data.sql
[0m20:37:13.786459 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/nonrecent_configs.sql
[0m20:37:13.789228 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/nonrecent_configs.sql
[0m20:37:13.789905 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/aggregations.sql
[0m20:37:13.793687 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/aggregations.sql
[0m20:37:13.794430 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/IQR_bounds.sql
[0m20:37:13.797799 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/IQR_bounds.sql
[0m20:37:13.798574 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/raw_data.sql
[0m20:37:13.801955 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/raw_data.sql
[0m20:37:13.802697 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/all_configs.sql
[0m20:37:13.805536 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/all_configs.sql
[0m20:37:13.806266 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/nonrecent_events.sql
[0m20:37:13.809877 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/nonrecent_events.sql
[0m20:37:13.810611 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/min_anomalies_configs.sql
[0m20:37:13.813622 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/min_anomalies_configs.sql
[0m20:37:13.814350 [debug] [MainThread]: 1603: static parser failed on anomaly_detection/reset_forecasts.sql
[0m20:37:13.817379 [debug] [MainThread]: 1602: parser fallback to jinja rendering on anomaly_detection/reset_forecasts.sql
[0m20:37:13.843364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11111cca0>]}
[0m20:37:13.847922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e230a0>]}
[0m20:37:13.848120 [info ] [MainThread]: Found 21 models, 0 tests, 0 snapshots, 0 analyses, 335 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m20:37:13.848272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e8e580>]}
[0m20:37:13.849368 [info ] [MainThread]: 
[0m20:37:13.850298 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m20:37:13.851408 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_prj-s-telus-tpm-data-fcfc'
[0m20:37:13.851634 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:37:15.175961 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_prj-s-telus-tpm-data-fcfc_tenant_B'
[0m20:37:15.176420 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:37:15.486114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e8e580>]}
[0m20:37:15.487639 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:37:15.488044 [info ] [MainThread]: 
[0m20:37:15.495512 [debug] [Thread-1  ]: Began running node model.anomaly_detection.raw_data
[0m20:37:15.496204 [info ] [Thread-1  ]: 1 of 21 START sql table model tenant_B.raw_data ................................ [RUN]
[0m20:37:15.497032 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.raw_data'
[0m20:37:15.497345 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.raw_data
[0m20:37:15.503221 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.raw_data"
[0m20:37:15.504021 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.raw_data (compile): 2024-05-08 20:37:15.497535 => 2024-05-08 20:37:15.503931
[0m20:37:15.504262 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.raw_data
[0m20:37:15.521268 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:37:15.867954 [debug] [Thread-1  ]: Writing runtime sql for node "model.anomaly_detection.raw_data"
[0m20:37:15.868705 [debug] [Thread-1  ]: On model.anomaly_detection.raw_data: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.raw_data"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`raw_data`
    
    
    OPTIONS()
    as (
      
SELECT collector_tstamp, event_id, app_event
FROM `prj-s-telus-tpm-data-fcfc`.`dbt_rhashemi`.`sample_table_final`
WHERE DATE( collector_tstamp ) >= DATE_SUB("2023-02-09", INTERVAL 90 DAY) AND DATE( collector_tstamp ) < "2023-02-09"
    );
  
[0m20:37:22.710536 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:b2261c75-e895-4251-b889-9716ce12a192&page=queryresults
[0m20:37:22.719934 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.raw_data (execute): 2024-05-08 20:37:15.504402 => 2024-05-08 20:37:22.719891
[0m20:37:22.720411 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e234c0>]}
[0m20:37:22.720650 [info ] [Thread-1  ]: 1 of 21 OK created sql table model tenant_B.raw_data ........................... [[32mCREATE TABLE (1.1m rows, 76.0 MB processed)[0m in 7.22s]
[0m20:37:22.721397 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.raw_data
[0m20:37:22.721829 [debug] [Thread-3  ]: Began running node model.anomaly_detection.aggregations
[0m20:37:22.722182 [info ] [Thread-3  ]: 2 of 21 START sql table model tenant_B.aggregations ............................ [RUN]
[0m20:37:22.722619 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.aggregations'
[0m20:37:22.722737 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.aggregations
[0m20:37:22.726405 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.aggregations"
[0m20:37:22.726854 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.aggregations (compile): 2024-05-08 20:37:22.722808 => 2024-05-08 20:37:22.726824
[0m20:37:22.726972 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.aggregations
[0m20:37:22.728006 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m20:37:23.015991 [debug] [Thread-3  ]: Writing runtime sql for node "model.anomaly_detection.aggregations"
[0m20:37:23.018947 [debug] [Thread-3  ]: On model.anomaly_detection.aggregations: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.aggregations"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`aggregations`
    
    
    OPTIONS()
    as (
      



    SELECT "4hr" AS agg_tag,
        PARSE_TIMESTAMP("%F %H", CONCAT(date_trunc, ' ', CAST(_4hr_trunc AS STRING))) AS time_stamps,
        app_event,
        event_count
    FROM (
        SELECT FORMAT_TIMESTAMP("%F", collector_tstamp) AS date_trunc,
        FLOOR(CAST(FORMAT_TIMESTAMP("%H", collector_tstamp) AS INT64)/4)*4 AS _4hr_trunc,
        app_event,
        COUNT(event_id) AS event_count
        FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`raw_data`
        GROUP BY
        date_trunc,
        _4hr_trunc,
        app_event
    )


    
    UNION ALL
    


    SELECT "8hr" AS agg_tag,
        PARSE_TIMESTAMP("%F %H", CONCAT(date_trunc, ' ', CAST(_8hr_trunc AS STRING))) AS time_stamps,
        app_event,
        event_count
    FROM (
        SELECT FORMAT_TIMESTAMP("%F", collector_tstamp) AS date_trunc,
        FLOOR(CAST(FORMAT_TIMESTAMP("%H", collector_tstamp) AS INT64)/8)*8 AS _8hr_trunc,
        app_event,
        COUNT(event_id) AS event_count
        FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`raw_data`
        GROUP BY
        date_trunc,
        _8hr_trunc,
        app_event
    )


    
    UNION ALL
    


    SELECT "12hr" AS agg_tag,
        PARSE_TIMESTAMP("%F %H", CONCAT(date_trunc, ' ', CAST(_12hr_trunc AS STRING))) AS time_stamps,
        app_event,
        event_count
    FROM (
        SELECT FORMAT_TIMESTAMP("%F", collector_tstamp) AS date_trunc,
        FLOOR(CAST(FORMAT_TIMESTAMP("%H", collector_tstamp) AS INT64)/12)*12 AS _12hr_trunc,
        app_event,
        COUNT(event_id) AS event_count
        FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`raw_data`
        GROUP BY
        date_trunc,
        _12hr_trunc,
        app_event
    )


    
    UNION ALL
    


    SELECT "24hr" AS agg_tag,
        PARSE_TIMESTAMP("%F %H", CONCAT(date_trunc, ' ', CAST(_24hr_trunc AS STRING))) AS time_stamps,
        app_event,
        event_count
    FROM (
        SELECT FORMAT_TIMESTAMP("%F", collector_tstamp) AS date_trunc,
        FLOOR(CAST(FORMAT_TIMESTAMP("%H", collector_tstamp) AS INT64)/24)*24 AS _24hr_trunc,
        app_event,
        COUNT(event_id) AS event_count
        FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`raw_data`
        GROUP BY
        date_trunc,
        _24hr_trunc,
        app_event
    )


    

    ORDER BY
    agg_tag,
    time_stamps,
    app_event




    );
  
[0m20:37:26.912009 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:f893a3ff-7b68-44e4-9b78-ffdd31069490&page=queryresults
[0m20:37:26.915187 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.aggregations (execute): 2024-05-08 20:37:22.727044 => 2024-05-08 20:37:26.915093
[0m20:37:26.916241 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111dd3d0>]}
[0m20:37:26.916887 [info ] [Thread-3  ]: 2 of 21 OK created sql table model tenant_B.aggregations ....................... [[32mCREATE TABLE (2.2k rows, 76.0 MB processed)[0m in 4.19s]
[0m20:37:26.917348 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.aggregations
[0m20:37:26.918254 [debug] [Thread-2  ]: Began running node model.anomaly_detection.cutoff_dates
[0m20:37:26.918689 [info ] [Thread-2  ]: 3 of 21 START sql table model tenant_B.cutoff_dates ............................ [RUN]
[0m20:37:26.919406 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.cutoff_dates'
[0m20:37:26.919664 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.cutoff_dates
[0m20:37:26.925089 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.cutoff_dates"
[0m20:37:26.926171 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.cutoff_dates (compile): 2024-05-08 20:37:26.919832 => 2024-05-08 20:37:26.926090
[0m20:37:26.926426 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.cutoff_dates
[0m20:37:26.928691 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m20:37:27.391621 [debug] [Thread-2  ]: Writing runtime sql for node "model.anomaly_detection.cutoff_dates"
[0m20:37:27.394857 [debug] [Thread-2  ]: On model.anomaly_detection.cutoff_dates: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.cutoff_dates"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`cutoff_dates`
    
    
    OPTIONS()
    as (
      

select agg_tag, app_event, min(time_stamps) as strt_time
from `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`aggregations`
where event_count > 50
group by app_event, agg_tag 
order by app_event, agg_tag
    );
  
[0m20:37:30.113236 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:7b18e595-d313-47b2-a935-33718f176059&page=queryresults
[0m20:37:30.116614 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.cutoff_dates (execute): 2024-05-08 20:37:26.926582 => 2024-05-08 20:37:30.116534
[0m20:37:30.117338 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111dd370>]}
[0m20:37:30.117728 [info ] [Thread-2  ]: 3 of 21 OK created sql table model tenant_B.cutoff_dates ....................... [[32mCREATE TABLE (8.0 rows, 103.9 KB processed)[0m in 3.20s]
[0m20:37:30.118000 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.cutoff_dates
[0m20:37:30.118547 [debug] [Thread-4  ]: Began running node model.anomaly_detection.aggregations_cutoff
[0m20:37:30.118987 [info ] [Thread-4  ]: 4 of 21 START sql table model tenant_B.aggregations_cutoff ..................... [RUN]
[0m20:37:30.119471 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.aggregations_cutoff'
[0m20:37:30.119634 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.aggregations_cutoff
[0m20:37:30.123186 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.aggregations_cutoff"
[0m20:37:30.123892 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.aggregations_cutoff (compile): 2024-05-08 20:37:30.119738 => 2024-05-08 20:37:30.123852
[0m20:37:30.124058 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.aggregations_cutoff
[0m20:37:30.126386 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m20:37:30.400206 [debug] [Thread-4  ]: Writing runtime sql for node "model.anomaly_detection.aggregations_cutoff"
[0m20:37:30.401265 [debug] [Thread-4  ]: On model.anomaly_detection.aggregations_cutoff: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.aggregations_cutoff"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`aggregations_cutoff`
    
    
    OPTIONS()
    as (
      

select time_stamps, app_event, agg_tag, event_count
from(
select time_stamps, strt_time, main.app_event, main.agg_tag, event_count
from `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`aggregations` as main
inner join `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`cutoff_dates` as cutoff
on main.agg_tag = cutoff.agg_tag
and main.app_event = cutoff.app_event
order by main.app_event, main.agg_tag, time_stamps)
where time_stamps >= strt_time
    );
  
[0m20:37:33.368256 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:715f50d5-70f9-4604-8054-c3f94546275b&page=queryresults
[0m20:37:33.372005 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.aggregations_cutoff (execute): 2024-05-08 20:37:30.124148 => 2024-05-08 20:37:33.371911
[0m20:37:33.372924 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11163f4f0>]}
[0m20:37:33.373449 [info ] [Thread-4  ]: 4 of 21 OK created sql table model tenant_B.aggregations_cutoff ................ [[32mCREATE TABLE (2.2k rows, 104.2 KB processed)[0m in 3.25s]
[0m20:37:33.373830 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.aggregations_cutoff
[0m20:37:33.374707 [debug] [Thread-1  ]: Began running node model.anomaly_detection.nonrecent_events
[0m20:37:33.375153 [debug] [Thread-2  ]: Began running node model.anomaly_detection.train_data
[0m20:37:33.375446 [info ] [Thread-1  ]: 5 of 21 START sql table model tenant_B.nonrecent_events ........................ [RUN]
[0m20:37:33.376176 [info ] [Thread-2  ]: 6 of 21 START sql table model tenant_B.train_data .............................. [RUN]
[0m20:37:33.377212 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.nonrecent_events'
[0m20:37:33.377822 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.train_data'
[0m20:37:33.378106 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.nonrecent_events
[0m20:37:33.378369 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.train_data
[0m20:37:33.383783 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.nonrecent_events"
[0m20:37:33.387034 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.train_data"
[0m20:37:33.388146 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.train_data (compile): 2024-05-08 20:37:33.383991 => 2024-05-08 20:37:33.388023
[0m20:37:33.388515 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.train_data
[0m20:37:33.388704 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_events (compile): 2024-05-08 20:37:33.378551 => 2024-05-08 20:37:33.388653
[0m20:37:33.390974 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m20:37:33.391258 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.nonrecent_events
[0m20:37:33.394009 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:37:33.699769 [debug] [Thread-2  ]: Writing runtime sql for node "model.anomaly_detection.train_data"
[0m20:37:33.703406 [debug] [Thread-2  ]: On model.anomaly_detection.train_data: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.train_data"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`train_data`
    
    
    OPTIONS()
    as (
      

select *
from `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`aggregations_cutoff`
where DATE(time_stamps) < DATE_SUB("2023-02-09", INTERVAL 10 DAY)
    );
  
[0m20:37:33.716277 [debug] [Thread-1  ]: Writing runtime sql for node "model.anomaly_detection.nonrecent_events"
[0m20:37:33.717125 [debug] [Thread-1  ]: On model.anomaly_detection.nonrecent_events: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.nonrecent_events"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`nonrecent_events`
    
    
    OPTIONS()
    as (
      

SELECT MIN(time_stamps) AS strt_time, app_event
FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`aggregations_cutoff`
GROUP BY app_event
HAVING DATE(MIN(time_stamps)) < DATE_SUB("2023-02-09", INTERVAL 30 DAY)
ORDER BY strt_time
    );
  
[0m20:37:36.422162 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:8c80a757-5cb8-4b08-bf91-bdec4e2d1447&page=queryresults
[0m20:37:36.426944 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.train_data (execute): 2024-05-08 20:37:33.388840 => 2024-05-08 20:37:36.426832
[0m20:37:36.428198 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11113bf10>]}
[0m20:37:36.429674 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:730da557-c18e-464c-8943-bed7fb85cd41&page=queryresults
[0m20:37:36.430305 [info ] [Thread-2  ]: 6 of 21 OK created sql table model tenant_B.train_data ......................... [[32mCREATE TABLE (1.9k rows, 103.9 KB processed)[0m in 3.05s]
[0m20:37:36.432360 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_events (execute): 2024-05-08 20:37:33.392245 => 2024-05-08 20:37:36.432303
[0m20:37:36.432768 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.train_data
[0m20:37:36.433480 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111d2190>]}
[0m20:37:36.434322 [info ] [Thread-1  ]: 5 of 21 OK created sql table model tenant_B.nonrecent_events ................... [[32mCREATE TABLE (2.0 rows, 75.9 KB processed)[0m in 3.06s]
[0m20:37:36.434781 [debug] [Thread-4  ]: Began running node model.anomaly_detection.IQR_quartiles
[0m20:37:36.435113 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.nonrecent_events
[0m20:37:36.435454 [info ] [Thread-4  ]: 7 of 21 START sql table model tenant_B.IQR_quartiles ........................... [RUN]
[0m20:37:36.436402 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_quartiles'
[0m20:37:36.436655 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.IQR_quartiles
[0m20:37:36.441622 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.IQR_quartiles"
[0m20:37:36.443649 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.IQR_quartiles (compile): 2024-05-08 20:37:36.436805 => 2024-05-08 20:37:36.443570
[0m20:37:36.443930 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.IQR_quartiles
[0m20:37:36.445976 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m20:37:36.727526 [debug] [Thread-4  ]: Writing runtime sql for node "model.anomaly_detection.IQR_quartiles"
[0m20:37:36.729229 [debug] [Thread-4  ]: On model.anomaly_detection.IQR_quartiles: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.IQR_quartiles"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_quartiles`
    
    
    OPTIONS()
    as (
      

select   ARRAY(SELECT x FROM UNNEST(output) AS x WITH OFFSET
  WHERE OFFSET BETWEEN 1 AND ARRAY_LENGTH(output) - 2) as output, 
  app_event, agg_tag
  from (
select APPROX_QUANTILES(event_count, 4) AS output, app_event
, agg_tag
from `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`train_data`
group by app_event, agg_tag
order by app_event, agg_tag )
    );
  
[0m20:37:39.691338 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:4ce8a7d6-d15c-4dd4-9353-98ca80921fc4&page=queryresults
[0m20:37:39.696724 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.IQR_quartiles (execute): 2024-05-08 20:37:36.444064 => 2024-05-08 20:37:39.696538
[0m20:37:39.698019 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11113be50>]}
[0m20:37:39.698647 [info ] [Thread-4  ]: 7 of 21 OK created sql table model tenant_B.IQR_quartiles ...................... [[32mCREATE TABLE (8.0 rows, 77.3 KB processed)[0m in 3.26s]
[0m20:37:39.699082 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.IQR_quartiles
[0m20:37:39.699848 [debug] [Thread-2  ]: Began running node model.anomaly_detection.IQR_bounds
[0m20:37:39.700446 [info ] [Thread-2  ]: 8 of 21 START sql table model tenant_B.IQR_bounds .............................. [RUN]
[0m20:37:39.701310 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_bounds'
[0m20:37:39.701704 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.IQR_bounds
[0m20:37:39.713509 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.IQR_bounds"
[0m20:37:39.715113 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.IQR_bounds (compile): 2024-05-08 20:37:39.701957 => 2024-05-08 20:37:39.714984
[0m20:37:39.715509 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.IQR_bounds
[0m20:37:39.717801 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m20:37:39.998888 [debug] [Thread-2  ]: Writing runtime sql for node "model.anomaly_detection.IQR_bounds"
[0m20:37:40.002833 [debug] [Thread-2  ]: On model.anomaly_detection.IQR_bounds: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.IQR_bounds"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_bounds`
    
    
    OPTIONS()
    as (
      

with temp as (
select quarts, app_event, agg_tag from(
select *
from `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_quartiles`,
unnest(output) as quarts)),

temp_1 as (
select app_event, agg_tag, max(quarts) as q3, min(quarts) as q1
from temp
group by app_event, agg_tag),

temp_2 as (
select app_event, agg_tag, q3, q1, q3-q1 as IQR 
from temp_1)

select app_event, agg_tag, (q1-4.5*IQR) as LB, (q3+4.5*IQR) as UB
from temp_2
order by app_event, agg_tag
    );
  
[0m20:37:42.825422 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:390e4018-a2ef-44d2-95ec-dfad0e41b715&page=queryresults
[0m20:37:42.829685 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.IQR_bounds (execute): 2024-05-08 20:37:39.715658 => 2024-05-08 20:37:42.829561
[0m20:37:42.830779 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e89be0>]}
[0m20:37:42.831456 [info ] [Thread-2  ]: 8 of 21 OK created sql table model tenant_B.IQR_bounds ......................... [[32mCREATE TABLE (8.0 rows, 460.0 Bytes processed)[0m in 3.13s]
[0m20:37:42.831950 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.IQR_bounds
[0m20:37:42.833050 [debug] [Thread-1  ]: Began running node model.anomaly_detection.IQR_outliers
[0m20:37:42.833811 [info ] [Thread-1  ]: 9 of 21 START sql table model tenant_B.IQR_outliers ............................ [RUN]
[0m20:37:42.834703 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.IQR_outliers'
[0m20:37:42.835009 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.IQR_outliers
[0m20:37:42.841013 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.IQR_outliers"
[0m20:37:42.842010 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.IQR_outliers (compile): 2024-05-08 20:37:42.835188 => 2024-05-08 20:37:42.841938
[0m20:37:42.842254 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.IQR_outliers
[0m20:37:42.844569 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:37:43.112639 [debug] [Thread-1  ]: Writing runtime sql for node "model.anomaly_detection.IQR_outliers"
[0m20:37:43.115961 [debug] [Thread-1  ]: On model.anomaly_detection.IQR_outliers: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.IQR_outliers"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_outliers`
    
    
    OPTIONS()
    as (
      

with bounds_agg as (
select time_stamps, bounds.app_event as app_event, bounds.agg_tag as agg_tag, event_count, LB, UB
from `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_bounds` as bounds
inner join `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`train_data` as aggs
on bounds.app_event = aggs.app_event
and bounds.agg_tag = aggs.agg_tag
order by bounds.app_event, bounds.agg_tag)

select time_stamps, app_event, agg_tag,
case when event_count > UB then UB
when event_count < LB then LB
else event_count
end as event_count
from bounds_agg
order by app_event, agg_tag, time_stamps
    );
  
[0m20:37:46.184062 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:308fb317-4f65-4f80-9b8d-972d2d188a25&page=queryresults
[0m20:37:46.185897 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.IQR_outliers (execute): 2024-05-08 20:37:42.842399 => 2024-05-08 20:37:46.185835
[0m20:37:46.186506 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111c1f40>]}
[0m20:37:46.186892 [info ] [Thread-1  ]: 9 of 21 OK created sql table model tenant_B.IQR_outliers ....................... [[32mCREATE TABLE (1.9k rows, 92.7 KB processed)[0m in 3.35s]
[0m20:37:46.187197 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.IQR_outliers
[0m20:37:46.187852 [debug] [Thread-3  ]: Began running node model.anomaly_detection.forecasts
[0m20:37:46.188443 [info ] [Thread-3  ]: 10 of 21 START sql table model tenant_B.forecasts .............................. [RUN]
[0m20:37:46.189081 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.forecasts'
[0m20:37:46.189454 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.forecasts
[0m20:37:46.196516 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.forecasts"
[0m20:37:46.200269 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.forecasts (compile): 2024-05-08 20:37:46.189593 => 2024-05-08 20:37:46.200200
[0m20:37:46.200541 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.forecasts
[0m20:37:46.203951 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m20:37:46.205315 [debug] [Thread-3  ]: On model.anomaly_detection.forecasts: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.forecasts"} */

        create or replace model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_8hr`
      options(
        MODEL_TYPE="ARIMA_PLUS",
        TIME_SERIES_TIMESTAMP_COL="time_stamps",
        TIME_SERIES_DATA_COL="event_count",
        TIME_SERIES_ID_COL=['app_event', 'agg_tag'],
        HORIZON=120,
        HOLIDAY_REGION="CA"
      ) as (
        SELECT
          time_stamps,
          event_count,
          app_event,
          agg_tag
        FROM
          `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_outliers`
        WHERE
          DATE(time_stamps) >= DATE_SUB("2023-02-09", INTERVAL 60 DAY)
          AND DATE(time_stamps) < DATE_SUB("2023-02-09", INTERVAL 10 DAY)
          AND agg_tag = "8hr"
      );

    

      create or replace model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_24hr`
      options(
        MODEL_TYPE="ARIMA_PLUS",
        TIME_SERIES_TIMESTAMP_COL="time_stamps",
        TIME_SERIES_DATA_COL="event_count",
        TIME_SERIES_ID_COL=['app_event', 'agg_tag'],
        HORIZON=120,
        HOLIDAY_REGION="CA"
      ) as (
        SELECT
          time_stamps,
          event_count,
          app_event,
          agg_tag
        FROM
          `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_outliers`
        WHERE
          DATE(time_stamps) >= DATE_SUB("2023-02-09", INTERVAL 90 DAY)
          AND DATE(time_stamps) < DATE_SUB("2023-02-09", INTERVAL 10 DAY)
          AND agg_tag = "24hr"
      );

    

      create or replace model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_12hr`
      options(
        MODEL_TYPE="ARIMA_PLUS",
        TIME_SERIES_TIMESTAMP_COL="time_stamps",
        TIME_SERIES_DATA_COL="event_count",
        TIME_SERIES_ID_COL=['app_event', 'agg_tag'],
        HORIZON=120,
        HOLIDAY_REGION="CA"
      ) as (
        SELECT
          time_stamps,
          event_count,
          app_event,
          agg_tag
        FROM
          `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_outliers`
        WHERE
          DATE(time_stamps) >= DATE_SUB("2023-02-09", INTERVAL 90 DAY)
          AND DATE(time_stamps) < DATE_SUB("2023-02-09", INTERVAL 10 DAY)
          AND agg_tag = "12hr"
      );

    

      create or replace model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_8hr`
      options(
        MODEL_TYPE="ARIMA_PLUS",
        TIME_SERIES_TIMESTAMP_COL="time_stamps",
        TIME_SERIES_DATA_COL="event_count",
        TIME_SERIES_ID_COL=['app_event', 'agg_tag'],
        HORIZON=120,
        HOLIDAY_REGION="CA"
      ) as (
        SELECT
          time_stamps,
          event_count,
          app_event,
          agg_tag
        FROM
          `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_outliers`
        WHERE
          DATE(time_stamps) >= DATE_SUB("2023-02-09", INTERVAL 90 DAY)
          AND DATE(time_stamps) < DATE_SUB("2023-02-09", INTERVAL 10 DAY)
          AND agg_tag = "8hr"
      );

    

      create or replace model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_4hr`
      options(
        MODEL_TYPE="ARIMA_PLUS",
        TIME_SERIES_TIMESTAMP_COL="time_stamps",
        TIME_SERIES_DATA_COL="event_count",
        TIME_SERIES_ID_COL=['app_event', 'agg_tag'],
        HORIZON=120,
        HOLIDAY_REGION="CA"
      ) as (
        SELECT
          time_stamps,
          event_count,
          app_event,
          agg_tag
        FROM
          `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_outliers`
        WHERE
          DATE(time_stamps) >= DATE_SUB("2023-02-09", INTERVAL 90 DAY)
          AND DATE(time_stamps) < DATE_SUB("2023-02-09", INTERVAL 10 DAY)
          AND agg_tag = "4hr"
      );

    

      create or replace model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_4hr`
      options(
        MODEL_TYPE="ARIMA_PLUS",
        TIME_SERIES_TIMESTAMP_COL="time_stamps",
        TIME_SERIES_DATA_COL="event_count",
        TIME_SERIES_ID_COL=['app_event', 'agg_tag'],
        HORIZON=120,
        HOLIDAY_REGION="CA"
      ) as (
        SELECT
          time_stamps,
          event_count,
          app_event,
          agg_tag
        FROM
          `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_outliers`
        WHERE
          DATE(time_stamps) >= DATE_SUB("2023-02-09", INTERVAL 60 DAY)
          AND DATE(time_stamps) < DATE_SUB("2023-02-09", INTERVAL 10 DAY)
          AND agg_tag = "4hr"
      );

    

      create or replace model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_12hr`
      options(
        MODEL_TYPE="ARIMA_PLUS",
        TIME_SERIES_TIMESTAMP_COL="time_stamps",
        TIME_SERIES_DATA_COL="event_count",
        TIME_SERIES_ID_COL=['app_event', 'agg_tag'],
        HORIZON=120,
        HOLIDAY_REGION="CA"
      ) as (
        SELECT
          time_stamps,
          event_count,
          app_event,
          agg_tag
        FROM
          `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_outliers`
        WHERE
          DATE(time_stamps) >= DATE_SUB("2023-02-09", INTERVAL 60 DAY)
          AND DATE(time_stamps) < DATE_SUB("2023-02-09", INTERVAL 10 DAY)
          AND agg_tag = "12hr"
      );

    

      create or replace model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_24hr`
      options(
        MODEL_TYPE="ARIMA_PLUS",
        TIME_SERIES_TIMESTAMP_COL="time_stamps",
        TIME_SERIES_DATA_COL="event_count",
        TIME_SERIES_ID_COL=['app_event', 'agg_tag'],
        HORIZON=120,
        HOLIDAY_REGION="CA"
      ) as (
        SELECT
          time_stamps,
          event_count,
          app_event,
          agg_tag
        FROM
          `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_outliers`
        WHERE
          DATE(time_stamps) >= DATE_SUB("2023-02-09", INTERVAL 60 DAY)
          AND DATE(time_stamps) < DATE_SUB("2023-02-09", INTERVAL 10 DAY)
          AND agg_tag = "24hr"
      );

    

      create or replace model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_4hr`
      options(
        MODEL_TYPE="ARIMA_PLUS",
        TIME_SERIES_TIMESTAMP_COL="time_stamps",
        TIME_SERIES_DATA_COL="event_count",
        TIME_SERIES_ID_COL=['app_event', 'agg_tag'],
        HORIZON=120,
        HOLIDAY_REGION="CA"
      ) as (
        SELECT
          time_stamps,
          event_count,
          app_event,
          agg_tag
        FROM
          `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_outliers`
        WHERE
          DATE(time_stamps) >= DATE_SUB("2023-02-09", INTERVAL 30 DAY)
          AND DATE(time_stamps) < DATE_SUB("2023-02-09", INTERVAL 10 DAY)
          AND agg_tag = "4hr"
      );

    

      create or replace model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_8hr`
      options(
        MODEL_TYPE="ARIMA_PLUS",
        TIME_SERIES_TIMESTAMP_COL="time_stamps",
        TIME_SERIES_DATA_COL="event_count",
        TIME_SERIES_ID_COL=['app_event', 'agg_tag'],
        HORIZON=120,
        HOLIDAY_REGION="CA"
      ) as (
        SELECT
          time_stamps,
          event_count,
          app_event,
          agg_tag
        FROM
          `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_outliers`
        WHERE
          DATE(time_stamps) >= DATE_SUB("2023-02-09", INTERVAL 30 DAY)
          AND DATE(time_stamps) < DATE_SUB("2023-02-09", INTERVAL 10 DAY)
          AND agg_tag = "8hr"
      );

    

      create or replace model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_12hr`
      options(
        MODEL_TYPE="ARIMA_PLUS",
        TIME_SERIES_TIMESTAMP_COL="time_stamps",
        TIME_SERIES_DATA_COL="event_count",
        TIME_SERIES_ID_COL=['app_event', 'agg_tag'],
        HORIZON=120,
        HOLIDAY_REGION="CA"
      ) as (
        SELECT
          time_stamps,
          event_count,
          app_event,
          agg_tag
        FROM
          `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_outliers`
        WHERE
          DATE(time_stamps) >= DATE_SUB("2023-02-09", INTERVAL 30 DAY)
          AND DATE(time_stamps) < DATE_SUB("2023-02-09", INTERVAL 10 DAY)
          AND agg_tag = "12hr"
      );

    

      create or replace model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_24hr`
      options(
        MODEL_TYPE="ARIMA_PLUS",
        TIME_SERIES_TIMESTAMP_COL="time_stamps",
        TIME_SERIES_DATA_COL="event_count",
        TIME_SERIES_ID_COL=['app_event', 'agg_tag'],
        HORIZON=120,
        HOLIDAY_REGION="CA"
      ) as (
        SELECT
          time_stamps,
          event_count,
          app_event,
          agg_tag
        FROM
          `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_outliers`
        WHERE
          DATE(time_stamps) >= DATE_SUB("2023-02-09", INTERVAL 30 DAY)
          AND DATE(time_stamps) < DATE_SUB("2023-02-09", INTERVAL 10 DAY)
          AND agg_tag = "24hr"
      );
      
[0m20:40:33.140370 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:8c8fc80b-85fa-4b39-9901-fc87943025a1&page=queryresults
[0m20:40:33.150339 [debug] [Thread-3  ]: Writing runtime sql for node "model.anomaly_detection.forecasts"
[0m20:40:33.154983 [debug] [Thread-3  ]: On model.anomaly_detection.forecasts: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.forecasts"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`forecasts`
    
    
    OPTIONS()
    as (
      -- 3 periods of training * 2 probabality threshold * 4 aggregation levels



-- depends_on: `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`IQR_outliers`


  WITH test_set AS (
    SELECT
    time_stamps,
          event_count,
          app_event,
          agg_tag
        FROM
          `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`aggregations_cutoff`
        WHERE
        DATE(time_stamps) >= DATE_SUB("2023-02-09", INTERVAL 10 DAY)
  )

    

      

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_1mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_8hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_2mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_24hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_2mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_12hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_2mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_8hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_2mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_4hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_1mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_4hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_1mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_12hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_1mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_24hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_05mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_4hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_05mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_8hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_05mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_12hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.9999" AS prob_threshold,
          "derived_models_05mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_24hr`,
            struct( 0.9999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

    

      

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_1mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_8hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_2mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_24hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_2mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_12hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_2mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_8hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_2mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_2mon_4hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_1mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_4hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_1mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_12hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_1mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_1mon_24hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_05mon_4hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_4hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "4hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_05mon_8hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_8hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "8hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_05mon_12hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_12hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "12hr" ))
          )

        union all

      

        SELECT
          app_event, agg_tag,
          time_stamps,
          "0.999999" AS prob_threshold,
          "derived_models_05mon_24hr" AS training_period,
          event_count,
          is_anomaly,
          lower_bound,
          upper_bound,
          anomaly_probability
        FROM
          ml.detect_anomalies(
            model `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`models_05mon_24hr`,
            struct( 0.999999 as anomaly_prob_threshold),
            (select * from (select * from test_set where agg_tag = "24hr" ))
          )

        

      

    
    );
  
[0m20:40:37.559503 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:dd394b9c-8906-4e17-9d04-9a65fb402096&page=queryresults
[0m20:40:37.566242 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.forecasts (execute): 2024-05-08 20:37:46.200659 => 2024-05-08 20:40:37.565646
[0m20:40:37.569075 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111666640>]}
[0m20:40:37.570679 [info ] [Thread-3  ]: 10 of 21 OK created sql table model tenant_B.forecasts ......................... [[32mCREATE TABLE (1.4k rows, 550.5 KB processed)[0m in 171.38s]
[0m20:40:37.571920 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.forecasts
[0m20:40:37.577458 [debug] [Thread-4  ]: Began running node model.anomaly_detection.reset_forecasts
[0m20:40:37.578143 [info ] [Thread-4  ]: 11 of 21 START sql table model tenant_B.reset_forecasts ........................ [RUN]
[0m20:40:37.579151 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.reset_forecasts'
[0m20:40:37.579851 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.reset_forecasts
[0m20:40:37.587984 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.reset_forecasts"
[0m20:40:37.589227 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.reset_forecasts (compile): 2024-05-08 20:40:37.580228 => 2024-05-08 20:40:37.589181
[0m20:40:37.589387 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.reset_forecasts
[0m20:40:37.591371 [debug] [Thread-4  ]: Writing runtime sql for node "model.anomaly_detection.reset_forecasts"
[0m20:40:37.592246 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m20:40:37.592549 [debug] [Thread-4  ]: On model.anomaly_detection.reset_forecasts: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.reset_forecasts"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`reset_forecasts`
    
    
    OPTIONS()
    as (
      
  
  with neg_bound_reset as (
SELECT app_event, agg_tag, time_stamps, prob_threshold, training_period, event_count, 
  IF (lower_bound < 0, 2, (1 / 1.3) * lower_bound) AS lower_bound, 1.3 * upper_bound AS upper_bound, anomaly_probability, is_anomaly
FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`forecasts` )

SELECT app_event, agg_tag, time_stamps, prob_threshold, training_period, event_count, 
  lower_bound, upper_bound, anomaly_probability,
  (upper_bound < event_count OR event_count < lower_bound) AS is_anomaly
FROM neg_bound_reset
    );
  
[0m20:40:40.571536 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:379762e9-1447-4eef-8a56-96d51557e117&page=queryresults
[0m20:40:40.578217 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.reset_forecasts (execute): 2024-05-08 20:40:37.589482 => 2024-05-08 20:40:40.578082
[0m20:40:40.579593 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111197fd0>]}
[0m20:40:40.580383 [info ] [Thread-4  ]: 11 of 21 OK created sql table model tenant_B.reset_forecasts ................... [[32mCREATE TABLE (1.4k rows, 151.6 KB processed)[0m in 3.00s]
[0m20:40:40.581057 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.reset_forecasts
[0m20:40:40.582566 [debug] [Thread-2  ]: Began running node model.anomaly_detection.all_configs
[0m20:40:40.583408 [info ] [Thread-2  ]: 12 of 21 START sql table model tenant_B.all_configs ............................ [RUN]
[0m20:40:40.584949 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.all_configs'
[0m20:40:40.585815 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.all_configs
[0m20:40:40.592138 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.all_configs"
[0m20:40:40.594376 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.all_configs (compile): 2024-05-08 20:40:40.586127 => 2024-05-08 20:40:40.594222
[0m20:40:40.594961 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.all_configs
[0m20:40:40.600219 [debug] [Thread-2  ]: Writing runtime sql for node "model.anomaly_detection.all_configs"
[0m20:40:40.601560 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m20:40:40.602061 [debug] [Thread-2  ]: On model.anomaly_detection.all_configs: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.all_configs"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`all_configs`
    
    
    OPTIONS()
    as (
      
  
  SELECT
    app_event,
    CONCAT(agg_tag, '_', prob_threshold, "threshold", '_', RTRIM(LTRIM(training_period, "derived_models_"), CONCAT('_', agg_tag))) AS control_config,
    SUM(CASE WHEN is_anomaly = TRUE THEN 1 ELSE 0 END) AS anomalies,
    SQRT(AVG( POWER(upper_bound - lower_bound, 2) ) ) / AVG(lower_bound) AS RMSD_prcnt
  FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`reset_forecasts` AS all_configs
  GROUP BY
    app_event,
    control_config
  ORDER BY
    control_config,
    app_event
    );
  
[0m20:40:43.124539 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:e4dcb68f-3e6c-49f7-a91f-5a88f4dc03de&page=queryresults
[0m20:40:43.127125 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.all_configs (execute): 2024-05-08 20:40:40.595629 => 2024-05-08 20:40:43.127029
[0m20:40:43.128213 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11125f9a0>]}
[0m20:40:43.128925 [info ] [Thread-2  ]: 12 of 21 OK created sql table model tenant_B.all_configs ....................... [[32mCREATE TABLE (48.0 rows, 119.3 KB processed)[0m in 2.54s]
[0m20:40:43.129449 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.all_configs
[0m20:40:43.130379 [debug] [Thread-1  ]: Began running node model.anomaly_detection.nonrecent_configs
[0m20:40:43.131152 [info ] [Thread-1  ]: 13 of 21 START sql table model tenant_B.nonrecent_configs ...................... [RUN]
[0m20:40:43.132345 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.nonrecent_configs'
[0m20:40:43.132758 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.nonrecent_configs
[0m20:40:43.137671 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.nonrecent_configs"
[0m20:40:43.138609 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_configs (compile): 2024-05-08 20:40:43.132895 => 2024-05-08 20:40:43.138551
[0m20:40:43.138846 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.nonrecent_configs
[0m20:40:43.142355 [debug] [Thread-1  ]: Writing runtime sql for node "model.anomaly_detection.nonrecent_configs"
[0m20:40:43.143410 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:40:43.143792 [debug] [Thread-1  ]: On model.anomaly_detection.nonrecent_configs: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.nonrecent_configs"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`nonrecent_configs`
    
    
    OPTIONS()
    as (
      
SELECT features.app_event, control_config, anomalies, RMSD_prcnt
FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`nonrecent_events` AS non_recent
INNER JOIN `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`all_configs` AS features
  ON non_recent.app_event = features.app_event
    );
  
[0m20:40:46.301254 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:6c7da194-3bdd-4f61-a9fa-48aea1c01fec&page=queryresults
[0m20:40:46.304376 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.nonrecent_configs (execute): 2024-05-08 20:40:43.139007 => 2024-05-08 20:40:46.304288
[0m20:40:46.305454 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e89790>]}
[0m20:40:46.306157 [info ] [Thread-1  ]: 13 of 21 OK created sql table model tenant_B.nonrecent_configs ................. [[32mCREATE TABLE (48.0 rows, 3.4 KB processed)[0m in 3.17s]
[0m20:40:46.306629 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.nonrecent_configs
[0m20:40:46.307419 [debug] [Thread-3  ]: Began running node model.anomaly_detection.filtered_nonrecent_configs
[0m20:40:46.307776 [info ] [Thread-3  ]: 14 of 21 START sql table model tenant_B.filtered_nonrecent_configs ............. [RUN]
[0m20:40:46.308348 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.filtered_nonrecent_configs'
[0m20:40:46.308588 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.filtered_nonrecent_configs
[0m20:40:46.311913 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.filtered_nonrecent_configs"
[0m20:40:46.312714 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.filtered_nonrecent_configs (compile): 2024-05-08 20:40:46.308717 => 2024-05-08 20:40:46.312639
[0m20:40:46.312986 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.filtered_nonrecent_configs
[0m20:40:46.316436 [debug] [Thread-3  ]: Writing runtime sql for node "model.anomaly_detection.filtered_nonrecent_configs"
[0m20:40:46.317081 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m20:40:46.317364 [debug] [Thread-3  ]: On model.anomaly_detection.filtered_nonrecent_configs: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.filtered_nonrecent_configs"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`filtered_nonrecent_configs`
    
    
    OPTIONS()
    as (
      

select *
from `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`nonrecent_configs`
where RMSD_prcnt is not null
    );
  
[0m20:40:48.885242 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:e9c3571c-dc39-42a9-8658-b694930aa24c&page=queryresults
[0m20:40:48.888813 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.filtered_nonrecent_configs (execute): 2024-05-08 20:40:46.313130 => 2024-05-08 20:40:48.888706
[0m20:40:48.889920 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11125f9a0>]}
[0m20:40:48.890564 [info ] [Thread-3  ]: 14 of 21 OK created sql table model tenant_B.filtered_nonrecent_configs ........ [[32mCREATE TABLE (48.0 rows, 3.4 KB processed)[0m in 2.58s]
[0m20:40:48.891063 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.filtered_nonrecent_configs
[0m20:40:48.892397 [debug] [Thread-4  ]: Began running node model.anomaly_detection.min_anomalies
[0m20:40:48.893030 [info ] [Thread-4  ]: 15 of 21 START sql table model tenant_B.min_anomalies .......................... [RUN]
[0m20:40:48.893838 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.min_anomalies'
[0m20:40:48.894126 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.min_anomalies
[0m20:40:48.904362 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.min_anomalies"
[0m20:40:48.905487 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.min_anomalies (compile): 2024-05-08 20:40:48.894299 => 2024-05-08 20:40:48.905409
[0m20:40:48.905728 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.min_anomalies
[0m20:40:48.908642 [debug] [Thread-4  ]: Writing runtime sql for node "model.anomaly_detection.min_anomalies"
[0m20:40:48.909307 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m20:40:48.909754 [debug] [Thread-4  ]: On model.anomaly_detection.min_anomalies: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.min_anomalies"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`min_anomalies`
    
    
    OPTIONS()
    as (
      

SELECT app_event, MIN(anomalies) AS anomalies 
  FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`filtered_nonrecent_configs`
  GROUP BY app_event
  ORDER BY app_event
    );
  
[0m20:40:51.816492 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:936fe62f-433b-42e7-a5e2-ff5894ea29c5&page=queryresults
[0m20:40:51.820515 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.min_anomalies (execute): 2024-05-08 20:40:48.905864 => 2024-05-08 20:40:51.820415
[0m20:40:51.821572 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11161e250>]}
[0m20:40:51.822440 [info ] [Thread-4  ]: 15 of 21 OK created sql table model tenant_B.min_anomalies ..................... [[32mCREATE TABLE (2.0 rows, 1.7 KB processed)[0m in 2.93s]
[0m20:40:51.824101 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.min_anomalies
[0m20:40:51.825223 [debug] [Thread-2  ]: Began running node model.anomaly_detection.min_anomalies_configs
[0m20:40:51.825978 [info ] [Thread-2  ]: 16 of 21 START sql table model tenant_B.min_anomalies_configs .................. [RUN]
[0m20:40:51.826954 [debug] [Thread-2  ]: Acquiring new bigquery connection 'model.anomaly_detection.min_anomalies_configs'
[0m20:40:51.827294 [debug] [Thread-2  ]: Began compiling node model.anomaly_detection.min_anomalies_configs
[0m20:40:51.832336 [debug] [Thread-2  ]: Writing injected SQL for node "model.anomaly_detection.min_anomalies_configs"
[0m20:40:51.833165 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.min_anomalies_configs (compile): 2024-05-08 20:40:51.827471 => 2024-05-08 20:40:51.833105
[0m20:40:51.833402 [debug] [Thread-2  ]: Began executing node model.anomaly_detection.min_anomalies_configs
[0m20:40:51.836316 [debug] [Thread-2  ]: Writing runtime sql for node "model.anomaly_detection.min_anomalies_configs"
[0m20:40:51.836830 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m20:40:51.837062 [debug] [Thread-2  ]: On model.anomaly_detection.min_anomalies_configs: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.min_anomalies_configs"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`min_anomalies_configs`
    
    
    OPTIONS()
    as (
      

SELECT configs.app_event, configs.control_config, 
    configs.anomalies, configs.RMSD_prcnt
  FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`filtered_nonrecent_configs` AS configs
  INNER JOIN `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`min_anomalies` AS min_anomalies
    ON configs.anomalies = min_anomalies.anomalies
      AND configs.app_event = min_anomalies.app_event
  ORDER BY configs.app_event, RMSD_prcnt DESC
    );
  
[0m20:40:54.525180 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:d97f029d-cbf4-46dc-8e9f-a3c20295acd5&page=queryresults
[0m20:40:54.530320 [debug] [Thread-2  ]: Timing info for model.anomaly_detection.min_anomalies_configs (execute): 2024-05-08 20:40:51.833565 => 2024-05-08 20:40:54.530189
[0m20:40:54.531573 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11127e160>]}
[0m20:40:54.532279 [info ] [Thread-2  ]: 16 of 21 OK created sql table model tenant_B.min_anomalies_configs ............. [[32mCREATE TABLE (37.0 rows, 3.4 KB processed)[0m in 2.70s]
[0m20:40:54.532793 [debug] [Thread-2  ]: Finished running node model.anomaly_detection.min_anomalies_configs
[0m20:40:54.534014 [debug] [Thread-1  ]: Began running node model.anomaly_detection.min_RMSD
[0m20:40:54.534726 [info ] [Thread-1  ]: 17 of 21 START sql table model tenant_B.min_RMSD ............................... [RUN]
[0m20:40:54.535585 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.anomaly_detection.min_RMSD'
[0m20:40:54.535897 [debug] [Thread-1  ]: Began compiling node model.anomaly_detection.min_RMSD
[0m20:40:54.541174 [debug] [Thread-1  ]: Writing injected SQL for node "model.anomaly_detection.min_RMSD"
[0m20:40:54.542165 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.min_RMSD (compile): 2024-05-08 20:40:54.536082 => 2024-05-08 20:40:54.542105
[0m20:40:54.542405 [debug] [Thread-1  ]: Began executing node model.anomaly_detection.min_RMSD
[0m20:40:54.545825 [debug] [Thread-1  ]: Writing runtime sql for node "model.anomaly_detection.min_RMSD"
[0m20:40:54.546556 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:40:54.546835 [debug] [Thread-1  ]: On model.anomaly_detection.min_RMSD: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.min_RMSD"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`min_RMSD`
    
    
    OPTIONS()
    as (
      

SELECT app_event, MIN(RMSD_prcnt) AS RMSD_prcnt 
  FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`min_anomalies_configs`
  GROUP BY app_event
  ORDER BY app_event
    );
  
[0m20:40:57.254801 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:11dc16e6-7e64-41de-9018-74fb6273e38e&page=queryresults
[0m20:40:57.259574 [debug] [Thread-1  ]: Timing info for model.anomaly_detection.min_RMSD (execute): 2024-05-08 20:40:54.542548 => 2024-05-08 20:40:57.259526
[0m20:40:57.260164 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11127e040>]}
[0m20:40:57.260491 [info ] [Thread-1  ]: 17 of 21 OK created sql table model tenant_B.min_RMSD .......................... [[32mCREATE TABLE (2.0 rows, 1.3 KB processed)[0m in 2.72s]
[0m20:40:57.260760 [debug] [Thread-1  ]: Finished running node model.anomaly_detection.min_RMSD
[0m20:40:57.261456 [debug] [Thread-3  ]: Began running node model.anomaly_detection.control_table
[0m20:40:57.261738 [info ] [Thread-3  ]: 18 of 21 START sql table model tenant_B.control_table .......................... [RUN]
[0m20:40:57.262230 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.control_table'
[0m20:40:57.262399 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.control_table
[0m20:40:57.266111 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.control_table"
[0m20:40:57.267128 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.control_table (compile): 2024-05-08 20:40:57.262509 => 2024-05-08 20:40:57.267065
[0m20:40:57.267354 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.control_table
[0m20:40:57.271202 [debug] [Thread-3  ]: Writing runtime sql for node "model.anomaly_detection.control_table"
[0m20:40:57.272009 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m20:40:57.272327 [debug] [Thread-3  ]: On model.anomaly_detection.control_table: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.control_table"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`control_table`
    
    
    OPTIONS()
    as (
      

SELECT configs.app_event, configs.control_config, 
    configs.anomalies, configs.RMSD_prcnt
  FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`min_anomalies_configs` AS configs
  INNER JOIN `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`min_RMSD` AS min_RMSD
    ON configs.RMSD_prcnt = min_RMSD.RMSD_prcnt
      AND configs.app_event = min_RMSD.app_event
  ORDER BY configs.app_event, control_config
    );
  
[0m20:40:59.938643 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:dfceaf99-8539-4586-8d3d-07fceff4df48&page=queryresults
[0m20:40:59.942642 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.control_table (execute): 2024-05-08 20:40:57.267479 => 2024-05-08 20:40:59.942533
[0m20:40:59.943827 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116d5580>]}
[0m20:40:59.944496 [info ] [Thread-3  ]: 18 of 21 OK created sql table model tenant_B.control_table ..................... [[32mCREATE TABLE (2.0 rows, 2.7 KB processed)[0m in 2.68s]
[0m20:40:59.944992 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.control_table
[0m20:40:59.946139 [debug] [Thread-4  ]: Began running node model.anomaly_detection.alerting_base
[0m20:40:59.946532 [debug] [Thread-1  ]: Began running node model.tenant_A.my_first_dbt_model
[0m20:40:59.947007 [info ] [Thread-4  ]: 19 of 21 START sql table model tenant_B.alerting_base .......................... [RUN]
[0m20:40:59.947433 [info ] [Thread-1  ]: 20 of 21 START sql table model tenant_B.my_first_dbt_model ..................... [RUN]
[0m20:40:59.948240 [debug] [Thread-4  ]: Acquiring new bigquery connection 'model.anomaly_detection.alerting_base'
[0m20:40:59.948822 [debug] [Thread-1  ]: Acquiring new bigquery connection 'model.tenant_A.my_first_dbt_model'
[0m20:40:59.949155 [debug] [Thread-4  ]: Began compiling node model.anomaly_detection.alerting_base
[0m20:40:59.949444 [debug] [Thread-1  ]: Began compiling node model.tenant_A.my_first_dbt_model
[0m20:40:59.955718 [debug] [Thread-4  ]: Writing injected SQL for node "model.anomaly_detection.alerting_base"
[0m20:40:59.959215 [debug] [Thread-1  ]: Writing injected SQL for node "model.tenant_A.my_first_dbt_model"
[0m20:40:59.960547 [debug] [Thread-1  ]: Timing info for model.tenant_A.my_first_dbt_model (compile): 2024-05-08 20:40:59.956155 => 2024-05-08 20:40:59.960465
[0m20:40:59.960841 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.alerting_base (compile): 2024-05-08 20:40:59.949622 => 2024-05-08 20:40:59.960716
[0m20:40:59.961215 [debug] [Thread-1  ]: Began executing node model.tenant_A.my_first_dbt_model
[0m20:40:59.961475 [debug] [Thread-4  ]: Began executing node model.anomaly_detection.alerting_base
[0m20:40:59.964527 [debug] [Thread-1  ]: Writing runtime sql for node "model.tenant_A.my_first_dbt_model"
[0m20:40:59.967617 [debug] [Thread-4  ]: Writing runtime sql for node "model.anomaly_detection.alerting_base"
[0m20:40:59.968329 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:40:59.968663 [debug] [Thread-1  ]: On model.tenant_A.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.tenant_A.my_first_dbt_model"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



select * 
from `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`control_table`

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m20:40:59.968834 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m20:40:59.969818 [debug] [Thread-4  ]: On model.anomaly_detection.alerting_base: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.alerting_base"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`alerting_base`
    
    
    OPTIONS()
    as (
      
  
  WITH ml_detect_updated AS (
    SELECT app_event, 
      CONCAT(agg_tag, '_', prob_threshold, "threshold", '_', RTRIM(LTRIM(training_period, "derived_models_"), CONCAT('_', agg_tag))) AS control_config,
      time_stamps, event_count, is_anomaly, lower_bound, upper_bound, anomaly_probability
    FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`reset_forecasts`
  )
  SELECT time_stamps, all_forecasts.app_event AS app_event, control_table.control_config AS control_config, 
    anomalies, RMSD_prcnt, event_count, lower_bound, upper_bound, anomaly_probability, is_anomaly
  FROM ml_detect_updated AS all_forecasts 
  INNER JOIN `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`control_table` AS control_table 
    ON all_forecasts.app_event = control_table.app_event
      AND all_forecasts.control_config = control_table.control_config
  ORDER BY all_forecasts.app_event, time_stamps
    );
  
[0m20:41:02.963619 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:24f95de2-7a31-42dd-ab9e-25781f8956b5&page=queryresults
[0m20:41:02.967221 [debug] [Thread-1  ]: Timing info for model.tenant_A.my_first_dbt_model (execute): 2024-05-08 20:40:59.961627 => 2024-05-08 20:41:02.967124
[0m20:41:02.968238 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116d46a0>]}
[0m20:41:02.968770 [info ] [Thread-1  ]: 20 of 21 OK created sql table model tenant_B.my_first_dbt_model ................ [[32mCREATE TABLE (2.0 rows, 141.0 Bytes processed)[0m in 3.02s]
[0m20:41:02.969147 [debug] [Thread-1  ]: Finished running node model.tenant_A.my_first_dbt_model
[0m20:41:03.023325 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:55a9c3f1-2a01-4a0e-9efe-feccbdf54bd8&page=queryresults
[0m20:41:03.025481 [debug] [Thread-4  ]: Timing info for model.anomaly_detection.alerting_base (execute): 2024-05-08 20:40:59.964818 => 2024-05-08 20:41:03.025403
[0m20:41:03.026274 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116d4ac0>]}
[0m20:41:03.026789 [info ] [Thread-4  ]: 19 of 21 OK created sql table model tenant_B.alerting_base ..................... [[32mCREATE TABLE (50.0 rows, 153.2 KB processed)[0m in 3.08s]
[0m20:41:03.027150 [debug] [Thread-4  ]: Finished running node model.anomaly_detection.alerting_base
[0m20:41:03.028179 [debug] [Thread-3  ]: Began running node model.anomaly_detection.daily_alerts
[0m20:41:03.028834 [info ] [Thread-3  ]: 21 of 21 START sql table model tenant_B.daily_alerts ........................... [RUN]
[0m20:41:03.029659 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.anomaly_detection.daily_alerts'
[0m20:41:03.029938 [debug] [Thread-3  ]: Began compiling node model.anomaly_detection.daily_alerts
[0m20:41:03.034292 [debug] [Thread-3  ]: Writing injected SQL for node "model.anomaly_detection.daily_alerts"
[0m20:41:03.036187 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.daily_alerts (compile): 2024-05-08 20:41:03.030096 => 2024-05-08 20:41:03.036120
[0m20:41:03.036419 [debug] [Thread-3  ]: Began executing node model.anomaly_detection.daily_alerts
[0m20:41:03.038878 [debug] [Thread-3  ]: Writing runtime sql for node "model.anomaly_detection.daily_alerts"
[0m20:41:03.039333 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m20:41:03.039582 [debug] [Thread-3  ]: On model.anomaly_detection.daily_alerts: /* {"app": "dbt", "dbt_version": "1.4.1", "profile_name": "tenant_A", "target_name": "dev", "node_id": "model.anomaly_detection.daily_alerts"} */

  
    

    create or replace table `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`daily_alerts`
    
    
    OPTIONS()
    as (
      
SELECT time_stamps, app_event, event_count AS event_count_anomalous_yesterday
FROM `prj-s-telus-tpm-data-fcfc`.`tenant_B`.`alerting_base`
WHERE DATE(time_stamps) = "2023-02-09" - 1 
  AND is_anomaly
    );
  
[0m20:41:05.702184 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=prj-s-telus-tpm-data-fcfc&j=bq:US:0da8a4a6-7f46-4c4a-a245-187606cd72e2&page=queryresults
[0m20:41:05.708592 [debug] [Thread-3  ]: Timing info for model.anomaly_detection.daily_alerts (execute): 2024-05-08 20:41:03.036551 => 2024-05-08 20:41:05.708476
[0m20:41:05.709796 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0b389a7-1931-43d3-905c-332abd2b5e3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116d41f0>]}
[0m20:41:05.710490 [info ] [Thread-3  ]: 21 of 21 OK created sql table model tenant_B.daily_alerts ...................... [[32mCREATE TABLE (0.0 rows, 2.2 KB processed)[0m in 2.68s]
[0m20:41:05.711009 [debug] [Thread-3  ]: Finished running node model.anomaly_detection.daily_alerts
[0m20:41:05.713597 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m20:41:05.714406 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:41:05.714665 [debug] [MainThread]: Connection 'model.tenant_A.my_first_dbt_model' was properly closed.
[0m20:41:05.714845 [debug] [MainThread]: Connection 'model.anomaly_detection.daily_alerts' was properly closed.
[0m20:41:05.715008 [debug] [MainThread]: Connection 'model.anomaly_detection.min_anomalies_configs' was properly closed.
[0m20:41:05.715169 [debug] [MainThread]: Connection 'model.anomaly_detection.alerting_base' was properly closed.
[0m20:41:05.715573 [info ] [MainThread]: 
[0m20:41:05.715954 [info ] [MainThread]: Finished running 21 table models in 0 hours 3 minutes and 51.87 seconds (231.87s).
[0m20:41:05.717473 [debug] [MainThread]: Command end result
[0m20:41:05.733809 [info ] [MainThread]: 
[0m20:41:05.734155 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:41:05.734362 [info ] [MainThread]: 
[0m20:41:05.734534 [info ] [MainThread]: Done. PASS=21 WARN=0 ERROR=0 SKIP=0 TOTAL=21
[0m20:41:05.734944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111687ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11119ce80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11119cd30>]}
[0m20:41:05.735154 [debug] [MainThread]: Flushing usage events
